{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NW_JBhf02YC8","outputId":"aea76776-ec5a-4312-869a-2001010d0cff","executionInfo":{"status":"ok","timestamp":1749052876148,"user_tz":-420,"elapsed":815048,"user":{"displayName":"Resconnect","userId":"00882996269091038835"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","✅ Đã giải nén: /content/drive/MyDrive/kaggle_data/aptos2019/train_images.zip → /content/extracted_zip_files/train_images\n","✅ Đã giải nén: /content/drive/MyDrive/kaggle_data/aptos2019/test_images.zip → /content/extracted_zip_files/test_images\n","Đã xử lý thành công 3662 ảnh.\n","Train X size: 2379\n","Train y size: 2379\n","Valid X size: 550\n","Valid y size: 550\n","Test X size: 733\n","Test y size: 733\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import glob\n","import zipfile\n","import matplotlib.pyplot as plt\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","\n","# 1. Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# 2. Đường dẫn đến dữ liệu\n","drive_folder = \"/content/drive/MyDrive/kaggle_data/aptos2019\"\n","extract_root = \"/content/extracted_zip_files\"\n","os.makedirs(extract_root, exist_ok=True)\n","\n","# Giải nén các file ZIP nếu chưa giải (nếu đã giải thì bỏ qua)\n","zip_files = glob.glob(os.path.join(drive_folder, \"*.zip\"))\n","for zip_path in zip_files:\n","    zip_name = os.path.basename(zip_path).replace(\".zip\", \"\")\n","    extract_path = os.path.join(extract_root, zip_name)\n","    os.makedirs(extract_path, exist_ok=True)\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_path)\n","    print(f\"✅ Đã giải nén: {zip_path} → {extract_path}\")\n","\n","# 3. Đọc file CSV\n","df_train = pd.read_csv(os.path.join(drive_folder, \"train.csv\"))\n","df_test = pd.read_csv(os.path.join(drive_folder, \"test.csv\"))\n","\n","# 4. Định nghĩa hàm xử lý ảnh: cắt, resize và tăng cường ảnh\n","def crop_image_from_gray_to_color(img, tol=7):\n","    \"\"\"\n","    Cắt bỏ các vùng không cần thiết (đặc biệt là các cạnh tối) của ảnh dựa trên thông tin từ ảnh xám,\n","    sau đó áp dụng vùng cắt này lên ảnh màu gốc.\n","    \"\"\"\n","    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","    mask = gray > tol\n","    if mask.sum() == 0:\n","        return img\n","    rows = mask.any(axis=1)\n","    cols = mask.any(axis=0)\n","    cropped_img = img[np.ix_(rows, cols)]\n","    return cropped_img\n","\n","def load_ben_color(path, sigmaX=10, IMG_SIZE=244):\n","    \"\"\"\n","    Load ảnh từ đường dẫn, cắt bỏ biên tối dựa trên ảnh xám, resize và tăng cường ảnh bằng GaussianBlur.\n","    \"\"\"\n","    image = cv2.imread(path)\n","    if image is None:\n","        raise ValueError(f\"Không thể đọc được ảnh từ đường dẫn: {path}\")\n","    # Chuyển BGR sang RGB\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    # Cắt ảnh theo vùng sáng\n","    image = crop_image_from_gray_to_color(image, tol=7)\n","    # Resize ảnh về kích thước mong muốn\n","    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n","    # Tăng cường ảnh bằng GaussianBlur và weighted addition\n","    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0, 0), sigmaX), -4, 128)\n","    return image\n","\n","# 5. Xử lý và lưu ảnh đã xử lý vào một thư mục tạm thời trên Colab\n","train_img_folder = os.path.join(extract_root, \"train_images\")  # Thư mục chứa ảnh gốc\n","processed_folder = \"/content/processed_train_images\"          # Thư mục lưu ảnh đã xử lý\n","os.makedirs(processed_folder, exist_ok=True)\n","\n","processed_ids = []  # Lưu lại id của các ảnh đã được xử lý thành công\n","\n","for idx, row in df_train.iterrows():\n","    img_filename = f\"{row['id_code']}.png\"\n","    img_path = os.path.join(train_img_folder, img_filename)\n","\n","    try:\n","        proc_img = load_ben_color(img_path, sigmaX=10, IMG_SIZE=244)\n","        # cv2.imwrite lưu ảnh theo định dạng BGR nên chuyển từ RGB sang BGR\n","        proc_img_bgr = cv2.cvtColor(proc_img, cv2.COLOR_RGB2BGR)\n","        save_path = os.path.join(processed_folder, img_filename)\n","        cv2.imwrite(save_path, proc_img_bgr)\n","        processed_ids.append(row['id_code'])\n","    except Exception as e:\n","        print(f\"Lỗi khi xử lý ảnh {img_filename}: {e}\")\n","\n","print(f\"Đã xử lý thành công {len(processed_ids)} ảnh.\")\n","\n","# 6. Cập nhật DataFrame chỉ với các ảnh đã xử lý thành công\n","df_train_processed = df_train[df_train['id_code'].isin(processed_ids)].copy()\n","\n","# 7. Chia dữ liệu thành tập train và validation dựa trên file CSV\n","x = df_train_processed['id_code']\n","y = df_train_processed['diagnosis']\n","\n","# Xáo trộn dữ liệu để đảm bảo tính ngẫu nhiên\n","x, y = shuffle(x, y, random_state=42)\n","\n","# Chia tập train+validation và test (80% - 20%)\n","x_temp, test_x, y_temp, test_y = train_test_split(x, y, test_size=0.20, stratify=y, random_state=42)\n","\n","# Chia tập train và validation (85% train, 15% val trong 80% dữ liệu ban đầu)\n","train_x, valid_x, train_y, valid_y = train_test_split(x_temp, y_temp, test_size=0.15/0.80, stratify=y_temp, random_state=42)\n","\n","# In thông tin kiểm tra\n","print(\"Train X size:\", len(train_x))\n","print(\"Train y size:\", len(train_y))\n","print(\"Valid X size:\", len(valid_x))\n","print(\"Valid y size:\", len(valid_y))\n","print(\"Test X size:\", len(test_x))\n","print(\"Test y size:\", len(test_y))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7923,"status":"ok","timestamp":1748584902570,"user":{"displayName":"Resconnect","userId":"00882996269091038835"},"user_tz":-420},"id":"ozYM5kEQ2YC-","outputId":"3f711bbc-4de9-4d18-d095-afccee206d60"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.7'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n"]}],"source":["import matplotlib.pyplot as plt\n","import skimage.io\n","from skimage.transform import resize\n","import albumentations as A\n","from tqdm import tqdm\n","import PIL\n","from PIL import Image, ImageOps\n","import cv2\n","from sklearn.utils import class_weight, shuffle\n","from keras.losses import binary_crossentropy, categorical_crossentropy\n","\n","# Tiền xử lý cho các mô hình khác nhau\n","from keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n","from keras.applications.inception_v3 import preprocess_input as inception_preprocess\n","from keras.applications.densenet import preprocess_input as densenet_preprocess\n","from keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n","from keras.applications.xception import preprocess_input as xception_preprocess  # Đã thay thế\n","\n","import keras.backend as K\n","import tensorflow as tf\n","from sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score, accuracy_score\n","from keras.utils import Sequence, to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","# Import các mô hình CNN từ Keras Applications\n","from keras.applications import ResNet50, EfficientNetB0, InceptionV3, DenseNet121, Xception  # Đã thay thế MobileNetV2\n","\n","\n","WORKERS = 2\n","CHANNEL = 3\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","SIZE = 244\n","NUM_CLASSES = 5\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I8-k9wBi2YC-"},"outputs":[],"source":["import numpy as np\n","\n","def to_multi_label(target, num_classes=5):\n","    \"\"\" Chuyển đổi nhãn đơn thành multi-label (One-vs-All). \"\"\"\n","    return (np.arange(num_classes) < (target[:, None] + 1)).astype(int)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1RHb02T12YC-"},"outputs":[],"source":["import tensorflow as tf\n","\n","class AdamAccumulate(tf.keras.optimizers.Adam):\n","    def __init__(self, accum_iters=2, **kwargs):\n","        \"\"\"\n","        accum_iters: số bước tích lũy gradient trước khi cập nhật trọng số.\n","        kwargs: các tham số khác của Adam (như learning_rate, beta_1, beta_2, epsilon, decay, v.v.)\n","        \"\"\"\n","        super(AdamAccumulate, self).__init__(**kwargs)\n","        if accum_iters < 1:\n","            raise ValueError('accum_iters phải >= 1')\n","        self.accum_iters = accum_iters\n","        # Đếm số batch đã tích lũy\n","        self._accum_steps = 0\n","        # Bộ nhớ chứa gradient đã tích lũy (dictionary: key là tham chiếu của biến)\n","        self._grad_accum = {}\n","\n","    @tf.function\n","    def apply_gradients(self, grads_and_vars, name=None, experimental_aggregate_gradients=True):\n","        # Nếu đây là lần chạy đầu tiên, khởi tạo biến tích lũy cho mỗi biến\n","        if not self._grad_accum:\n","            for grad, var in grads_and_vars:\n","                if grad is None:\n","                    continue\n","                self._grad_accum[var.ref()] = tf.Variable(tf.zeros_like(var), trainable=False)\n","\n","        # Tích lũy gradient cho mỗi biến\n","        for grad, var in grads_and_vars:\n","            if grad is None:\n","                continue\n","            self._grad_accum[var.ref()].assign_add(grad)\n","\n","        self._accum_steps += 1\n","\n","        # Chỉ cập nhật trọng số khi số bước tích lũy đạt đến accum_iters\n","        if self._accum_steps % self.accum_iters == 0:\n","            # Tính trung bình gradient và tạo danh sách cập nhật\n","            avg_grads_and_vars = []\n","            for grad, var in grads_and_vars:\n","                if grad is None:\n","                    continue\n","                accumulated_grad = self._grad_accum[var.ref()]\n","                avg_grad = accumulated_grad / tf.cast(self.accum_iters, accumulated_grad.dtype)\n","                avg_grads_and_vars.append((avg_grad, var))\n","                # Reset lại gradient tích lũy cho biến\n","                accumulated_grad.assign(tf.zeros_like(var))\n","            # Gọi phương thức apply_gradients của lớp Adam gốc để cập nhật trọng số\n","            super(AdamAccumulate, self).apply_gradients(avg_grads_and_vars, name, experimental_aggregate_gradients)\n","        # Nếu chưa đủ số bước, không cập nhật trọng số\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zJWwUcTl2YC-"},"outputs":[],"source":["import albumentations as A\n","import numpy as np\n","import cv2\n","import os\n","from sklearn.utils import shuffle\n","from keras.utils import Sequence\n","\n","# Import preprocess_input từ các mô hình\n","from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n","from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n","from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n","from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n","from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess\n","\n","class My_Generator(Sequence):\n","    def __init__(self, image_filenames, labels, batch_size, is_train=False,\n","                 mix=False, augment=False, size1=224, size2=299, model_type=\"default\",\n","                 balance_classes=False):\n","        self.image_filenames = np.array(image_filenames)\n","        self.labels = np.array(labels)\n","        self.batch_size = batch_size\n","        self.is_train = is_train\n","        self.is_augment = augment\n","        self.is_mix = mix\n","        self.model_type = str(model_type).lower()\n","        self.n_classes = self.labels.shape[1] if self.labels.ndim > 1 else int(max(self.labels) + 1)\n","\n","        if \"inceptionv3\" in self.model_type:\n","            self.target_size = (size2, size2)\n","        else:\n","            self.target_size = (size1, size1)\n","\n","        self.base_path = \"/content/processed_train_images/\"\n","\n","        if self.is_augment and self.is_train:\n","            self.augmenter = A.Compose([\n","                A.OneOf([\n","                    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0, p=1),\n","                    A.MultiplicativeNoise(multiplier=(0.9, 1.1), per_channel=True, p=1),\n","                    A.RandomBrightnessContrast(brightness_limit=0, contrast_limit=0.1, p=1)\n","                ], p=0.5),\n","                A.HorizontalFlip(p=0.5),\n","                A.VerticalFlip(p=0.5),\n","                A.CropAndPad(percent=(-0.1, 0), p=0.5)\n","            ])\n","\n","        self.rare_augmenter = A.Compose([\n","            A.HorizontalFlip(p=0.5),\n","            A.VerticalFlip(p=0.5),\n","            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n","            A.GaussNoise(p=0.5),\n","            A.Rotate(limit=30, p=0.5),\n","            A.RandomScale(scale_limit=0.2, p=0.5),\n","            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n","            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5)\n","        ])\n","\n","        self.class_counts = self._compute_initial_class_counts()\n","        self.augmented_class_counts = self.class_counts.copy()\n","        self.class_weights = None  # Khởi tạo trọng số lớp là None\n","\n","        if self.is_train and balance_classes:\n","            self.balance_classes()\n","\n","        if self.is_train:\n","            self.on_epoch_end()\n","\n","    def _compute_initial_class_counts(self):\n","        labels = np.argmax(self.labels, axis=1) if self.labels.ndim > 1 else self.labels\n","        return np.bincount(labels, minlength=self.n_classes)\n","\n","    def _compute_class_weights(self):\n","        total_samples = np.sum(self.augmented_class_counts)\n","        if total_samples == 0:\n","            return np.ones(self.n_classes)\n","        class_weights = total_samples / (self.n_classes * self.augmented_class_counts)\n","        class_weights = np.where(np.isinf(class_weights) | (self.augmented_class_counts == 0), 1.0, class_weights)\n","        return class_weights / np.min(class_weights[np.isfinite(class_weights)])\n","\n","    def get_class_weights(self):\n","        \"\"\"Trả về trọng số lớp hiện tại để sử dụng trong huấn luyện.\"\"\"\n","        return self.class_weights\n","\n","    def balance_classes(self):\n","        class_counts = self._compute_initial_class_counts()\n","        max_count = class_counts[0]  # Sử dụng số lượng mẫu của lớp 0 làm mục tiêu\n","\n","        print(f\"Số lượng mẫu ban đầu: {class_counts}\")\n","        print(f\"Số lượng mẫu mục tiêu cho mỗi lớp (dựa trên lớp 0): {max_count}\")\n","\n","        new_filenames = []\n","        new_labels = []\n","        for cls in range(self.n_classes):\n","            current_count = class_counts[cls]\n","            if current_count == 0:\n","                print(f\"Lớp {cls} không có mẫu, bỏ qua.\")\n","                continue\n","            if cls == 3:\n","                target_count = int(max_count * 1.3)  # Lớp 3 được tăng thêm 30%\n","            else:\n","                target_count = max_count\n","            if current_count < target_count:\n","                samples_to_add = target_count - current_count\n","                label_indices = np.argmax(self.labels, axis=1) if self.labels.ndim > 1 else self.labels\n","                class_indices = np.where(label_indices == cls)[0]\n","                for i in range(samples_to_add):\n","                    idx = np.random.choice(class_indices)\n","                    img_id = self.image_filenames[idx]\n","                    label = self.labels[idx]\n","                    img = self._load_image(img_id)\n","                    if img is None:\n","                        continue\n","                    aug_img = self.rare_augmenter(image=img)['image']\n","                    new_img_id = f\"{img_id}_balance_aug_{i}\"\n","                    save_path = os.path.join(self.base_path, f\"{new_img_id}.png\")\n","                    if cv2.imwrite(save_path, cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)):\n","                        new_filenames.append(new_img_id)\n","                        new_labels.append(np.array(label, dtype=self.labels.dtype))\n","                        self.augmented_class_counts[cls] += 1\n","                    else:\n","                        print(f\"Lỗi khi lưu ảnh tăng cường {new_img_id}\")\n","\n","        if new_labels:\n","            new_labels_array = np.array(new_labels)\n","            if new_labels_array.ndim == 1:\n","                new_labels_array = new_labels_array[:, np.newaxis]\n","            self.image_filenames = np.concatenate([self.image_filenames, new_filenames])\n","            self.labels = np.concatenate([self.labels, new_labels_array])\n","\n","        # Không gọi on_epoch_end() ở đây để tránh tính trọng số lớp ngay lập tức\n","\n","        # Kiểm tra số lượng mẫu sau khi cân bằng\n","        updated_counts = self._compute_initial_class_counts()\n","        print(f\"Số lượng mẫu sau khi cân bằng và tăng lớp 3: {updated_counts}\")\n","\n","    def augment_weak_classes(self, weak_classes, augment_factor=2):\n","        new_filenames = []\n","        new_labels = []\n","        for idx, label in enumerate(self.labels):\n","            label_class = np.argmax(label) if label.ndim > 1 else label\n","            if np.isscalar(label_class) and np.isin(label_class, weak_classes):\n","                img_id = self.image_filenames[idx]\n","                img = self._load_image(img_id)\n","                if img is None:\n","                    continue\n","                for i in range(augment_factor):\n","                    aug_img = self.rare_augmenter(image=img)['image']\n","                    new_img_id = f\"{img_id}_weak_aug_{i}\"\n","                    save_path = os.path.join(self.base_path, f\"{new_img_id}.png\")\n","                    if cv2.imwrite(save_path, cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)):\n","                        new_filenames.append(new_img_id)\n","                        new_labels.append(np.array(label, dtype=self.labels.dtype))\n","                        self.augmented_class_counts[label_class] += 1\n","                    else:\n","                        print(f\"Lỗi khi lưu ảnh tăng cường {new_img_id}\")\n","        if new_labels:\n","            new_labels_array = np.array(new_labels)\n","            if new_labels_array.ndim == 1:\n","                new_labels_array = new_labels_array[:, np.newaxis]\n","            self.image_filenames = np.concatenate([self.image_filenames, new_filenames])\n","            self.labels = np.concatenate([self.labels, new_labels_array])\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n","\n","    def __getitem__(self, idx):\n","        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n","        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n","        return self._generate_batch(batch_x, batch_y, augment=self.is_train)\n","\n","    def on_epoch_end(self):\n","        if self.is_train:\n","            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n","            # Tính trọng số lớp vào cuối mỗi epoch\n","            self.class_weights = self._compute_class_weights()\n","            print(f\"Trọng số lớp sau epoch: {self.class_weights}\")\n","            print(f\"Số lượng mẫu tăng cường: {self.augmented_class_counts}\")\n","\n","    def _load_image(self, img_id):\n","        img_path = os.path.join(self.base_path, f\"{img_id}.png\")\n","        try:\n","            img = cv2.imread(img_path)\n","            if img is None:\n","                raise ValueError(f\"Hình ảnh không tìm thấy hoặc bị hỏng: {img_path}\")\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            img = cv2.resize(img, self.target_size)\n","            return img\n","        except Exception as e:\n","            print(f\"Lỗi khi tải hình ảnh {img_id}: {str(e)}\")\n","            return None\n","\n","    def _generate_batch(self, batch_x, batch_y, augment=False):\n","        batch_images = []\n","        valid_labels = []\n","\n","        for img_id, label in zip(batch_x, batch_y):\n","            img = self._load_image(img_id)\n","            if img is None:\n","                continue\n","            if augment and self.is_augment:\n","                img = self.augmenter(image=img.astype(np.uint8))['image']\n","            img = img.astype(np.float32) / 255.0\n","\n","            if \"resnet50\" in self.model_type:\n","                img = resnet50_preprocess(img)\n","            elif \"efficientnetb0\" in self.model_type:\n","                img = efficientnet_preprocess(img)\n","            elif \"inceptionv3\" in self.model_type:\n","                img = inception_preprocess(img)\n","            elif \"densenet121\" in self.model_type:\n","                img = densenet_preprocess(img)\n","            elif \"xception\" in self.model_type:\n","                img = xception_preprocess(img)\n","\n","            batch_images.append(img)\n","            valid_labels.append(label)\n","\n","        if not batch_images:\n","            return np.zeros((1, *self.target_size, 3), dtype=np.float32), np.zeros((1, *batch_y.shape[1:]), dtype=np.float32)\n","\n","        batch_images = np.array(batch_images)\n","        valid_labels = np.array(valid_labels)\n","\n","        if self.is_mix and len(batch_images) > 1:\n","            batch_images, valid_labels = self._mixup(batch_images, valid_labels)\n","\n","        return batch_images, valid_labels\n","\n","    def _mixup(self, x, y):\n","        lam = np.random.beta(0.2, 0.4)\n","        index = np.random.permutation(len(x))\n","        mixed_x = np.zeros_like(x)\n","        mixed_y = np.zeros_like(y)\n","        for i in range(len(x)):\n","            if np.argmax(y[i]) == np.argmax(y[index[i]]):\n","                mixed_x[i] = lam * x[i] + (1 - lam) * x[index[i]]\n","                mixed_y[i] = y[i]\n","            else:\n","                mixed_x[i] = x[i]\n","                mixed_y[i] = y[i]\n","        return mixed_x, mixed_y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34tqm68_2YC_"},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential, load_model\n","from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n","                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)\n","\n","from keras.applications.resnet50 import ResNet50\n","from keras.applications import EfficientNetB0\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.applications.densenet import DenseNet121\n","from keras.applications.xception import Xception  # 🔄 Thay MobileNetV2 bằng Xception\n","\n","from keras.callbacks import ModelCheckpoint\n","from keras import metrics\n","from keras.optimizers import Adam\n","from keras import backend as K\n","import keras\n","from keras.models import Model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-W9xFeWB2YC_"},"outputs":[],"source":["def create_model(input_shape, n_out, model_type, weights_path=None, weights=\"imagenet\"):\n","    input_tensor = Input(shape=input_shape)\n","\n","    # Khởi tạo mô hình với weights hoặc weights_path\n","    if model_type == \"resnet50\":\n","        base_model = ResNet50(include_top=False, weights=weights if not weights_path else None, input_tensor=input_tensor)\n","    elif model_type == \"efficientnetb0\":\n","        base_model = EfficientNetB0(include_top=False, weights=weights if not weights_path else None, input_tensor=input_tensor)\n","    elif model_type == \"inceptionv3\":\n","        base_model = InceptionV3(include_top=False, weights=weights if not weights_path else None, input_tensor=input_tensor)\n","    elif model_type == \"densenet121\":\n","        base_model = DenseNet121(include_top=False, weights=weights if not weights_path else None, input_tensor=input_tensor)\n","    elif model_type == \"xception\":  # Đổi từ \"mobilenetv2\" thành \"xception\"\n","        base_model = Xception(include_top=False, weights=weights if not weights_path else None, input_tensor=input_tensor)\n","\n","    else:\n","        raise ValueError(f\"Unsupported model type: {model_type}\")\n","\n","    # Nếu có weights_path, tải trọng số từ file\n","    if weights_path:\n","        try:\n","            base_model.load_weights(weights_path)\n","            print(f\"Loaded weights from {weights_path}\")\n","        except Exception as e:\n","            print(f\"Error loading weights from {weights_path}: {e}\")\n","            raise\n","\n","    x = GlobalAveragePooling2D(name='global_avg_pool')(base_model.output)\n","    x = Dropout(0.5)(x)\n","    x = Dense(1024, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    final_output = Dense(n_out, activation=\"softmax\", name='final_output')(x)\n","\n","    model = Model(input_tensor, final_output)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ozVAHa0S2YC_"},"outputs":[],"source":["# Cấu hình mô hình\n","model_configs = {\n","    # \"xception\": {\n","    #     \"model_type\": \"xception\",\n","    #     \"weights\": \"imagenet\",\n","    #     \"save_path\": \"/content/drive/MyDrive/working/Xception_bestqwk.h5\"\n","    # },\n","    \"resnet50\": {\n","        \"model_type\": \"resnet50\",\n","        \"weights_path\": \"/content/drive/MyDrive/keras_weights/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n","        \"save_path\": \"/content/drive/MyDrive/working/ResNet50_bestqwk.h5\"\n","    },\n","    # \"efficientnetb0\": {\n","    #     \"model_type\": \"efficientnetb0\",\n","    #     \"weights\": \"imagenet\",\n","    #     \"save_path\": \"/content/drive/MyDrive/working/EfficientNetB1_bestqwk.h5\"\n","    # },\n","    # \"inceptionv3\": {\n","    #     \"model_type\": \"inceptionv3\",\n","    #     \"weights_path\": \"/content/drive/MyDrive/keras_weights/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n","    #     \"save_path\": \"/content/drive/MyDrive/working/InceptionV3_bestqwk.h5\"\n","    # },\n","    \"densenet121\": {\n","        \"model_type\": \"densenet121\",\n","        \"weights_path\": \"/content/drive/MyDrive/keras_weights/densenet121/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n","        \"save_path\": \"/content/drive/MyDrive/working/DenseNet121_bestqwk.h5\"\n","    }\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":41,"status":"error","timestamp":1748842223055,"user":{"displayName":"Resconnect","userId":"00882996269091038835"},"user_tz":-420},"id":"SgxCVgEY2YC_","outputId":"fc63e827-0a98-48b8-90c8-51f1a1be6a31"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'create_model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-be20847cfa99>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m'train_x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'valid_x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_x hoặc valid_x không được định nghĩa\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m'train_y'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'valid_y'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_y hoặc valid_y không được định nghĩa\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"create_model không phải là hàm\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m'My_Generator'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"My_Generator không được định nghĩa\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'create_model' is not defined"]}],"source":["from sklearn.metrics import f1_score, recall_score, cohen_kappa_score, confusion_matrix\n","from datetime import datetime\n","import json\n","import os\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tensorflow.keras.callbacks import EarlyStopping, Callback\n","from tensorflow.keras.losses import CategoricalCrossentropy\n","import shutil\n","from sklearn.utils import resample\n","import subprocess\n","\n","# Class QWKEvaluation\n","class QWKEvaluation(tf.keras.callbacks.Callback):\n","    def __init__(self, validation_data=(), batch_size=64, interval=1, model_type=None, save_paths=None):\n","        super().__init__()\n","        self.interval = interval\n","        self.batch_size = batch_size\n","        self.valid_generator, self.y_val = validation_data\n","        self.history = []\n","        self.model_type = model_type\n","        self.save_paths = save_paths if save_paths is not None else {}\n","        self.save_path = self.save_paths.get(model_type, None)\n","        self.best_qwk = -float('inf')\n","        self.best_y_true = None\n","        self.best_y_pred = None\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        if epoch % self.interval == 0:\n","            steps = int(np.ceil(len(self.y_val) / self.batch_size))\n","            y_pred = self.model.predict(self.valid_generator, steps=steps, verbose=1)\n","\n","            if len(self.y_val.shape) > 1 and self.y_val.shape[1] > 1:\n","                y_true = np.argmax(self.y_val, axis=1)\n","                y_pred_classes = np.argmax(y_pred, axis=1)\n","            else:\n","                y_true = self.y_val.astype(int)\n","                y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","            score = cohen_kappa_score(y_true, y_pred_classes, labels=[0, 1, 2, 3, 4], weights='quadratic')\n","            print(f\"\\nEpoch {epoch+1} - QWK: {score:.4f}\")\n","\n","            f1 = f1_score(y_true, y_pred_classes, average=None, labels=[0, 1, 2, 3, 4])\n","            sensitivity = recall_score(y_true, y_pred_classes, average=None, labels=[0, 1, 2, 3, 4])\n","            print(f\"F1-score per class: {f1}\")\n","            print(f\"Sensitivity per class: {sensitivity}\")\n","\n","            self.history.append(score)\n","\n","            if score > self.best_qwk:\n","                self.best_qwk = score\n","                self.best_y_true = y_true\n","                self.best_y_pred = y_pred_classes\n","                print(f\"New best QWK: {self.best_qwk:.4f} at Epoch {epoch+1}\")\n","\n","                if self.save_path:\n","                    keras_save_path = self.save_path.replace('.h5', '.keras')\n","                    save_dir = os.path.dirname(keras_save_path)\n","                    os.makedirs(save_dir, exist_ok=True)\n","\n","                    self.model.save(keras_save_path, overwrite=True)\n","                    print(f\"Saved (overwritten) full model to {keras_save_path}\")\n","\n","                    save_dir = self.save_path.replace('.h5', '')\n","                    os.makedirs(save_dir, exist_ok=True)\n","\n","                    model_json = self.model.to_json()\n","                    config_path = os.path.join(save_dir, \"config.json\")\n","                    with open(config_path, \"w\") as json_file:\n","                        json_file.write(model_json)\n","                    print(f\"Saved model architecture to {config_path}\")\n","\n","                    weights_path = os.path.join(save_dir, \"model.weights.h5\")\n","                    self.model.save_weights(weights_path)\n","                    print(f\"Saved model weights to {weights_path}\")\n","\n","                    metadata = {\n","                        \"keras_version\": tf.keras.__version__,\n","                        \"save_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n","                        \"model_type\": self.model_type\n","                    }\n","                    metadata_path = os.path.join(save_dir, \"metadata.json\")\n","                    with open(metadata_path, \"w\") as meta_file:\n","                        json.dump(metadata, meta_file)\n","                    print(f\"Saved metadata to {metadata_path}\")\n","\n","# Class QWKReduceLROnPlateau\n","class QWKReduceLROnPlateau(tf.keras.callbacks.Callback):\n","    def __init__(self, qwk_callback, factor=0.5, patience=3, min_lr=1e-6, verbose=1):\n","        super().__init__()\n","        self.qwk_callback = qwk_callback\n","        self.factor = factor\n","        self.patience = patience\n","        self.min_lr = min_lr\n","        self.verbose = verbose\n","        self.best_qwk = -float('inf')\n","        self.wait = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        current_qwk = self.qwk_callback.history[-1] if self.qwk_callback.history else -float('inf')\n","        if current_qwk > self.best_qwk:\n","            self.best_qwk = current_qwk\n","            self.wait = 0\n","        else:\n","            self.wait += 1\n","            if self.wait >= self.patience:\n","                old_lr = float(self.model.optimizer.learning_rate)\n","                if old_lr > self.min_lr:\n","                    new_lr = max(old_lr * self.factor, self.min_lr)\n","                    self.model.optimizer.learning_rate.assign(new_lr)\n","                    if self.verbose > 0:\n","                        print(f\"\\nEpoch {epoch+1}: QWKReduceLROnPlateau reducing learning rate to {new_lr:.6f}.\")\n","                    self.wait = 0\n","\n","# Class DynamicRareClassAugmentationCallback\n","class DynamicRareClassAugmentationCallback(Callback):\n","    def __init__(self, train_generator, valid_generator, valid_labels, threshold=0.6, augment_factor=2):\n","        super().__init__()\n","        self.train_generator = train_generator\n","        self.valid_generator = valid_generator\n","        self.valid_labels = valid_labels\n","        self.threshold = threshold\n","        self.augment_factor = augment_factor\n","        self.f1_history = []\n","        self.batch_size = self.train_generator.batch_size\n","        self.num_classes = self.train_generator.n_classes\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        steps = int(np.ceil(len(self.valid_labels) / self.batch_size))\n","        y_pred = self.model.predict(self.valid_generator, steps=steps, verbose=1)\n","        y_true = np.argmax(self.valid_labels, axis=1)\n","        y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","        f1_scores = f1_score(y_true, y_pred_classes, average=None, labels=list(range(self.num_classes)))\n","        print(f\"F1-scores at epoch {epoch+1}: {f1_scores}\")\n","\n","        self.f1_history.append(f1_scores)\n","\n","        weak_classes = [i for i, f1 in enumerate(f1_scores) if f1 < self.threshold]\n","        print(f\"Weak classes at epoch {epoch+1} (F1 < {self.threshold}): {weak_classes}\")\n","\n","        if weak_classes:\n","            self.train_generator.augment_weak_classes(weak_classes, augment_factor=self.augment_factor)\n","            print(f\"Augmented {self.augment_factor} samples for weak classes: {weak_classes}\")\n","\n","            self.train_generator.on_epoch_end()\n","            print(f\"Updated class weights: {self.train_generator.get_class_weights()}\")\n","\n","        if len(self.f1_history) > 1:\n","            prev_f1 = self.f1_history[-2]\n","            curr_f1 = self.f1_history[-1]\n","            print(f\"F1-score comparison (epoch {epoch} vs {epoch+1}):\")\n","            for i in range(self.num_classes):\n","                print(f\"Class {i}: {prev_f1[i]:.4f} -> {curr_f1[i]:.4f} (Change: {curr_f1[i] - prev_f1[i]:.4f})\")\n","\n","# Class để thu thập và vẽ loss\n","class LossHistoryCallback(Callback):\n","    def __init__(self):\n","        super().__init__()\n","        self.losses = []\n","        self.val_losses = []\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        self.losses.append(logs.get('loss'))\n","        self.val_losses.append(logs.get('val_loss'))\n","\n","    def plot_and_save_loss(self, model_type, save_dir=\"/content/drive/MyDrive/working/\"):\n","        plt.figure(figsize=(10, 6))\n","        plt.plot(self.losses, label='Training Loss', marker='o')\n","        plt.plot(self.val_losses, label='Validation Loss', marker='s')\n","        plt.title(f'Training and Validation Loss - {model_type}')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss')\n","        plt.legend()\n","        plt.grid(True)\n","\n","        os.makedirs(save_dir, exist_ok=True)\n","        save_path = os.path.join(save_dir, f'loss_plot_{model_type}.png')\n","        plt.savefig(save_path)\n","        plt.close()\n","        print(f\"Saved loss plot to {save_path}\")\n","\n","# Chuyển đổi nhãn\n","NUM_CLASSES = 5\n","SIZE = 244\n","if len(train_y.shape) == 1 or train_y.shape[1] != NUM_CLASSES:\n","    train_y_multi = tf.keras.utils.to_categorical(train_y, num_classes = NUM_CLASSES)\n","    valid_y_multi = tf.keras.utils.to_categorical(valid_y, num_classes = NUM_CLASSES)\n","else:\n","    train_y_multi = train_y\n","    valid_y_multi = valid_y\n","\n","batch_size = 64\n","resized_train_x = train_x.values\n","resized_valid_x = valid_x.values\n","\n","# Định nghĩa callback\n","early_stopping = EarlyStopping(monitor='accuracy', patience=7, restore_best_weights=True, verbose=1, mode='max')\n","\n","# Cấu hình mô hình\n","# Cấu hình mô hình\n","model_configs = {\n","    \"xception\": {\n","        \"model_type\": \"xception\",\n","        \"weights\": \"imagenet\",\n","        \"save_path\": \"/content/drive/MyDrive/working/Xception_bestqwk_aptos.h5\"\n","    },\n","    \"resnet50\": {\n","        \"model_type\": \"resnet50\",\n","        \"weights_path\": \"/content/drive/MyDrive/keras_weights/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n","        \"save_path\": \"/content/drive/MyDrive/working/ResNet50_bestqwk_aptos.h5\"\n","    },\n","    \"efficientnetb0\": {\n","        \"model_type\": \"efficientnetb0\",\n","        \"weights\": \"imagenet\",\n","        \"save_path\": \"/content/drive/MyDrive/working/EfficientNetB1_bestqwk_aptos.h5\"\n","    },\n","    \"inceptionv3\": {\n","        \"model_type\": \"inceptionv3\",\n","        \"weights_path\": \"/content/drive/MyDrive/keras_weights/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n","        \"save_path\": \"/content/drive/MyDrive/working/InceptionV3_bestqwk_aptos.h5\"\n","    },\n","    \"densenet121\": {\n","        \"model_type\": \"densenet121\",\n","        \"weights_path\": \"/content/drive/MyDrive/keras_weights/densenet121/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n","        \"save_path\": \"/content/drive/MyDrive/working/DenseNet121_bestqwk_aptos.h5\"\n","    }\n","}\n","\n","# Kiểm tra trước khi huấn luyện\n","assert 'train_x' in globals() and 'valid_x' in globals(), \"train_x hoặc valid_x không được định nghĩa\"\n","assert 'train_y' in globals() and 'valid_y' in globals(), \"train_y hoặc valid_y không được định nghĩa\"\n","assert callable(create_model), \"create_model không phải là hàm\"\n","assert 'My_Generator' in globals(), \"My_Generator không được định nghĩa\"\n","\n","# In thông tin dữ liệu để debug\n","print(\"train_y shape:\", train_y.shape)\n","print(\"valid_y shape:\", valid_y.shape)\n","print(\"train_y_multi shape:\", train_y_multi.shape)\n","print(\"valid_y_multi shape:\", valid_y_multi.shape)\n","\n","# Vòng lặp huấn luyện\n","for model_name, config in model_configs.items():\n","    print(f\"\\n==> Đang huấn luyện mô hình {model_name} ...\")\n","\n","    if config[\"model_type\"] == \"inceptionv3\":\n","        model_input_shape = (299, 299, 3)\n","        img_size = 299\n","    else:\n","        model_input_shape = (SIZE, SIZE, 3)\n","        img_size = SIZE\n","\n","    # Tạo generator với balance_classes\n","    train_generator = My_Generator(\n","        resized_train_x, train_y_multi, batch_size,\n","        is_train=True, mix=False, augment=True,\n","        size1=SIZE, size2=299, model_type=config[\"model_type\"],\n","        balance_classes=True\n","    )\n","\n","    # Kiểm tra số lượng mẫu\n","    try:\n","        print(f\"Số lượng mẫu: {train_generator.augmented_class_counts}\")\n","    except AttributeError:\n","        print(\"Không truy cập được augmented_class_counts, tiếp tục huấn luyện...\")\n","\n","    valid_generator = My_Generator(\n","        resized_valid_x, valid_y_multi, batch_size,\n","        is_train=False, size1=SIZE, size2=299, model_type=config[\"model_type\"]\n","    )\n","\n","    # Lấy trọng số lớp ban đầu (sẽ được cập nhật sau mỗi epoch)\n","    class_weights = train_generator.get_class_weights()\n","    if class_weights is None:\n","        class_weights = np.ones(NUM_CLASSES)  # Mặc định nếu chưa tính\n","    class_weight = {i: float(w) for i, w in enumerate(class_weights)}\n","    print(f\"Trọng số lớp ban đầu: {class_weight}\")\n","\n","    # Tạo mô hình\n","    weights_path = config.get(\"weights_path\", None)\n","    pretrained_weights = config.get(\"weights\", \"imagenet\")\n","    model = create_model(\n","        input_shape=model_input_shape,\n","        n_out=NUM_CLASSES,\n","        model_type=config[\"model_type\"],\n","        weights_path=weights_path,\n","        weights=pretrained_weights\n","    )\n","\n","    # Khởi tạo QWKEvaluation\n","    qwk_callback = QWKEvaluation(\n","        validation_data=(valid_generator, valid_y_multi),\n","        batch_size=batch_size,\n","        interval=1,\n","        model_type=config[\"model_type\"],\n","        save_paths={config[\"model_type\"]: config[\"save_path\"]}\n","    )\n","\n","    # Khởi tạo QWKReduceLROnPlateau\n","    qwk_reduce_lr = QWKReduceLROnPlateau(\n","        qwk_callback=qwk_callback,\n","        factor=0.5,\n","        patience=3,\n","        min_lr=1e-6,\n","        verbose=1\n","    )\n","\n","    # Khởi tạo LossHistoryCallback\n","    loss_history = LossHistoryCallback()\n","\n","    # Giai đoạn khởi động (warm-up) - KHÔNG dùng class_weight\n","    for layer in model.layers[:50]:\n","        layer.trainable = False\n","    for layer in model.layers[50:]:\n","        layer.trainable = True\n","\n","    # Sử dụng CategoricalCrossentropy với label smoothing\n","    loss_fn = CategoricalCrossentropy(label_smoothing=0.1)\n","    model.compile(\n","        loss=loss_fn,\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n","        metrics=['accuracy']\n","    )\n","\n","    augment_callback = DynamicRareClassAugmentationCallback(\n","        train_generator=train_generator,\n","        valid_generator=valid_generator,\n","        valid_labels=valid_y_multi,\n","        threshold=0.6,\n","        augment_factor=2\n","    )\n","\n","    # Huấn luyện khởi động (Không áp dụng class_weight)\n","    model.fit(\n","        train_generator,\n","        steps_per_epoch=int(np.ceil(len(train_generator.image_filenames) / batch_size)),\n","        epochs=5,\n","        validation_data=valid_generator,\n","        validation_steps=int(np.ceil(len(valid_x) / batch_size)),\n","        verbose=1,\n","        callbacks=[qwk_callback, qwk_reduce_lr, early_stopping, augment_callback, loss_history]\n","    )\n","\n","    # Huấn luyện đầy đủ\n","    for layer in model.layers:\n","        layer.trainable = True\n","\n","    model.compile(\n","        loss=CategoricalCrossentropy(label_smoothing=0.1),\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n","        metrics=['accuracy']\n","    )\n","\n","    train_mixup = My_Generator(\n","        resized_train_x, train_y_multi, batch_size,\n","        is_train=True, mix=True, augment=True,\n","        size1=SIZE, size2=299, model_type=config[\"model_type\"],\n","        balance_classes=True\n","    )\n","\n","    # Kiểm tra số lượng mẫu\n","    try:\n","        print(f\"Số lượng mẫu (mixup): {train_mixup.augmented_class_counts}\")\n","    except AttributeError:\n","        print(\"Không truy cập được augmented_class_counts (mixup), tiếp tục huấn luyện...\")\n","\n","    augment_callback = DynamicRareClassAugmentationCallback(\n","        train_generator=train_mixup,\n","        valid_generator=valid_generator,\n","        valid_labels=valid_y_multi,\n","        threshold=0.6,\n","        augment_factor=2\n","    )\n","\n","    # Huấn luyện đầy đủ với vòng lặp epoch để cập nhật class_weight\n","    epochs = 30\n","    for epoch in range(epochs):\n","        print(f\"\\nBắt đầu epoch {epoch + 1} cho mô hình {model_name}\")\n","        # Lấy trọng số lớp cho epoch hiện tại\n","        class_weights = train_mixup.get_class_weights()\n","        if class_weights is None:\n","            class_weights = np.ones(NUM_CLASSES)  # Mặc định nếu chưa tính\n","        class_weight = {i: float(w) for i, w in enumerate(class_weights)}\n","        print(f\"Trọng số lớp cho epoch {epoch + 1}: {class_weight}\")\n","\n","        # Huấn luyện một epoch (Áp dụng class_weight)\n","        model.fit(\n","            train_mixup,\n","            steps_per_epoch=int(np.ceil(len(train_mixup.image_filenames) / batch_size)),\n","            epochs=1,  # Huấn luyện từng epoch\n","            validation_data=valid_generator,\n","            validation_steps=int(np.ceil(len(valid_x) / batch_size)),\n","            verbose=1,\n","            callbacks=[qwk_callback, qwk_reduce_lr, augment_callback, early_stopping, loss_history],\n","            class_weight=class_weight  # Áp dụng class_weight\n","        )\n","\n","    # Lưu mô hình cuối cùng\n","    final_save_path = config[\"save_path\"].replace('.h5', '_final.keras')\n","    model.save(final_save_path, overwrite=True)\n","    print(f\"Đã lưu mô hình cuối cùng tại {final_save_path}\")\n","\n","    # Vẽ và lưu biểu đồ loss\n","    loss_history.plot_and_save_loss(config[\"model_type\"], save_dir=\"/content/drive/MyDrive/working/\")\n","\n","    # Vẽ và lưu biểu đồ ma trận nhầm lẫn tốt nhất cho mô hình này\n","    if qwk_callback.best_y_true is not None and qwk_callback.best_y_pred is not None:\n","        cm = confusion_matrix(qwk_callback.best_y_true, qwk_callback.best_y_pred, labels=[0, 1, 2, 3, 4])\n","        plt.figure(figsize=(8, 6))\n","        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                    xticklabels=[0, 1, 2, 3, 4],\n","                    yticklabels=[0, 1, 2, 3, 4])\n","        plt.title(f'Best Confusion Matrix - QWK: {qwk_callback.best_qwk:.4f} ({config[\"model_type\"]})')\n","        plt.xlabel('Predicted')\n","        plt.ylabel('True')\n","        save_cm_path = f\"/content/drive/MyDrive/working/best_confusion_matrix_{config['model_type']}.png\"\n","        plt.savefig(save_cm_path)\n","        plt.close()  # Đóng figure để tránh chiếm bộ nhớ\n","        print(f\"Saved best confusion matrix to {save_cm_path}\")\n","    else:\n","        print(f\"Không có best QWK được ghi nhận cho mô hình {config['model_type']}, không vẽ biểu đồ.\")\n","\n","    #TEST\n","    import numpy as np\n","    import tensorflow as tf\n","    import seaborn as sns\n","    import matplotlib.pyplot as plt\n","    from sklearn.metrics import cohen_kappa_score, f1_score, recall_score, precision_score, accuracy_score, confusion_matrix\n","\n","    # ... (Giả sử các biến như model, test_x, test_y, batch_size, NUM_CLASSES, config, My_Generator đã được định nghĩa trước đó)\n","\n","    print(f\"\\n==> Đang kiểm tra mô hình {model_name} trên tập test ...\")\n","\n","    # Chuyển nhãn test_y sang dạng one-hot nếu cần\n","    if len(test_y.shape) == 1 or test_y.shape[1] != NUM_CLASSES:\n","        test_y_multi = tf.keras.utils.to_categorical(test_y, num_classes=NUM_CLASSES)\n","    else:\n","        test_y_multi = test_y\n","\n","    # Tạo generator cho tập test\n","    test_generator = My_Generator(\n","        test_x.values, test_y_multi, batch_size,\n","        is_train=False, size1=SIZE, size2=299, model_type=config[\"model_type\"]\n","    )\n","\n","    # Dự đoán trên tập test\n","    steps_test = int(np.ceil(len(test_x) / batch_size))\n","    y_pred_test = model.predict(test_generator, steps=steps_test, verbose=1)\n","\n","    # Chuyển dự đoán và nhãn thật sang dạng lớp (class indices)\n","    y_true_test = np.argmax(test_y_multi, axis=1)\n","    y_pred_classes_test = np.argmax(y_pred_test, axis=1)\n","\n","    # Tính Quadratic Weighted Kappa (QWK)\n","    qwk_test = cohen_kappa_score(y_true_test, y_pred_classes_test, labels=[0, 1, 2, 3, 4], weights='quadratic')\n","    print(f\"QWK trên tập test: {qwk_test:.4f}\")\n","\n","    # Tính độ chính xác tổng thể (Accuracy)\n","    accuracy_test = accuracy_score(y_true_test, y_pred_classes_test)\n","    print(f\"Độ chính xác trên tập test: {accuracy_test:.4f}\")\n","\n","    # Tính F1-score và độ nhạy (Sensitivity/Recall) cho từng lớp\n","    f1_test = f1_score(y_true_test, y_pred_classes_test, average=None, labels=[0, 1, 2, 3, 4])\n","    sensitivity_test = recall_score(y_true_test, y_pred_classes_test, average=None, labels=[0, 1, 2, 3, 4])\n","    print(f\"F1-score cho từng lớp trên tập test: {[f'{f1:.4f}' for f1 in f1_test]}\")\n","    print(f\"Độ nhạy cho từng lớp trên tập test: {[f'{sens:.4f}' for sens in sensitivity_test]}\")\n","\n","    # Tính độ đặc hiệu (Specificity) cho từng lớp\n","    specificity_test = []\n","    cm = confusion_matrix(y_true_test, y_pred_classes_test, labels=[0, 1, 2, 3, 4])\n","    for cls in range(NUM_CLASSES):\n","        # Specificity = TN / (TN + FP)\n","        tn = np.sum(cm) - np.sum(cm[cls, :]) - np.sum(cm[:, cls]) + cm[cls, cls]\n","        fp = np.sum(cm[:, cls]) - cm[cls, cls]\n","        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n","        specificity_test.append(specificity)\n","    print(f\"Độ đặc hiệu cho từng lớp trên tập test: {[f'{spec:.4f}' for spec in specificity_test]}\")\n","\n","    # Tính độ chính xác (Precision) cho từng lớp\n","    precision_test = precision_score(y_true_test, y_pred_classes_test, average=None, labels=[0, 1, 2, 3, 4])\n","    print(f\"Độ chính xác cho từng lớp trên tập test: {[f'{prec:.4f}' for prec in precision_test]}\")\n","\n","    # Vẽ và lưu ma trận nhầm lẫn cho tập test\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=[0, 1, 2, 3, 4],\n","                yticklabels=[0, 1, 2, 3, 4])\n","    plt.title(f'Ma trận nhầm lẫn tập test - QWK: {qwk_test:.4f} ({config[\"model_type\"]})')\n","    plt.xlabel('Dự đoán')\n","    plt.ylabel('Thật')\n","    save_cm_test_path = f\"/content/drive/MyDrive/working/test_confusion_matrix_{config['model_type']}.png\"\n","    plt.savefig(save_cm_test_path)\n","    plt.close()\n","    print(f\"Đã lưu ma trận nhầm lẫn tập test tại {save_cm_test_path}\")"]},{"cell_type":"markdown","metadata":{"id":"F8ImhblXS1AO"},"source":["**Huấn luyện meta-learner**"]},{"cell_type":"markdown","source":[],"metadata":{"id":"PmKhX5uMYqQ-"}},{"cell_type":"markdown","metadata":{"id":"YuTdef73gE0e"},"source":["mẫu 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"LblX7kriIIs2","outputId":"ac86ac35-1839-46e9-f5ed-f120c875d53b","executionInfo":{"status":"error","timestamp":1749025283024,"user_tz":-420,"elapsed":253066,"user":{"displayName":"Resconnect","userId":"00882996269091038835"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Tìm thấy 3662 ID ảnh trong /content/processed_train_images\n","Mẫu ID: ['cb2f3c5d71a7', '5c6194562ed2', 'e893e86dde94', '58059e73d2d4', '8ee50c26fc13']...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'loss_scale_optimizer', because it has 436 variables whereas the saved optimizer has 432 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n","/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 432 variables whereas the saved optimizer has 0 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n","ERROR:root:Lỗi trong episode 1: 'NoneType' object has no attribute 'save_weights'\n","ERROR:root:Lỗi trong episode 2: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 550) + inhomogeneous part.\n","ERROR:root:Lỗi trong episode 3: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 550) + inhomogeneous part.\n","ERROR:root:Lỗi trong episode 4: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 550) + inhomogeneous part.\n","ERROR:root:Lỗi trong episode 5: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 550) + inhomogeneous part.\n","ERROR:root:Lỗi trong episode 6: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 550) + inhomogeneous part.\n","ERROR:root:Lỗi trong episode 7: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (2, 550) + inhomogeneous part.\n","ERROR:root:Lỗi trong episode 8: 'NoneType' object has no attribute 'save_weights'\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-6e4e0df9f6b7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2246\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m     \u001b[0;31m# Chạy pipeline với tùy chọn hyperparameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2248\u001b[0;31m     \u001b[0mtrain_features_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_features_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_hyperparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-6e4e0df9f6b7>\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(tune_hyperparameters, use_gpu)\u001b[0m\n\u001b[1;32m   2201\u001b[0m         \u001b[0;31m# Chạy pipeline chính\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chạy pipeline chính...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         pipeline_results = main_pipeline(\n\u001b[0m\u001b[1;32m   2204\u001b[0m             \u001b[0mbalanced_train_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m             \u001b[0mbalanced_train_y_multi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-6e4e0df9f6b7>\u001b[0m in \u001b[0;36mmain_pipeline\u001b[0;34m(balanced_train_x, balanced_train_y_multi, valid_images, valid_y_multi, test_images, test_y_multi, df_train_processed, train_ids, valid_ids, test_ids, balanced_train_ids, processed_image_ids)\u001b[0m\n\u001b[1;32m   2025\u001b[0m                 \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m             )\n\u001b[0;32m-> 2027\u001b[0;31m             meta_model, history = maml_fomaml_train_manual(\n\u001b[0m\u001b[1;32m   2028\u001b[0m                 \u001b[0mmeta_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m                 \u001b[0mdata_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train_processed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-6e4e0df9f6b7>\u001b[0m in \u001b[0;36mmaml_fomaml_train_manual\u001b[0;34m(meta_model, data_df, valid_features, valid_labels, valid_images, input_dim, model_type, n_episodes, inner_lr, outer_lr, fine_tune_lr, support_size, query_size, save_dir, sample_ids, callbacks)\u001b[0m\n\u001b[1;32m   1357\u001b[0m             \u001b[0;31m# Gọi callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"qwk\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqwk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m             \u001b[0;31m# Lưu confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-6e4e0df9f6b7>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0my_pred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    498\u001b[0m     ):\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# Create an iterator that yields batches of input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         epoch_iterator = TFEpochIterator(\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribute_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             dataset = self._distribute_strategy.experimental_distribute_dataset(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/array_data_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/array_data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             dataset = tf.data.Dataset.zip(\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             )\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensors\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_tensors_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_tensors_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/from_tensors_op.py\u001b[0m in \u001b[0;36m_from_tensors\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_from_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-private-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_TensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/from_tensors_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element, name)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     variant_tensor = gen_dataset_ops.tensor_dataset(\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moutput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_flat_tensor_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mtensor_dataset\u001b[0;34m(components, output_shapes, metadata, name)\u001b[0m\n\u001b[1;32m   7709\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7710\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7711\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   7712\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TensorDataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7713\u001b[0m         output_shapes, \"metadata\", metadata)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import tensorflow as tf\n","import logging\n","\n","# Cấu hình logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","# Cấu hình GPU trước khi TensorFlow khởi tạo\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if physical_devices:\n","    for device in physical_devices:\n","        try:\n","            tf.config.experimental.set_memory_growth(device, True)\n","            logging.info(f\"Đã bật memory growth cho {device}\")\n","        except Exception as e:\n","            logging.error(f\"Lỗi khi cài đặt memory growth cho {device}: {str(e)}\")\n","\n","import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import cohen_kappa_score, confusion_matrix, f1_score, recall_score, classification_report, roc_curve, auc, precision_recall_curve\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.utils import shuffle\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import EfficientNetB1, Xception, InceptionV3, ResNet50, DenseNet121\n","from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n","from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess\n","from tensorflow.keras.applications.inception_v3 import preprocess_input as inceptionv3_preprocess\n","from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n","from tensorflow.keras.applications.densenet import preprocess_input as densenet121_preprocess\n","from tensorflow.keras.layers import Layer, Input, Conv2D, BatchNormalization, GlobalAveragePooling2D, Dense, Dropout\n","from tensorflow.keras.models import Model, model_from_json  # Thêm model_from_json\n","from tensorflow.keras.callbacks import Callback\n","from pathlib import Path\n","import os\n","import gc\n","import psutil\n","import logging\n","import cv2\n","import json\n","import time\n","import random\n","from itertools import product\n","from sklearn.calibration import calibration_curve\n","from datetime import datetime\n","import albumentations as A\n","import GPUtil\n","\n","# Thiết lập logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","logging.info(f\"Pipeline khởi động lúc: {datetime.now().strftime('%H:%M %p %z, %d/%m/%Y')}\")\n","\n","# Tham số cố định\n","FEATURE_SAVE_DIR = \"/content/drive/MyDrive/working\"\n","PROCESSED_FOLDER = \"/content/processed_train_images\"\n","TEMP_AUGMENT_DIR = \"/content/temp_augment\"\n","DRIVE_FOLDER = \"/content/drive/MyDrive/kaggle_data/aptos2019\"\n","SIZE = 244\n","NUM_CLASSES = 5\n","BATCH_SIZE = 16\n","SUPPORT_SET_SIZE = 10\n","QUERY_SET_SIZE = 10\n","\n","# Định nghĩa model_configs\n","MODEL_CONFIGS = {\n","    \"efficientnetb1\": {\n","        \"model_type\": \"efficientnetb1\",\n","        \"config_path\": \"/content/drive/MyDrive/working/EfficientNetB1_bestqwk_aptos/config.json\",\n","        \"weights_path\": \"/content/drive/MyDrive/working/EfficientNetB1_bestqwk_aptos/model.weights.h5\",\n","        \"preprocess\": efficientnet_preprocess,\n","        \"img_size\": 244,  # Sửa từ 244 thành 224\n","        \"base_model\": EfficientNetB1\n","    },\n","    \"xception\": {\n","        \"model_type\": \"xception\",\n","        \"config_path\": \"/content/drive/MyDrive/working/Xception_bestqwk_aptos/config.json\",\n","        \"weights_path\": \"/content/drive/MyDrive/working/Xception_bestqwk_aptos/model.weights.h5\",\n","        \"preprocess\": xception_preprocess,\n","        \"img_size\": 244,\n","        \"base_model\": Xception\n","    },\n","    \"inceptionv3\": {\n","        \"model_type\": \"inceptionv3\",\n","        \"config_path\": \"/content/drive/MyDrive/working/InceptionV3_bestqwk_aptos/config.json\",\n","        \"weights_path\": \"/content/drive/MyDrive/working/InceptionV3_bestqwk_aptos/model.weights.h5\",\n","        \"preprocess\": inceptionv3_preprocess,\n","        \"img_size\": 299,\n","        \"base_model\": InceptionV3\n","    },\n","    \"resnet50\": {\n","        \"model_type\": \"resnet50\",\n","        \"config_path\": \"/content/drive/MyDrive/working/ResNet50_bestqwk_aptos/config.json\",\n","        \"weights_path\": \"/content/drive/MyDrive/working/ResNet50_bestqwk_aptos/model.weights.h5\",\n","        \"preprocess\": resnet50_preprocess,\n","        \"img_size\": 244,\n","        \"base_model\": ResNet50\n","    },\n","    \"densenet121\": {\n","        \"model_type\": \"densenet121\",\n","        \"config_path\": \"/content/drive/MyDrive/working/DenseNet121_bestqwk_aptos/config.json\",\n","        \"weights_path\": \"/content/drive/MyDrive/working/DenseNet121_bestqwk_aptos/model.weights.h5\",\n","        \"preprocess\": densenet121_preprocess,\n","        \"img_size\": 244,\n","        \"base_model\": DenseNet121\n","    }\n","}\n","\n","# Kiểm tra và mount Google Drive\n","from google.colab import drive\n","if not os.path.ismount('/content/drive'):\n","    drive.mount('/content/drive')\n","else:\n","    logging.info(\"Google Drive đã được mount.\")\n","\n","# Tạo thư mục lưu trữ\n","os.makedirs(FEATURE_SAVE_DIR, exist_ok=True)\n","os.makedirs(PROCESSED_FOLDER, exist_ok=True)\n","os.makedirs(TEMP_AUGMENT_DIR, exist_ok=True)\n","\n","def validate_model_configs(model_configs):\n","    for model_name, config in model_configs.items():\n","        config_path = config['config_path']\n","        weights_path = config['weights_path']\n","        if not os.path.exists(config_path):\n","            logging.error(f\"Tệp cấu hình không tồn tại cho {model_name}: {config_path}\")\n","            raise FileNotFoundError(f\"Thiếu tệp cấu hình: {config_path}\")\n","        if not os.path.exists(weights_path):\n","            logging.error(f\"Tệp trọng số không tồn tại cho {model_name}: {weights_path}\")\n","            raise FileNotFoundError(f\"Thiếu tệp trọng số: {weights_path}\")\n","        logging.info(f\"Xác nhận tệp hợp lệ cho {model_name}: {config_path}, {weights_path}\")\n","\n","def load_model_from_config(config_path, weights_path, base_model_fn, input_shape):\n","    if not os.path.exists(config_path) or not os.path.exists(weights_path):\n","        logging.error(f\"Thiếu tệp: config={config_path}, weights={weights_path}\")\n","        raise FileNotFoundError(\"Thiếu tệp cấu hình hoặc trọng số\")\n","    try:\n","        with open(config_path, 'r') as f:\n","            model_config = json.load(f)\n","        model = model_from_json(json.dumps(model_config), custom_objects={\n","            'CustomGridDropout': CustomGridDropout,\n","            'MemoryAugmentedLayer': MemoryAugmentedLayer,\n","            'GradientReversalLayer': GradientReversalLayer\n","        })\n","        model.load_weights(weights_path, skip_mismatch=True)  # Bỏ by_name=True\n","        logging.info(f\"Đã tải trọng số từ {weights_path}\")\n","    except Exception as e:\n","        logging.warning(f\"Không tải được mô hình: {str(e)}. Khởi tạo với trọng số ImageNet...\")\n","        model = base_model_fn(include_top=False, weights='imagenet', input_shape=input_shape)\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","    return model\n","\n","# Hàm tải mô hình từ config\n","def load_processed_image(image_id, processed_folder, model_type):\n","    try:\n","        if model_type not in MODEL_CONFIGS:\n","            logging.error(f\"model_type không hợp lệ: {model_type}\")\n","            raise ValueError(f\"model_type không hợp lệ: {model_type}\")\n","        target_size = MODEL_CONFIGS[model_type]['img_size']\n","        img_path = os.path.join(processed_folder, f\"{image_id}.png\")\n","        if not os.path.exists(img_path):\n","            logging.error(f\"Ảnh không tồn tại: {img_path}\")\n","            return None\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            logging.error(f\"Không đọc được ảnh: {img_path}\")\n","            return None\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (target_size, target_size), interpolation=cv2.INTER_AREA)\n","        if img.shape != (target_size, target_size, 3):\n","            logging.error(f\"Shape ảnh không đúng: {img.shape}, kỳ vọng: ({target_size}, {target_size}, 3)\")\n","            return None\n","        img = img.astype(np.float32) / 255.0  # Chuẩn hóa\n","        logging.debug(f\"Đã tải ảnh {image_id} cho {model_type}: shape={img.shape}\")\n","        return img\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi tải ảnh {image_id} cho {model_type}: {str(e)}\")\n","        return None\n","# Custom layers\n","class CustomGridDropout(Layer):\n","    def __init__(self, ratio=0.3, holes_number=4, p=0.5, **kwargs):\n","        super().__init__(**kwargs)\n","        self.ratio = ratio\n","        self.holes_number = holes_number\n","        self.p = p\n","\n","    def call(self, inputs, training=None):\n","        if not training:\n","            return inputs\n","        inputs = tf.cast(inputs, tf.float16)  # Ép kiểu sang float16\n","        batch_size = tf.shape(inputs)[0]\n","        height = tf.shape(inputs)[1]\n","        width = tf.shape(inputs)[2]\n","        channels = tf.shape(inputs)[3]\n","\n","        hole_height = tf.maximum(1, tf.cast(tf.cast(height, tf.float32) * self.ratio, tf.int32))\n","        hole_width = tf.maximum(1, tf.cast(tf.cast(width, tf.float32) * self.ratio, tf.int32))\n","\n","        mask = tf.ones_like(inputs, dtype=tf.float16)  # Sử dụng float16\n","        random_probs = tf.random.uniform([self.holes_number], 0, 1)\n","        active_holes = tf.cast(random_probs < self.p, tf.int32)\n","\n","        all_indices = []\n","        for i in range(self.holes_number):\n","            should_apply = active_holes[i]\n","            indices = tf.cond(\n","                should_apply > 0,\n","                lambda: self._generate_patch_indices(\n","                    batch_size, height, width, channels, hole_height, hole_width, i\n","                ),\n","                lambda: tf.zeros([0, 4], dtype=tf.int32)\n","            )\n","            all_indices.append(indices)\n","\n","        all_indices = tf.concat(all_indices, axis=0)\n","        updates = tf.zeros([tf.shape(all_indices)[0]], dtype=tf.float16)\n","\n","        if tf.shape(all_indices)[0] > 0:\n","            mask = tf.tensor_scatter_nd_update(mask, all_indices, updates)\n","\n","        return tf.cast(inputs * mask, tf.float16)  # Đảm bảo đầu ra là float16\n","\n","    def _generate_patch_indices(self, batch_size, height, width, channels, hole_height, hole_width, hole_idx):\n","        h_start = tf.random.uniform([], 0, height - hole_height + 1, dtype=tf.int32)\n","        w_start = tf.random.uniform([], 0, width - hole_width + 1, dtype=tf.int32)\n","\n","        h_indices = tf.range(h_start, h_start + hole_height)\n","        w_indices = tf.range(w_start, w_start + hole_width)\n","        c_indices = tf.range(channels)\n","\n","        batch_indices = tf.tile(tf.range(batch_size), [hole_height * hole_width * channels])\n","        h_grid, w_grid, c_grid = tf.meshgrid(h_indices, w_indices, c_indices, indexing='ij')\n","        h_grid = tf.reshape(h_grid, [-1])\n","        w_grid = tf.reshape(w_grid, [-1])\n","        c_grid = tf.reshape(c_grid, [-1])\n","\n","        h_indices = tf.tile(h_grid, [batch_size])\n","        w_indices = tf.tile(w_grid, [batch_size])\n","        c_indices = tf.tile(c_grid, [batch_size])\n","\n","        indices = tf.stack([batch_indices, h_indices, w_indices, c_indices], axis=1)\n","        return indices\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\"ratio\": self.ratio, \"holes_number\": self.holes_number, \"p\": self.p})\n","        return config\n","\n","class MemoryAugmentedLayer(Layer):\n","    def __init__(self, memory_size, memory_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.memory_size = memory_size\n","        self.memory_dim = memory_dim\n","        self.memory = self.add_weight(\n","            shape=(memory_size, memory_dim),\n","            initializer='random_normal',\n","            trainable=True,\n","            name='memory'\n","        )\n","\n","    def call(self, inputs):\n","        # Placeholder: Trả về inputs mà không thay đổi\n","        # Thay thế bằng triển khai thực tế của bạn\n","        return inputs\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\"memory_size\": self.memory_size, \"memory_dim\": self.memory_dim})\n","        return config\n","\n","def check_memory():\n","    try:\n","        memory_info = psutil.virtual_memory()\n","        logging.info(f\"Memory usage: Total={memory_info.total / (1024 ** 3):.2f} GB, \"\n","                     f\"Used={memory_info.used / (1024 ** 3):.2f} GB, \"\n","                     f\"Free={memory_info.available / (1024 ** 3):.2f} GB, \"\n","                     f\"Percent={memory_info.percent}%\")\n","\n","        # Check GPU memory usage\n","        try:\n","            gpus = GPUtil.getGPUs()\n","            for gpu in gpus:\n","                logging.info(f\"GPU {gpu.id}: {gpu.name}, \"\n","                            f\"Memory Used={gpu.memoryUsed / 1024:.2f} GB, \"\n","                            f\"Memory Total={gpu.memoryTotal / 1024:.2f} GB, \"\n","                            f\"Utilization={gpu.memoryUtil * 100:.2f}%\")\n","        except:\n","            logging.warning(f\"Failed to get GPU memory information\")\n","\n","        # Perform garbage collection\n","        gc.collect()\n","\n","        # Warn if memory usage is high\n","        memory_threshold = 1024  # Threshold in MB\n","        if memory_info.available < memory_threshold:\n","            logging.warning(f\"Low memory detected: {memory_info.available / (1024 ** 3):.2f} GB available\")\n","            tf.keras.backend.clear_session()\n","\n","            # Free GPU memory\n","            try:\n","                tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n","            except:\n","                logging.warning(f\"Failed to set memory growth\")\n","\n","        return memory_info.available / (1024 ** 3)  # Return available memory in GB\n","\n","    except Exception as e:\n","        logging.error(f\"Error checking memory: {str(e)}\")\n","        return None\n","\n","class GradientReversalLayer(Layer):\n","    def __init__(self, lambda_=1.0, **kwargs):\n","        super().__init__(**kwargs)\n","        self.lambda_ = lambda_\n","\n","    def call(self, inputs, training=None):\n","        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n","        return inputs if not training else tf.math.multiply(-self.lambda_, inputs)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\"lambda_\": self.lambda_})\n","        return config\n","\n","# Hàm random erasing tùy chỉnh\n","def custom_random_erasing(image, scale=(0.01, 0.05), ratio=(0.5, 2.0), p=0.3, value=None):\n","    if np.random.random() > p:\n","        return image\n","    height, width, channels = image.shape\n","    area = height * width\n","    scale_factor = np.random.uniform(scale[0], scale[1])\n","    erase_area = area * scale_factor\n","    aspect_ratio = np.random.uniform(ratio[0], ratio[1])\n","    erase_height = int(np.sqrt(erase_area / aspect_ratio))\n","    erase_width = int(np.sqrt(erase_area * aspect_ratio))\n","    erase_height = min(erase_height, height)\n","    erase_width = min(erase_width, width)\n","    if erase_height < 1 or erase_width < 1:\n","        return image\n","    x = np.random.randint(0, width - erase_width + 1)\n","    y = np.random.randint(0, height - erase_height + 1)\n","    output = image.copy()\n","    if value is None:\n","        value = np.mean(image, axis=(0, 1))\n","    output[y:y+erase_height, x:x+erase_width, :] = value\n","    return output\n","\n","\n","# Hàm cân bằng và tăng cường dữ liệu\n","def balance_data(images, labels, target_classes=[0, 1, 2, 3, 4]):\n","    if not isinstance(target_classes, (list, np.ndarray)):\n","        raise TypeError(f\"target_classes must be list or numpy array, got: {type(target_classes)}\")\n","\n","    num_classes = labels.shape[1]\n","    label_indices = np.argmax(labels, axis=1)\n","\n","    # Filter samples belonging to target_classes\n","    keep_indices = np.isin(label_indices, target_classes)\n","    filtered_images = images[keep_indices]\n","    filtered_labels = labels[keep_indices]\n","    filtered_label_indices = label_indices[keep_indices]\n","\n","    # Count samples per class\n","    class_counts = np.bincount(filtered_label_indices, minlength=num_classes)\n","    logging.info(f\"Initial label distribution: {dict(zip(range(num_classes), class_counts))}\")\n","\n","    # Target ~7148 samples (~1430 per class)\n","    total_samples = 7148\n","    base_samples_per_class = total_samples // len(target_classes)  # 1429\n","    extra_samples = total_samples % len(target_classes)  # 3\n","    samples_per_class = [base_samples_per_class] * len(target_classes)\n","    for i in range(extra_samples):\n","        samples_per_class[i] += 1\n","    logging.info(f\"Target samples per class: {dict(zip(target_classes, samples_per_class))}\")\n","\n","    new_images = []\n","    new_labels = []\n","\n","    for cls_idx, cls in enumerate(target_classes):\n","        cls_indices = np.where(filtered_label_indices == cls)[0]\n","        cls_images = filtered_images[cls_indices]\n","        cls_labels = filtered_labels[cls_indices]\n","        current_count = len(cls_indices)\n","        target_count = samples_per_class[cls_idx]\n","\n","        logging.info(f\"Class {cls}: {current_count} initial samples, target {target_count} samples\")\n","\n","        # Add all available samples\n","        new_images.extend(cls_images)\n","        new_labels.extend(cls_labels)\n","\n","        # Oversample if needed\n","        if current_count < target_count:\n","            oversample_count = target_count - current_count\n","            logging.info(f\"Oversampling {oversample_count} samples for class {cls}\")\n","            # Randomly select indices with replacement\n","            oversample_indices = np.random.choice(cls_indices, size=oversample_count, replace=True)\n","            new_images.extend(filtered_images[oversample_indices])\n","            new_labels.extend(filtered_labels[oversample_indices])\n","\n","    new_images = np.array(new_images, dtype=np.float32)\n","    new_labels = np.array(new_labels, dtype=np.float32)\n","\n","    # Verify total samples\n","    if len(new_images) != total_samples:\n","        logging.error(f\"Sample count mismatch: got {len(new_images)}, expected {total_samples}\")\n","        raise ValueError(\"Sample count mismatch after balancing\")\n","\n","    new_images, new_labels = shuffle(new_images, new_labels, random_state=42)\n","\n","    final_class_counts = np.bincount(np.argmax(new_labels, axis=1), minlength=num_classes)\n","    logging.info(f\"Final label distribution: {dict(zip(range(num_classes), final_class_counts))}\")\n","\n","    return new_images, new_labels\n","\n","\n","class My_Generator(tf.keras.utils.Sequence):\n","    def __init__(self, images, labels, batch_size, is_train=False, mix=False, augment=False, model_type=\"default\", preprocess=None, image_paths=None, sample_ids=None, temp_augment_dir=\"/content/temp_augment\"):\n","        self.batch_size = batch_size\n","        self.is_train = is_train\n","        self.is_mix = False  # Disable mixup\n","        self.augment = False  # Disable augmentation\n","        self.model_type = str(model_type).lower()\n","        self.preprocess = preprocess\n","        self.temp_augment_dir = temp_augment_dir\n","        os.makedirs(self.temp_augment_dir, exist_ok=True)\n","        if not os.access(self.temp_augment_dir, os.W_OK):\n","            raise PermissionError(f\"No write permission for {self.temp_augment_dir}\")\n","\n","        # Set target_size dynamically based on model_type\n","        if self.model_type not in MODEL_CONFIGS:\n","            raise ValueError(f\"Invalid model_type: {self.model_type}. Must be in {list(MODEL_CONFIGS.keys())}\")\n","        self.target_size = (MODEL_CONFIGS[self.model_type]['img_size'], MODEL_CONFIGS[self.model_type]['img_size'])\n","        logging.info(f\"Initialized My_Generator for {self.model_type} with target_size={self.target_size}\")\n","\n","        self.image_paths = []\n","        self.labels = []\n","        self.sample_ids = []\n","\n","        if image_paths is not None:\n","            if len(image_paths) != len(labels) or len(image_paths) != len(sample_ids):\n","                raise ValueError(f\"Mismatch: image_paths={len(image_paths)}, labels={len(labels)}, sample_ids={len(sample_ids)}\")\n","            for path, label, sid in zip(image_paths, labels, sample_ids):\n","                if os.path.exists(path):\n","                    self.image_paths.append(path)\n","                    self.labels.append(label)\n","                    self.sample_ids.append(sid)\n","                else:\n","                    logging.warning(f\"Skipping non-existent image: {path}\")\n","        elif isinstance(images, np.ndarray):\n","            if len(images) != len(labels) or len(images) != len(sample_ids):\n","                raise ValueError(f\"Mismatch: images={len(images)}, labels={len(labels)}, sample_ids={len(sample_ids)}\")\n","            for i, (img, label, sid) in enumerate(zip(images, labels, sample_ids)):\n","                img_path = os.path.join(self.temp_augment_dir, f\"img_{i}_{np.random.randint(1000000)}.png\")\n","                try:\n","                    # Resize image to target_size\n","                    img = cv2.resize(img, self.target_size, interpolation=cv2.INTER_AREA)\n","                    if img.dtype != np.uint8:\n","                        if img.max() <= 1.0:\n","                            img = (img * 255).astype(np.uint8)\n","                        else:\n","                            img = img.astype(np.uint8)\n","                    cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n","                    if os.path.exists(img_path):\n","                        self.image_paths.append(img_path)\n","                        self.labels.append(label)\n","                        self.sample_ids.append(sid)\n","                    else:\n","                        logging.warning(f\"Failed to save image: {img_path}\")\n","                except Exception as e:\n","                    logging.warning(f\"Error saving image {img_path}: {str(e)}\")\n","                    continue\n","        else:\n","            raise ValueError(\"Require valid image_paths or images\")\n","\n","        if not self.image_paths:\n","            raise ValueError(\"No valid image_paths created\")\n","\n","        self.labels = np.array(self.labels, dtype=np.float32)\n","        self.sample_ids = np.array(self.sample_ids, dtype=str)\n","\n","        if len(self.image_paths) != len(self.labels) or len(self.image_paths) != len(self.sample_ids):\n","            raise ValueError(f\"Post-init mismatch: image_paths={len(self.image_paths)}, labels={len(self.labels)}, sample_ids={len(self.sample_ids)}\")\n","\n","        logging.info(f\"Initialized My_Generator: {len(self.image_paths)} samples, batch_size={batch_size}, is_train={is_train}, target_size={self.target_size}\")\n","        self.indices = np.arange(len(self.image_paths))\n","        if self.is_train:\n","            np.random.shuffle(self.indices)\n","\n","    def __len__(self):\n","        num_samples = len(self.image_paths)\n","        if num_samples == 0:\n","            logging.error(\"No samples in generator\")\n","            raise ValueError(\"Generator has no samples\")\n","        num_batches = (num_samples + self.batch_size - 1) // self.batch_size\n","        logging.info(f\"Generator len: {num_samples} samples, {num_batches} batches\")\n","        return num_batches\n","\n","    def __getitem__(self, index):\n","        start_idx = index * self.batch_size\n","        end_idx = min(start_idx + self.batch_size, len(self.image_paths))\n","        batch_indices = self.indices[start_idx:end_idx]\n","\n","        if len(batch_indices) == 0:\n","            logging.warning(f\"Batch {index} has no indices, returning empty batch\")\n","            return np.array([]), np.array([]), []\n","\n","        batch_images = []\n","        batch_labels = []\n","        batch_ids = []\n","\n","        for idx in batch_indices:\n","            try:\n","                img = self._load_image(self.image_paths[idx])\n","                if img is not None and img.size > 0:\n","                    batch_images.append(img)\n","                    batch_labels.append(self.labels[idx])\n","                    batch_ids.append(self.sample_ids[idx])\n","                else:\n","                    logging.warning(f\"Skipping empty or failed image at index {idx}: {self.image_paths[idx]}\")\n","            except Exception as e:\n","                logging.warning(f\"Error loading image at index {idx}: {str(e)}\")\n","                continue\n","\n","        if not batch_images:\n","            logging.warning(f\"Batch {index} empty after processing, returning empty batch\")\n","            return np.array([]), np.array([]), []\n","\n","        batch_images = np.array(batch_images)\n","        batch_labels = np.array(batch_labels)\n","        logging.debug(f\"Batch {index}: images_shape={batch_images.shape}, labels_shape={batch_labels.shape}, ids_count={len(batch_ids)}\")\n","        return batch_images, batch_labels, batch_ids\n","\n","    def _load_image(self, img_path):\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            logging.error(f\"Failed to read image: {img_path}\")\n","            return None\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, self.target_size)\n","        if self.preprocess:\n","            img = self.preprocess(img)\n","        return img\n","\n","    def on_epoch_end(self):\n","        if self.is_train:\n","            np.random.shuffle(self.indices)\n","\n","# Callback để tính trọng số lớp từ confusion matrix\n","class ConfusionMatrixWeightCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, valid_features, valid_labels, classification_model, num_classes=5, class_counts=None):\n","        super().__init__()\n","        self.valid_features = valid_features\n","        self.valid_labels = valid_labels\n","        self.classification_model = classification_model\n","        self.num_classes = num_classes\n","        self.prev_cm = None\n","        self.class_weights = np.ones(num_classes, dtype=np.float32)\n","        self.class_counts = class_counts\n","        self.history_dir = os.path.join(FEATURE_SAVE_DIR, \"history\")\n","        os.makedirs(self.history_dir, exist_ok=True)\n","        self.weights_history = []\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        y_pred = self.classification_model.predict(self.valid_features, verbose=0, batch_size=32)\n","        y_true = np.argmax(self.valid_labels, axis=1)\n","        y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","        cm = confusion_matrix(y_true, y_pred_classes, labels=list(range(self.num_classes)))\n","        logging.info(f\"Epoch {epoch+1} - Ma trận nhầm lẫn:\\n{cm}\")\n","\n","        errors = np.sum(cm * (1 - np.eye(self.num_classes)), axis=1)\n","        total_samples_per_class = np.sum(cm, axis=1)\n","        total_samples_per_class = np.where(total_samples_per_class == 0, 1, total_samples_per_class)\n","        error_rates = errors / total_samples_per_class\n","\n","        weak_classes = []\n","        if self.class_counts is not None:\n","            min_count = np.min(self.class_counts[self.class_counts > 0])\n","            weak_classes = np.where(self.class_counts <= min_count * 1.5)[0]\n","        high_error_classes = np.where(error_rates >= np.percentile(error_rates, 75))[0]\n","        weak_classes = np.unique(np.concatenate([weak_classes, high_error_classes])).astype(int)\n","\n","        self.class_weights = 1.0 + error_rates\n","        for cls in weak_classes:\n","            self.class_weights[cls] *= 2.0\n","        self.class_weights /= self.class_weights.max()\n","\n","        logging.info(f\"Epoch {epoch+1} - Lớp yếu: {weak_classes}\")\n","        logging.info(f\"Epoch {epoch+1} - Trọng số lớp: {self.class_weights}\")\n","\n","        self.weights_history.append({\n","            \"epoch\": epoch + 1,\n","            \"class_weights\": self.class_weights.tolist(),\n","            \"weak_classes\": weak_classes.tolist(),\n","            \"confusion_matrix\": cm.tolist()\n","        })\n","        weights_path = os.path.join(self.history_dir, f\"class_weights_epoch_{epoch+1}.json\")\n","        with open(weights_path, 'w') as f:\n","            json.dump(self.weights_history[-1], f, indent=4)\n","        logging.info(f\"Đã lưu trọng số lớp tại: {weights_path}\")\n","\n","        plt.figure(figsize=(8, 6))\n","        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                    xticklabels=list(range(self.num_classes)),\n","                    yticklabels=list(range(self.num_classes)))\n","        plt.title(f'Ma trận nhầm lẫn - Epoch {epoch+1}')\n","        plt.xlabel('Dự đoán')\n","        plt.ylabel('Thực tế')\n","        cm_path = os.path.join(FEATURE_SAVE_DIR, f'confusion_matrix_epoch_{epoch+1}.png')\n","        plt.savefig(cm_path)\n","        plt.close()\n","        logging.info(f\"Đã lưu ma trận nhầm lẫn tại: {cm_path}\")\n","\n","        self.prev_cm = cm.copy()\n","\n","    def get_class_weights(self):\n","        return self.class_weights\n","\n","# Callback cho checkpoint dựa trên nhiều metrics\n","class MultiMetricCheckpoint(tf.keras.callbacks.Callback):\n","    def __init__(self, filepath, monitor_metrics, mode='max', save_best_only=True):\n","        super().__init__()\n","        self.filepath = filepath\n","        self.monitor_metrics = monitor_metrics\n","        self.mode = mode\n","        self.save_best_only = save_best_only\n","        self.best_metrics = {metric: -float('inf') if mode == 'max' else float('inf') for metric in monitor_metrics}\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        current_metrics = {}\n","        improved = False\n","\n","        for metric in self.monitor_metrics:\n","            current = logs.get(metric, 0.0)\n","            current_metrics[metric] = current\n","            if self.mode == 'max' and current > self.best_metrics[metric]:\n","                self.best_metrics[metric] = current\n","                improved = True\n","            elif self.mode == 'min' and current < self.best_metrics[metric]:\n","                self.best_metrics[metric] = current\n","                improved = True\n","\n","        if improved and self.save_best_only:\n","            self.model.save_weights(self.filepath.format(epoch=epoch + 1), overwrite=True)\n","            logging.info(f\"Đã lưu mô hình tốt nhất tại epoch {epoch + 1} với metrics: {current_metrics}\")\n","\n","# Hàm kiểm tra bộ nhớ\n","\n","# Hàm debug layers của mô hình\n","def debug_model_layers(model, model_name=\"model\"):\n","    logging.info(f\"Kiểm tra layers của {model_name}:\")\n","    conv_layers = []\n","    for layer in model.layers:\n","        if hasattr(layer, 'output'):\n","            output_shape = layer.output.shape\n","            if len(output_shape) == 4:\n","                conv_layers.append((layer.name, output_shape))\n","                logging.info(f\"Layer: {layer.name}, Type: {type(layer).__name__}, Output Shape: {output_shape}\")\n","    if not conv_layers:\n","        logging.error(f\"Không tìm thấy layer 4D nào trong {model_name}\")\n","    else:\n","        logging.info(f\"Tìm thấy {len(conv_layers)} layers với đầu ra 4D:\")\n","        for name, shape in conv_layers:\n","            logging.info(f\"  - {name}: {shape}\")\n","    return conv_layers\n","\n","# Hàm validate dataset\n","def validate_dataset(image_ids, processed_folder, save_dir):\n","    valid_ids = []\n","    corrupted_files = []\n","\n","    for image_id in image_ids:\n","        img_path = os.path.join(processed_folder, f\"{image_id}.png\")\n","        if not os.path.exists(img_path):\n","            logging.error(f\"Ảnh không tồn tại: {img_path}\")\n","            corrupted_files.append(image_id)\n","            continue\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            logging.error(f\"Không đọc được ảnh: {img_path}\")\n","            corrupted_files.append(image_id)\n","            continue\n","        valid_ids.append(image_id)\n","\n","    report = {\n","        \"total_images\": len(image_ids),\n","        \"valid_images\": len(valid_ids),\n","        \"corrupted_images\": len(corrupted_files),\n","        \"corrupted_ids\": corrupted_files\n","    }\n","    report_path = os.path.join(save_dir, \"dataset_validation_report.json\")\n","    with open(report_path, 'w') as f:\n","        json.dump(report, f, indent=4)\n","    logging.info(f\"Đã lưu báo cáo validation tại: {report_path}\")\n","\n","    if corrupted_files:\n","        logging.warning(f\"Đã tìm thấy {len(corrupted_files)} ảnh bị lỗi hoặc thiếu: {corrupted_files[:5]}...\")\n","\n","    return valid_ids\n","\n","# Hàm kiểm tra data leakage\n","def check_data_leakage(train_x, valid_x, test_x, metadata_df=None, id_column='id_code'):\n","    train_set = set(train_x)\n","    valid_set = set(valid_x)\n","    test_set = set(test_x)\n","\n","    train_valid_overlap = train_set.intersection(valid_set)\n","    train_test_overlap = train_set.intersection(test_set)\n","    valid_test_overlap = valid_set.intersection(test_set)\n","\n","    leakage_detected = False\n","    if train_valid_overlap:\n","        logging.warning(f\"Phát hiện overlap giữa train và valid: {len(train_valid_overlap)} mẫu\")\n","        leakage_detected = True\n","    if train_test_overlap:\n","        logging.warning(f\"Phát hiện overlap giữa train và test: {len(train_test_overlap)} mẫu\")\n","        leakage_detected = True\n","    if valid_test_overlap:\n","        logging.warning(f\"Phát hiện overlap giữa valid và test: {len(valid_test_overlap)} mẫu\")\n","        leakage_detected = True\n","\n","    if metadata_df is not None and 'patient_id' in metadata_df.columns:\n","        train_patients = set(metadata_df[metadata_df[id_column].isin(train_x)]['patient_id'])\n","        valid_patients = set(metadata_df[metadata_df[id_column].isin(valid_x)]['patient_id'])\n","        test_patients = set(metadata_df[metadata_df[id_column].isin(test_x)]['patient_id'])\n","\n","        patient_overlap = train_patients.intersection(valid_patients, test_patients)\n","        if patient_overlap:\n","            logging.warning(f\"Phát hiện overlap bệnh nhân: {patient_overlap}\")\n","            leakage_detected = True\n","\n","    if not leakage_detected:\n","        logging.info(\"Không phát hiện data leakage.\")\n","\n","    return not leakage_detected\n","\n","def get_image_ids(folder_path):\n","    try:\n","        if not os.path.exists(folder_path):\n","            print(f\"ERROR: Thư mục {folder_path} không tồn tại.\")\n","            return []\n","\n","        image_files = [f for f in os.listdir(folder_path) if f.endswith('.png')]\n","        image_ids = [os.path.splitext(f)[0] for f in image_files]\n","\n","        print(f\"Tìm thấy {len(image_ids)} ID ảnh trong {folder_path}\")\n","        print(f\"Mẫu ID: {image_ids[:5]}...\")\n","\n","        return image_ids\n","    except Exception as e:\n","        print(f\"ERROR: Lỗi khi liệt kê ID ảnh trong {folder_path}: {str(e)}\")\n","        return []\n","\n","def extract_features(generator, feature_extractor):\n","    features = []\n","    feature_ids = []\n","    total_samples = len(generator.image_paths)\n","    num_batches = len(generator)\n","    processed_samples = 0\n","    empty_batch_count = 0\n","    max_empty_batches = 10\n","    batch_size = 16\n","\n","    logging.info(f\"Trích xuất đặc trưng cho {total_samples} mẫu, {num_batches} batch\")\n","\n","    for batch_idx in range(num_batches):\n","        try:\n","            batch_images, _, batch_ids = generator[batch_idx]\n","        except Exception as e:\n","            logging.warning(f\"Lỗi khi lấy batch {batch_idx}: {str(e)}\")\n","            empty_batch_count += 1\n","            if empty_batch_count >= max_empty_batches:\n","                logging.error(f\"Quá nhiều batch rỗng liên tiếp ({empty_batch_count})\")\n","                break\n","            continue\n","\n","        if len(batch_images) == 0 or len(batch_ids) == 0:\n","            logging.warning(f\"Batch {batch_idx} rỗng, bỏ qua\")\n","            empty_batch_count += 1\n","            if empty_batch_count >= max_empty_batches:\n","                logging.error(f\"Quá nhiều batch rỗng liên tiếp ({empty_batch_count})\")\n","                break\n","            continue\n","\n","        empty_batch_count = 0\n","        try:\n","            batch_features = feature_extractor.predict(batch_images, batch_size=batch_size, verbose=0)\n","            logging.debug(f\"Batch {batch_idx} feature shape trước pooling: {batch_features.shape}\")\n","            if len(batch_features.shape) > 2:\n","                batch_features = np.mean(batch_features, axis=(1, 2))  # Global average pooling\n","            logging.debug(f\"Batch {batch_idx} feature shape sau pooling: {batch_features.shape}\")\n","            if batch_features.shape[0] != len(batch_ids):\n","                logging.warning(f\"Số đặc trưng ({batch_features.shape[0]}) không khớp với số ID ({len(batch_ids)})\")\n","                continue\n","            features.append(batch_features)\n","            feature_ids.extend(batch_ids)\n","            processed_samples += len(batch_ids)\n","            logging.info(f\"Batch {batch_idx}: {len(batch_ids)} samples, features_shape={batch_features.shape}\")\n","        except Exception as e:\n","            logging.warning(f\"Lỗi khi xử lý batch {batch_idx}: {str(e)}\")\n","            continue\n","\n","    if not features:\n","        logging.error(\"Không trích xuất được đặc trưng nào.\")\n","        raise ValueError(\"Không trích xuất được đặc trưng.\")\n","\n","    features = np.concatenate(features, axis=0)\n","    if len(features) != len(feature_ids):\n","        logging.error(f\"Số đặc trưng ({len(features)}) không khớp với số feature_ids ({len(feature_ids)})\")\n","        raise ValueError(\"Đặc trưng và ID không đồng bộ.\")\n","    logging.info(f\"Hoàn thành trích xuất: {len(features)} đặc trưng\")\n","    return features, feature_ids\n","\n","# Hàm trích xuất và lưu đặc trưng\n","def extract_and_save_features(model_name, extractor, generator, save_dir, sample_ids):\n","    if not sample_ids or len(sample_ids) == 0:\n","        logging.error(f\"sample_ids rỗng hoặc không được cung cấp cho {model_name}.\")\n","        raise ValueError(\"sample_ids rỗng hoặc không được cung cấp.\")\n","\n","    logging.info(f\"Bắt đầu trích xuất đặc trưng cho {model_name}\")\n","    features, feature_ids = extract_features(generator, extractor)\n","    logging.info(f\"Trích xuất {len(features)} đặc trưng cho {model_name}\")\n","\n","    if len(features) != len(sample_ids):\n","        logging.warning(f\"Số đặc trưng ({len(features)}) không khớp với số sample_ids ({len(sample_ids)})\")\n","        missing_ids = set(sample_ids) - set(feature_ids)\n","        logging.warning(f\"ID bị thiếu trong feature_ids: {list(missing_ids)[:5]}...\")\n","\n","    feature_path = os.path.join(save_dir, f\"{model_name}_features.npy\")\n","    np.save(feature_path, features)\n","    logging.info(f\"Đã lưu đặc trưng tại: {feature_path}\")\n","\n","    ids_path = os.path.join(save_dir, f\"{model_name}_feature_ids.npy\")\n","    np.save(ids_path, np.array(feature_ids, dtype=str))\n","    logging.info(f\"Đã lưu feature_ids tại: {ids_path}\")\n","\n","    return features, feature_ids\n","\n","# Hàm kết hợp và giảm chiều đặc trưng\n","def combine_and_reduce_features(features_dict, features_dict_4d, labels, sample_ids, save_dir, n_components=50):\n","    try:\n","        features_2d_list = []\n","        feature_ids_list = []\n","\n","        for model_name, features in features_dict.items():\n","            if features is None:\n","                logging.warning(f\"Đặc trưng từ {model_name} là None, bỏ qua.\")\n","                continue\n","            if len(features.shape) != 2:\n","                logging.warning(f\"Đặc trưng từ {model_name} có shape {features.shape}, áp dụng global average pooling.\")\n","                features = np.mean(features, axis=tuple(range(1, len(features.shape)-1)), keepdims=False)\n","            features_2d_list.append(features)\n","            feature_ids = np.load(os.path.join(save_dir, f\"{model_name}_feature_ids.npy\"), allow_pickle=True)\n","            feature_ids_list.append(feature_ids)\n","            logging.info(f\"Đã thêm đặc trưng 2D từ {model_name}, shape: {features.shape}\")\n","\n","        if not features_2d_list:\n","            logging.error(\"Không có đặc trưng 2D hợp lệ nào để kết hợp.\")\n","            raise ValueError(\"Yêu cầu ít nhất một tập đặc trưng 2D hợp lệ.\")\n","\n","        # Kiểm tra tính nhất quán của feature_ids\n","        feature_ids_array = np.array(feature_ids_list)\n","        if not np.all(feature_ids_array == feature_ids_array[0]):\n","            logging.warning(\"Feature_ids không nhất quán, sử dụng feature_ids từ mô hình đầu tiên.\")\n","        common_ids = feature_ids_list[0]\n","\n","        # Kiểm tra shape đồng nhất\n","        feature_shapes = [f.shape for f in features_2d_list]\n","        if len(set(tuple(s) for s in feature_shapes)) > 1:\n","            logging.error(f\"Shape đặc trưng không đồng nhất: {feature_shapes}\")\n","            raise ValueError(\"Đặc trưng có shape không đồng nhất.\")\n","\n","        combined_2d = np.concatenate(features_2d_list, axis=1)\n","        scaler = StandardScaler()\n","        combined_2d = scaler.fit_transform(combined_2d)\n","\n","        indices = []\n","        missing_ids = []\n","        for sample_id in sample_ids:\n","            idx = np.where(common_ids == sample_id)[0]\n","            if len(idx) > 0:\n","                indices.append(idx[0])\n","            else:\n","                missing_ids.append(sample_id)\n","                logging.warning(f\"Không tìm thấy sample_id {sample_id} trong feature_ids.\")\n","\n","        if not indices:\n","            logging.error(\"Không tìm thấy sample_id nào trong feature_ids.\")\n","            raise ValueError(\"Không có sample_id hợp lệ.\")\n","\n","        indices = np.array(indices)\n","        combined_2d = combined_2d[indices]\n","        aligned_labels = labels[indices] if labels is not None else None\n","\n","        if n_components is not None:\n","            pca = PCA(n_components=n_components, random_state=42)\n","            reduced_2d = pca.fit_transform(combined_2d)\n","            explained_variance = np.sum(pca.explained_variance_ratio_)\n","            logging.info(f\"PCA: {n_components} thành phần, giải thích {explained_variance*100:.2f}% phương sai\")\n","        else:\n","            reduced_2d = combined_2d\n","            explained_variance = 1.0\n","            logging.info(\"Bỏ qua PCA, giữ nguyên đặc trưng gốc.\")\n","\n","        save_path = os.path.join(save_dir, \"combined_reduced_features.npy\")\n","        np.save(save_path, reduced_2d)\n","        logging.info(f\"Đã lưu đặc trưng giảm chiều tại: {save_path}\")\n","\n","        return reduced_2d, aligned_labels, indices, reduced_2d.shape[1]\n","\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi kết hợp và giảm chiều đặc trưng: {str(e)}\")\n","        raise\n","\n","# Hàm apply temperature scaling và laplace smoothing\n","def apply_temperature_scaling(logits, temperature=2.0):\n","    logits = tf.convert_to_tensor(logits, dtype=tf.float32)\n","    return tf.nn.softmax(logits / temperature)\n","\n","def laplace_smoothing(probs, epsilon=1e-5):\n","    probs = tf.convert_to_tensor(probs, dtype=tf.float32)\n","    return (probs + epsilon) / (tf.reduce_sum(probs, axis=-1, keepdims=True) + NUM_CLASSES * epsilon)\n","\n","# Hàm lưu confusion matrix\n","def save_confusion_matrix(y_true, y_pred, episode, qwk, save_dir, prefix=''):\n","    cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3, 4])\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=[0, 1, 2, 3, 4], yticklabels=[0, 1, 2, 3, 4])\n","    plt.title(f'Ma trận nhầm lẫn - {prefix}QWK: {qwk:.4f} tại Episode {episode+1}')\n","    plt.xlabel('Dự đoán')\n","    plt.ylabel('Thực tế')\n","    cm_path = os.path.join(save_dir, f'confusion_matrix_{prefix}qwk_episode_{episode+1}.png')\n","    plt.savefig(cm_path)\n","    plt.close()\n","    logging.info(f\"Đã lưu ma trận nhầm lẫn {prefix}QWK tại: {cm_path}\")\n","    return cm\n","\n","# Hàm đánh giá chi tiết per-class metrics\n","def evaluate_per_class_metrics(y_true, y_pred_probs, y_pred_classes, labels, save_dir, prefix=\"test\"):\n","    report = classification_report(\n","        y_true, y_pred_classes, labels=labels, target_names=[f\"Class {i}\" for i in labels], output_dict=True\n","    )\n","    metrics_df = pd.DataFrame(report).transpose()\n","\n","    metrics_path = Path(save_dir) / f\"{prefix}_classification_report.csv\"\n","    metrics_df.to_csv(metrics_path)\n","    logging.info(f\"Đã lưu báo cáo phân loại tại: {metrics_path}\")\n","\n","    plt.figure(figsize=(12, 5))\n","\n","    plt.subplot(1, 2, 1)\n","    for i in labels:\n","        fpr, tpr, _ = roc_curve(y_true == i, y_pred_probs[:, i])\n","        roc_auc = auc(fpr, tpr)\n","        plt.plot(fpr, tpr, label=f\"Class {i} (AUC = {roc_auc:.2f})\")\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlabel(\"False Positive Rate\")\n","    plt.ylabel(\"True Positive Rate\")\n","    plt.title(\"ROC Curves\")\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    for i in labels:\n","        precision, recall, _ = precision_recall_curve(y_true == i, y_pred_probs[:, i])\n","        plt.plot(recall, precision, label=f\"Class {i}\")\n","    plt.xlabel(\"Recall\")\n","    plt.ylabel(\"Precision\")\n","    plt.title(\"Precision-Recall Curves\")\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    curves_path = Path(save_dir) / f\"{prefix}_roc_pr_curves.png\"\n","    plt.savefig(curves_path, bbox_inches=\"tight\")\n","    plt.close()\n","    logging.info(f\"Đã lưu ROC và PR curves tại: {curves_path}\")\n","\n","    return metrics_df\n","\n","# Hàm đánh giá calibration\n","def evaluate_calibration(y_true, y_pred_probs, save_dir, prefix=\"test\"):\n","    plt.figure(figsize=(10, 8))\n","\n","    for cls in range(NUM_CLASSES):\n","        prob_true, prob_pred = calibration_curve(\n","            y_true == cls, y_pred_probs[:, cls], n_bins=10, strategy='uniform'\n","        )\n","        plt.plot(prob_pred, prob_true, marker='o', label=f\"Class {cls}\")\n","\n","    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n","    plt.xlabel(\"Mean Predicted Probability\")\n","    plt.ylabel(\"Fraction of Positives\")\n","    plt.title(\"Reliability Diagram\")\n","    plt.legend()\n","\n","    calib_path = Path(save_dir) / f\"{prefix}_calibration_curve.png\"\n","    plt.savefig(calib_path, bbox_inches=\"tight\")\n","    plt.close()\n","    logging.info(f\"Đã lưu calibration curve tại: {calib_path}\")\n","\n","# Hàm export predictions\n","def export_predictions(image_ids, y_true, y_pred_probs, y_pred_classes, save_dir, filename=\"predictions.csv\"):\n","    predictions_df = pd.DataFrame({\n","        \"id_code\": image_ids,\n","        \"true_label\": y_true,\n","        \"predicted_label\": y_pred_classes\n","    })\n","    for i in range(y_pred_probs.shape[1]):\n","        predictions_df[f\"prob_class_{i}\"] = y_pred_probs[:, i]\n","\n","    output_path = Path(save_dir) / filename\n","    predictions_df.to_csv(output_path, index=False)\n","    logging.info(f\"Đã xuất dự đoán tại: {output_path}\")\n","\n","    return predictions_df\n","\n","\n","\n","# Hàm lưu meta-learner model\n","\n","def save_meta_learner_model(model, save_dir, episode, qwk_scores, training_config):\n","    if model is None:\n","        logging.error(f\"Không thể lưu mô hình tại episode {episode + 1}: model là None\")\n","        raise ValueError(\"Mô hình là None\")\n","    try:\n","        os.makedirs(save_dir, exist_ok=True)\n","        model_path = os.path.join(save_dir, f\"meta_model_episode_{episode + 1}.h5\")\n","        model.save_weights(model_path, overwrite=True)  # Chỉ lưu trọng số\n","        logging.info(f\"Đã lưu trọng số mô hình tại: {model_path}\")\n","        meta_info = {\n","            \"episode\": episode + 1,\n","            \"qwk_scores\": [float(score) for score in qwk_scores],\n","            \"training_config\": training_config\n","        }\n","        info_path = os.path.join(save_dir, f\"meta_info_episode_{episode + 1}.json\")\n","        with open(info_path, 'w') as f:\n","            json.dump(meta_info, f, indent=4)\n","        logging.info(f\"Đã lưu thông tin meta tại: {info_path}\")\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi lưu meta mô hình tại episode {episode + 1}: {str(e)}\")\n","        raise\n","\n","# Hàm tạo episode cho meta-learning\n","def create_episode(data_df, support_size, query_size, num_classes, model_type=\"efficientnetb1\"):\n","    config = MODEL_CONFIGS[model_type]\n","    size = config['img_size']\n","    support_images = []\n","    support_labels = []\n","    query_images = []\n","    query_labels = []\n","    included_classes = []\n","\n","    for cls in range(num_classes):\n","        cls_samples = data_df[data_df['diagnosis'] == cls]\n","        required_samples = support_size + query_size\n","        if len(cls_samples) < required_samples:\n","            logging.warning(f\"Không đủ mẫu cho lớp {cls}: cần {required_samples}, có {len(cls_samples)}\")\n","            continue\n","        cls_samples = cls_samples.sample(n=required_samples, random_state=42)\n","        support_samples = cls_samples.iloc[:support_size]\n","        query_samples = cls_samples.iloc[support_size:support_size + query_size]\n","\n","        for _, row in support_samples.iterrows():\n","            img = load_processed_image(row['id_code'], PROCESSED_FOLDER, model_type=model_type)\n","            if img is not None and img.shape == (size, size, 3):\n","                support_images.append(img)\n","                support_labels.append(cls)\n","            else:\n","                logging.warning(f\"Bỏ qua ảnh support không hợp lệ: {row['id_code']}, shape: {getattr(img, 'shape', 'None')}\")\n","\n","        for _, row in query_samples.iterrows():\n","            img = load_processed_image(row['id_code'], PROCESSED_FOLDER, model_type=model_type)\n","            if img is not None and img.shape == (size, size, 3):\n","                query_images.append(img)\n","                query_labels.append(cls)\n","            else:\n","                logging.warning(f\"Bỏ qua ảnh query không hợp lệ: {row['id_code']}, shape: {getattr(img, 'shape', 'None')}\")\n","\n","        included_classes.append(cls)\n","\n","    if not included_classes:\n","        logging.error(\"Không có lớp nào có đủ mẫu cho episode\")\n","        return np.zeros((0, size, size, 3)), np.zeros((0, num_classes)), np.zeros((0, size, size, 3)), np.zeros((0, num_classes))\n","\n","    if len(support_images) < support_size * len(included_classes) or len(query_images) < query_size * len(included_classes):\n","        logging.error(f\"Không đủ ảnh hợp lệ: support_images={len(support_images)}, query_images={len(query_images)}\")\n","        return np.zeros((0, size, size, 3)), np.zeros((0, num_classes)), np.zeros((0, size, size, 3)), np.zeros((0, num_classes))\n","\n","    try:\n","        # Kiểm tra và in hình dạng của từng ảnh\n","        for i, img in enumerate(support_images + query_images):\n","            if img.shape != (size, size, 3):\n","                logging.error(f\"Ảnh {i} có shape không hợp lệ: {img.shape}\")\n","                raise ValueError(f\"Ảnh không hợp lệ trong episode: shape {img.shape}\")\n","        support_images = np.array(support_images, dtype=np.float32)\n","        support_labels = tf.keras.utils.to_categorical(support_labels, num_classes)\n","        query_images = np.array(query_images, dtype=np.float32)\n","        query_labels = tf.keras.utils.to_categorical(query_labels, num_classes)\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi chuyển đổi mảng: {str(e)}\")\n","        return np.zeros((0, size, size, 3)), np.zeros((0, num_classes)), np.zeros((0, size, size, 3)), np.zeros((0, num_classes))\n","\n","    logging.info(f\"Đã tạo episode: support_images={support_images.shape}, support_labels={support_labels.shape}, \"\n","                 f\"query_images={query_images.shape}, query_labels={query_labels.shape}, classes={included_classes}\")\n","    return support_images, support_labels, query_images, query_labels\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Dense, Dropout, Concatenate\n","from tensorflow.keras.models import Model\n","import numpy as np\n","import logging\n","import os\n","from sklearn.metrics import cohen_kappa_score, f1_score\n","\n","def build_meta_conv_model(img_shape, feature_2d_shape, num_classes):\n","    \"\"\"\n","    Xây dựng mô hình meta-learning với kiến trúc đơn giản hơn.\n","    \"\"\"\n","    img_input = Input(shape=img_shape, name='img_input')\n","    x = Conv2D(32, (3, 3), padding='same', activation=None)(img_input)  # Giảm từ 64\n","    x = BatchNormalization(trainable=True)(x)\n","    x = ReLU()(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Conv2D(64, (3, 3), padding='same', activation=None)(x)  # Giảm từ 128\n","    x = BatchNormalization(trainable=True)(x)\n","    x = ReLU()(x)\n","    x = MaxPooling2D((2, 2))(x)\n","    x = Conv2D(128, (3, 3), padding='same', activation=None)(x)  # Giảm từ 256\n","    x = BatchNormalization(trainable=True)(x)\n","    x = ReLU()(x)\n","    x = MaxPooling2D((4, 4))(x)\n","    conv_features = x\n","\n","    x = GlobalAveragePooling2D()(conv_features)\n","\n","    feature_2d_input = Input(shape=feature_2d_shape, name='feature_2d_input')\n","    y = Dense(128, activation='relu')(feature_2d_input)  # Giảm từ 256\n","    y = BatchNormalization(trainable=True)(y)\n","    y = Dropout(0.5)(y)\n","\n","    combined = Concatenate()([x, y])\n","    z = Dense(64, activation='relu')(combined)  # Giảm từ 128\n","    z = BatchNormalization(trainable=True)(z)\n","    z = Dropout(0.5)(z)\n","    logits = Dense(num_classes, activation='softmax')(z)\n","\n","    model = Model(inputs=[img_input, feature_2d_input], outputs=[conv_features, logits], name='meta_conv_model')\n","    return model\n","\n","def maml_fomaml_train_manual(\n","    meta_model,\n","    data_df,\n","    valid_features,\n","    valid_labels,\n","    valid_images,\n","    input_dim,\n","    model_type=\"efficientnetb1\",\n","    n_episodes=40,\n","    inner_lr=0.01,\n","    outer_lr=0.001,\n","    fine_tune_lr=0.0001,\n","    support_size=16,\n","    query_size=16,\n","    save_dir=\"./features\",\n","    sample_ids=None,\n","    callbacks=None\n","):\n","    logging.info(f\"Khởi tạo huấn luyện MAML/FOMAML cho {model_type}\")\n","\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=outer_lr)\n","    qwk_scores = []\n","    best_qwk = -1.0\n","    history = {\"qwk\": [], \"loss\": []}\n","    NUM_CLASSES = valid_labels.shape[1] if valid_labels is not None else 5\n","    BATCH_SIZE = 16\n","\n","    if valid_images.shape[0] != valid_features.shape[0]:\n","        logging.error(f\"Số lượng mẫu không khớp: valid_images={valid_images.shape[0]}, valid_features={valid_features.shape[0]}\")\n","        raise ValueError(\"Số lượng mẫu không khớp giữa ảnh và đặc trưng.\")\n","    logging.info(f\"Dữ liệu validation: images_shape={valid_images.shape}, features_shape={valid_features.shape}, labels_shape={valid_labels.shape}\")\n","\n","    config = MODEL_CONFIGS[model_type]\n","    input_shape = (config['img_size'], config['img_size'], 3)\n","    try:\n","        # Trong vòng lặp model_name trong main_pipeline\n","        base_model = load_model_from_config(\n","            config['config_path'], config['weights_path'], config['base_model'], input_shape\n","        )\n","        feature_2d_layers = [\n","            layer for layer in base_model.layers\n","            if not isinstance(layer, tf.keras.layers.InputLayer) and len(layer.output.shape) == 2\n","        ]\n","        if not feature_2d_layers:\n","            logging.warning(f\"Không tìm thấy tầng 2D trong {model_name}, thêm GlobalAveragePooling2D\")\n","            x = base_model.output\n","            x = GlobalAveragePooling2D()(x)\n","            feature_2d_output = x\n","        else:\n","            feature_2d_output = feature_2d_layers[-1].output\n","        feature_extractor = tf.keras.Model(inputs=base_model.input, outputs=feature_2d_output)\n","        logging.info(f\"Feature extractor output shape: {feature_2d_output.shape}\")\n","    except Exception as e:\n","        logging.error(f\"Lỗi tải base model hoặc tạo feature extractor cho {model_type}: {str(e)}\")\n","        raise\n","\n","    # Tiếp tục với các bước còn lại\n","    try:\n","        if not isinstance(valid_images, np.ndarray):\n","            logging.warning(f\"valid_images không phải np.ndarray, type: {type(valid_images)}. Chuyển đổi sang np.ndarray.\")\n","            valid_images = np.array(valid_images)\n","        if len(valid_images.shape) != 4:\n","            logging.error(f\"valid_images có shape không hợp lệ: {valid_images.shape}. Kỳ vọng mảng 4D.\")\n","            raise ValueError(\"valid_images phải là mảng 4D.\")\n","\n","        valid_images_preprocessed = config['preprocess'](valid_images)\n","        if not isinstance(valid_images_preprocessed, np.ndarray):\n","            logging.warning(f\"valid_images_preprocessed không phải np.ndarray, type: {type(valid_images_preprocessed)}. Chuyển đổi sang np.ndarray.\")\n","            valid_images_preprocessed = np.array(valid_images_preprocessed)\n","        logging.info(f\"Valid images preprocessed shape: {valid_images_preprocessed.shape}, dtype: {valid_images_preprocessed.dtype}\")\n","        valid_features_2d = feature_extractor.predict(valid_images_preprocessed, batch_size=BATCH_SIZE, verbose=0)\n","        logging.info(f\"Valid features 2D shape: {valid_features_2d.shape}, dtype: {valid_features_2d.dtype}\")\n","        tf.keras.backend.clear_session()\n","        gc.collect()\n","        check_memory()\n","    except Exception as e:\n","        logging.error(f\"Lỗi tiền xử lý hoặc trích xuất đặc trưng: {str(e)}\")\n","        raise\n","\n","    # ... (phần còn lại của hàm giữ nguyên)\n","\n","    # Xây dựng meta_conv_model nếu chưa có\n","    if meta_model is None:\n","        try:\n","            meta_model = build_meta_conv_model(\n","                img_shape=input_shape,\n","                feature_2d_shape=(valid_features_2d.shape[1],),\n","                num_classes=NUM_CLASSES\n","            )\n","            logging.info(\"Đã xây dựng meta_conv_model thành công.\")\n","        except Exception as e:\n","            logging.error(f\"Lỗi xây dựng meta_conv_model: {str(e)}\")\n","            raise\n","\n","    # Tạo classification model cho tinh chỉnh và dự đoán\n","    img_input = tf.keras.Input(shape=input_shape, name='img_input')\n","    feature_2d_input = tf.keras.Input(shape=(valid_features_2d.shape[1],), name='feature_2d_input')\n","    conv_features, logits = meta_model([img_input, feature_2d_input])\n","    classification_model = tf.keras.Model(\n","        inputs=[img_input, feature_2d_input],\n","        outputs=logits,\n","        name='meta_classification_model'\n","    )\n","\n","    # Callback cho confusion matrix\n","    class_counts = np.sum(valid_labels, axis=0) if valid_labels is not None else None\n","    cm_callback = ConfusionMatrixWeightCallback(\n","        valid_features=[valid_images_preprocessed, valid_features_2d],\n","        valid_labels=valid_labels,\n","        classification_model=classification_model,\n","        num_classes=NUM_CLASSES,\n","        class_counts=class_counts\n","    )\n","    checkpoint_callback = MultiMetricCheckpoint(\n","        filepath=os.path.join(save_dir, f\"meta_model_best_{model_type}_{{epoch}}.weights.h5\"),\n","        monitor_metrics={'qwk': 'max', 'f1': 'max'},\n","        mode='max',\n","        save_best_only=True\n","    )\n","    callbacks = [cm_callback, checkpoint_callback] + (callbacks or [])\n","\n","    # Huấn luyện từng episode\n","    for episode in range(n_episodes):\n","        logging.info(f\"Huấn luyện episode {episode + 1}/{n_episodes}\")\n","        try:\n","            # Tạo support và query set\n","            support_images, support_labels, query_images, query_labels = create_episode(\n","                data_df, support_size, query_size, NUM_CLASSES, model_type=model_type\n","            )\n","            if support_images.shape[0] == 0 or query_images.shape[0] == 0:\n","                logging.warning(f\"Episode rỗng tại {episode + 1}, bỏ qua\")\n","                continue\n","\n","            # Tiền xử lý và trích xuất đặc trưng\n","            support_preprocessed = config['preprocess'](support_images)\n","            query_preprocessed = config['preprocess'](query_images)\n","            support_features_2d = feature_extractor.predict(support_preprocessed, batch_size=BATCH_SIZE, verbose=0)\n","            query_features_2d = feature_extractor.predict(query_preprocessed, batch_size=BATCH_SIZE, verbose=0)\n","            tf.keras.backend.clear_session()\n","            gc.collect()\n","            check_memory()\n","\n","            logging.info(f\"Support set: images={support_preprocessed.shape}, features={support_features_2d.shape}\")\n","            logging.info(f\"Query set: images={query_preprocessed.shape}, features={query_features_2d.shape}\")\n","\n","            # Kiểm tra shape\n","            if support_preprocessed.shape[0] != support_features_2d.shape[0]:\n","                logging.error(f\"Số lượng mẫu không khớp trong support set: images={support_preprocessed.shape[0]}, features={support_features_2d.shape[0]}\")\n","                raise ValueError(\"Số lượng mẫu không khớp trong support set.\")\n","            if query_preprocessed.shape[0] != query_features_2d.shape[0]:\n","                logging.error(f\"Số lượng mẫu không khớp trong query set: images={query_preprocessed.shape[0]}, features={query_features_2d.shape[0]}\")\n","                raise ValueError(\"Số lượng mẫu không khớp trong query set.\")\n","\n","            # MAML inner loop (FOMAML style)\n","            fast_weights = [w.numpy() for w in meta_model.weights]  # Lưu trọng số gốc\n","            with tf.GradientTape() as inner_tape:\n","                support_conv_features, support_logits = meta_model(\n","                    [support_preprocessed, support_features_2d], training=True\n","                )\n","                support_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(support_labels, support_logits))\n","            inner_grads = inner_tape.gradient(support_loss, meta_model.trainable_variables)\n","\n","            # Cập nhật trọng số nhanh\n","            fast_weights_updated = fast_weights.copy()\n","            trainable_indices = [i for i, w in enumerate(meta_model.weights) if w.trainable]\n","            grad_idx = 0\n","            for i in trainable_indices:\n","                if grad_idx < len(inner_grads) and inner_grads[grad_idx] is not None:\n","                    fast_weights_updated[i] = fast_weights[i] - inner_lr * inner_grads[grad_idx]\n","                grad_idx += 1\n","\n","            meta_model.set_weights(fast_weights_updated)  # Cập nhật trọng số nhanh\n","\n","            # MAML outer loop\n","            with tf.GradientTape() as outer_tape:\n","                query_conv_features, query_logits = meta_model(\n","                    [query_preprocessed, query_features_2d], training=True\n","                )\n","                query_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(query_labels, query_logits))\n","                query_logits = apply_temperature_scaling(query_logits, temperature=2.0)\n","                query_logits = laplace_smoothing(query_logits)\n","            outer_grads = outer_tape.gradient(query_loss, meta_model.trainable_variables)\n","            valid_grads_and_vars = [(g, v) for g, v in zip(outer_grads, meta_model.trainable_variables) if g is not None]\n","            if not valid_grads_and_vars:\n","                logging.error(\"Không có gradient ngoài hợp lệ để áp dụng.\")\n","                raise ValueError(\"Không có gradient ngoài hợp lệ.\")\n","            optimizer.apply_gradients(valid_grads_and_vars)\n","\n","            # Khôi phục trọng số gốc\n","            meta_model.set_weights(fast_weights)\n","\n","            # Đánh giá\n","            y_true = np.argmax(query_labels, axis=1)\n","            y_pred = np.argmax(query_logits, axis=1)\n","            qwk = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n","            qwk_scores.append(qwk)\n","            history[\"qwk\"].append(float(qwk))\n","            history[\"loss\"].append(float(query_loss))\n","            logging.info(f\"Episode {episode + 1}: QWK={qwk:.4f}, Loss={query_loss:.4f}\")\n","\n","            # Gọi callbacks\n","            for callback in callbacks:\n","                callback.on_epoch_end(episode, logs={\"qwk\": qwk, \"f1\": f1_score(y_true, y_pred, average='weighted')})\n","\n","            # Lưu confusion matrix\n","            save_confusion_matrix(y_true, y_pred, episode, qwk, save_dir, prefix=f'meta_{model_type}_')\n","\n","            # Lưu mô hình tốt nhất\n","            if qwk > best_qwk:\n","                best_qwk = qwk\n","                training_config = {\n","                    \"inner_lr\": float(inner_lr),\n","                    \"outer_lr\": float(outer_lr),\n","                    \"fine_tune_lr\": float(fine_tune_lr),\n","                    \"train_config\": {\n","                        \"support_size\": support_size,\n","                        \"query_size\": query_size,\n","                        \"n_episodes\": n_episodes,\n","                        \"model_type\": model_type\n","                    }\n","                }\n","                save_meta_learner_model(meta_model, save_dir, episode, qwk_scores, training_config)\n","                logging.info(f\"Đã lưu mô hình tốt nhất tại episode {episode + 1}\")\n","\n","            # Quản lý bộ nhớ\n","            tf.keras.backend.clear_session()\n","            gc.collect()\n","            check_memory()\n","\n","        except Exception as e:\n","            logging.error(f\"Lỗi trong episode {episode + 1}: {str(e)}\")\n","            continue\n","\n","    # Tinh chỉnh classification_model\n","    try:\n","        classification_model.compile(\n","            optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_lr),\n","            loss='categorical_crossentropy',\n","            metrics=['accuracy']\n","        )\n","        classification_model.fit(\n","            [valid_images_preprocessed, valid_features_2d],\n","            valid_labels,\n","            batch_size=BATCH_SIZE,\n","            epochs=5,\n","            verbose=1,\n","            callbacks=callbacks\n","        )\n","        logging.info(\"Hoàn thành tinh chỉnh classification_model.\")\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi tinh chỉnh classification_model: {str(e)}\")\n","        raise\n","\n","    return meta_model, classification_model, history\n","\n","# Hàm cross-validation\n","def cross_validate_pipeline(\n","    x, y, processed_folder, model_configs, feature_save_dir, n_splits=5, n_episodes=20, **kwargs\n","):\n","    \"\"\"\n","    Performs k-fold cross-validation for the meta-learning pipeline.\n","\n","    Args:\n","        x (pd.Series): Series of image IDs (id_code).\n","        y (np.ndarray): Array of labels (diagnosis).\n","        processed_folder (str): Path to folder containing processed images.\n","        model_configs (dict): Dictionary of model configurations (MODEL_CONFIGS).\n","        feature_save_dir (str): Directory to save features and results.\n","        n_splits (int): Number of folds for cross-validation.\n","        n_episodes (int): Number of episodes for meta-learning.\n","        **kwargs: Additional arguments for maml_fomaml_train_manual.\n","\n","    Returns:\n","        dict: Cross-validation results with QWK, F1, and recall scores.\n","    \"\"\"\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","    cv_results = {\"qwk\": [], \"f1\": [], \"recall\": []}\n","\n","    for fold, (train_idx, valid_idx) in enumerate(kf.split(x)):\n","        logging.info(f\"Processing fold {fold + 1}/{n_splits}\")\n","\n","        # Split data\n","        train_x, valid_x = x.iloc[train_idx].values, x.iloc[valid_idx].values\n","        train_y, valid_y = y[train_idx], y[valid_idx]\n","\n","        # Prepare image paths and filter missing images\n","        train_image_paths = [os.path.join(processed_folder, f\"{id_code}.png\") for id_code in train_x]\n","        valid_image_paths = [os.path.join(processed_folder, f\"{id_code}.png\") for id_code in valid_x]\n","        train_sample_ids = []\n","        train_y_filtered = []\n","        valid_sample_ids = []\n","        valid_y_filtered = []\n","\n","        # Filter train data\n","        for path, id_code, label in zip(train_image_paths, train_x, train_y):\n","            if os.path.exists(path):\n","                train_sample_ids.append(id_code)\n","                train_y_filtered.append(label)\n","            else:\n","                logging.warning(f\"Skipping non-existent train image: {path}\")\n","        train_y_filtered = np.array(train_y_filtered)\n","\n","        # Filter valid data\n","        for path, id_code, label in zip(valid_image_paths, valid_x, valid_y):\n","            if os.path.exists(path):\n","                valid_sample_ids.append(id_code)\n","                valid_y_filtered.append(label)\n","            else:\n","                logging.warning(f\"Skipping non-existent valid image: {path}\")\n","        valid_y_filtered = np.array(valid_y_filtered)\n","\n","        if len(train_sample_ids) == 0 or len(valid_sample_ids) == 0:\n","            logging.error(f\"Fold {fold + 1}: Empty train or valid set after filtering.\")\n","            continue\n","\n","        # Convert labels to one-hot encoding\n","        train_y_multi = tf.keras.utils.to_categorical(train_y_filtered, num_classes=NUM_CLASSES)\n","        valid_y_multi = tf.keras.utils.to_categorical(valid_y_filtered, num_classes=NUM_CLASSES)\n","\n","        # Load train and valid images\n","        train_images = np.array([\n","            img for img in [load_processed_image(id_code, processed_folder, model_type=\"efficientnetb1\") for id_code in train_sample_ids]\n","            if img is not None\n","        ])\n","        valid_images = np.array([\n","            img for img in [load_processed_image(id_code, processed_folder, model_type=\"efficientnetb1\") for id_code in valid_sample_ids]\n","            if img is not None\n","        ])\n","        train_y_multi = train_y_multi[:len(train_images)]  # Adjust labels to match images\n","        valid_y_multi = valid_y_multi[:len(valid_images)]\n","\n","        # Balance training data\n","        balanced_train_x, balanced_train_y_multi = balance_data(\n","            train_images, train_y_multi, target_classes=[0, 1, 2, 3, 4]\n","        )\n","\n","        # Initialize feature dictionaries\n","        train_features_dict, valid_features_dict = {}, {}\n","\n","        # Extract features for each model\n","        for model_name, config in model_configs.items():\n","            logging.info(f\"Extracting features for {model_name} in fold {fold + 1}\")\n","\n","            # Create generators\n","            train_generator = My_Generator(\n","                images=None,\n","                labels=balanced_train_y_multi,\n","                batch_size=BATCH_SIZE,\n","                is_train=True,\n","                mix=False,\n","                augment=False,\n","                model_type=config['model_type'],\n","                preprocess=config['preprocess'],\n","                image_paths=[os.path.join(processed_folder, f\"{id_code}.png\") for id_code in train_sample_ids],\n","                sample_ids=train_sample_ids,\n","                temp_augment_dir=TEMP_AUGMENT_DIR\n","            )\n","            valid_generator = My_Generator(\n","                images=None,\n","                labels=valid_y_multi,\n","                batch_size=BATCH_SIZE,\n","                is_train=False,\n","                mix=False,\n","                augment=False,\n","                model_type=config['model_type'],\n","                preprocess=config['preprocess'],\n","                image_paths=[os.path.join(processed_folder, f\"{id_code}.png\") for id_code in valid_sample_ids],\n","                sample_ids=valid_sample_ids,\n","                temp_augment_dir=TEMP_AUGMENT_DIR\n","            )\n","\n","            # Load model and create feature extractor\n","            base_model = load_model_from_config(\n","                config['config_path'],\n","                config['weights_path'],\n","                config['base_model'],\n","                input_shape=(config['img_size'], config['img_size'], 3)\n","            )\n","            feature_layer = base_model.layers[-2].output\n","            feature_extractor = Model(inputs=base_model.input, outputs=feature_layer)\n","\n","            # Extract and save features\n","            train_features, train_features_ids = extract_and_save_features(\n","                model_name, feature_extractor, train_generator, feature_save_dir, sample_ids=train_sample_ids\n","            )\n","            valid_features, valid_features_ids = extract_and_save_features(\n","                model_name, feature_extractor, valid_generator, feature_save_dir, sample_ids=valid_sample_ids\n","            )\n","\n","            train_features_dict[model_name] = train_features\n","            valid_features_dict[model_name] = valid_features\n","\n","            # Clean up\n","            del base_model, feature_extractor\n","            tf.keras.backend.clear_session()\n","            gc.collect()\n","\n","        # Combine and reduce features (skip PCA to keep 1024 dims)\n","        train_combined, train_labels, train_indices, input_dim = combine_and_reduce_features(\n","            train_features_dict, {}, balanced_train_y_multi, train_sample_ids, feature_save_dir, n_components=None\n","        )\n","        valid_combined, valid_labels, valid_indices, _ = combine_and_reduce_features(\n","            valid_features_dict, {}, valid_y_multi, valid_sample_ids, feature_save_dir, n_components=None\n","        )\n","\n","        # Create feature extractor for validation\n","        img_size = model_configs[\"efficientnetb1\"][\"img_size\"]\n","        base_model = load_model_from_config(\n","            model_configs[\"efficientnetb1\"][\"config_path\"],\n","            model_configs[\"efficientnetb1\"][\"weights_path\"],\n","            model_configs[\"efficientnetb1\"][\"base_model\"],\n","            input_shape=(img_size, img_size, 3)\n","        )\n","        feature_layer = base_model.layers[-2].output\n","        feature_extractor = Model(inputs=base_model.input, outputs=feature_layer)\n","        valid_images_preprocessed = model_configs[\"efficientnetb1\"][\"preprocess\"](valid_images)\n","        valid_features_2d = feature_extractor.predict(valid_images_preprocessed, batch_size=BATCH_SIZE)\n","        del base_model, feature_extractor\n","        tf.keras.backend.clear_session()\n","        gc.collect()\n","\n","        # Build meta-model\n","        meta_model = build_meta_conv_model(\n","            img_shape=(img_size, img_size, 3),\n","            feature_2d_shape=(1024,),\n","            num_classes=NUM_CLASSES\n","        )\n","\n","        # Train meta-model\n","        meta_model, meta_classification_model, history = maml_fomaml_train_manual(\n","            meta_model=meta_model,\n","            data_df=pd.DataFrame({'id_code': np.array(train_sample_ids)[train_indices], 'diagnosis': np.argmax(train_labels[train_indices], axis=1)}),\n","            valid_features=valid_features_2d,\n","            valid_labels=valid_y_multi[valid_indices],\n","            valid_images=valid_images[valid_indices],\n","            input_dim=input_dim,\n","            model_type=\"efficientnetb1\",\n","            n_episodes=n_episodes,\n","            sample_ids=np.array(valid_sample_ids)[valid_indices],\n","            **kwargs\n","        )\n","\n","        # Predict and evaluate\n","        logging.info(f\"Valid images shape: {valid_images_preprocessed.shape}\")\n","        logging.info(f\"Valid features 2D shape: {valid_features_2d.shape}\")\n","        if valid_images_preprocessed.shape[0] != valid_features_2d.shape[0]:\n","            logging.error(f\"Sample count mismatch: images={valid_images_preprocessed.shape[0]}, features={valid_features_2d.shape[0]}\")\n","            raise ValueError(\"Sample count mismatch\")\n","\n","        _, y_pred = meta_classification_model.predict(\n","            [valid_images_preprocessed[valid_indices], valid_features_2d[valid_indices]], batch_size=BATCH_SIZE\n","        )\n","        y_pred_classes = np.argmax(y_pred, axis=1)\n","        y_true = np.argmax(valid_y_multi[valid_indices], axis=1)\n","\n","        qwk = cohen_kappa_score(y_true, y_pred_classes, labels=[0, 1, 2, 3, 4], weights='quadratic')\n","        f1 = f1_score(y_true, y_pred_classes, average='weighted')\n","        recall = recall_score(y_true, y_pred_classes, average='weighted')\n","\n","        cv_results[\"qwk\"].append(qwk)\n","        cv_results[\"f1\"].append(f1)\n","        cv_results[\"recall\"].append(recall)\n","\n","        logging.info(f\"Fold {fold + 1}: QWK={qwk:.4f}, F1={f1:.4f}, Recall={recall:.4f}\")\n","\n","        # Save confusion matrix\n","        save_confusion_matrix(y_true, y_pred_classes, fold, qwk, feature_save_dir, prefix=f'fold_{fold + 1}_')\n","\n","        # Clean up\n","        del meta_model, meta_classification_model\n","        tf.keras.backend.clear_session()\n","        gc.collect()\n","\n","    # Summarize results\n","    cv_summary = {\n","        \"mean_qwk\": np.mean(cv_results[\"qwk\"]) if cv_results[\"qwk\"] else 0.0,\n","        \"std_qwk\": np.std(cv_results[\"qwk\"]) if cv_results[\"qwk\"] else 0.0,\n","        \"mean_f1\": np.mean(cv_results[\"f1\"]) if cv_results[\"f1\"] else 0.0,\n","        \"std_f1\": np.std(cv_results[\"f1\"]) if cv_results[\"f1\"] else 0.0,\n","        \"mean_recall\": np.mean(cv_results[\"recall\"]) if cv_results[\"recall\"] else 0.0,\n","        \"std_recall\": np.std(cv_results[\"recall\"]) if cv_results[\"recall\"] else 0.0\n","    }\n","\n","    summary_path = Path(feature_save_dir) / \"cross_validation_summary.json\"\n","    with open(summary_path, 'w') as f:\n","        json.dump(cv_summary, f, indent=4)\n","    logging.info(f\"Saved cross-validation summary at: {summary_path}\")\n","\n","    return cv_results\n","# Hàm hyperparameter tuning\n","def hyperparameter_tuning(\n","    x, y, processed_folder, model_configs, feature_save_dir, param_grid, n_iter=10, n_episodes=20\n","):\n","    if n_iter is None:\n","        param_combinations = list(product(*param_grid.values()))\n","    else:\n","        param_combinations = [\n","            {k: random.choice(v) for k, v in param_grid.items()} for _ in range(n_iter)\n","        ]\n","\n","    best_qwk = -float('inf')\n","    best_params = None\n","\n","    for params in param_combinations:\n","        logging.info(f\"Thử tham số: {params}\")\n","\n","        cv_results = cross_validate_pipeline(\n","            x, y, processed_folder, model_configs, feature_save_dir, n_splits=3, n_episodes=n_episodes, **params\n","        )\n","\n","        mean_qwk = np.mean(cv_results[\"qwk\"])\n","        if mean_qwk > best_qwk:\n","            best_qwk = mean_qwk\n","            best_params = params\n","\n","        logging.info(f\"Mean QWK: {mean_qwk:.4f}\")\n","\n","    logging.info(f\"Tham số tốt nhất: {best_params}, QWK tốt nhất: {best_qwk:.4f}\")\n","\n","    return best_params, best_qwk\n","\n","# Hàm tạo Grad-CAM heatmap\n","def generate_gradcam_heatmap(\n","    meta_conv_model,\n","    img_array,\n","    feature_2d,\n","    class_idx,\n","    conv_layer_output='conv2d_3'  # Tên tầng cuối cùng trong build_meta_conv_model\n","):\n","    try:\n","        # Tạo mô hình trung gian để lấy conv_features\n","        intermediate_model = Model(\n","            inputs=meta_conv_model.input,\n","            outputs=meta_conv_model.get_layer(conv_layer_output).output\n","        )\n","        with tf.GradientTape() as tape:\n","            conv_output = intermediate_model([img_array, feature_2d], training=False)\n","            tape.watch(conv_output)\n","            _, predictions = meta_conv_model([img_array, feature_2d], training=False)\n","            loss = predictions[:, class_idx]\n","        grads = tape.gradient(loss, conv_output)\n","        if grads is None:\n","            logging.error(f\"Gradient trả về None cho class {class_idx}\")\n","            return None\n","        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","        conv_output = conv_output[0]\n","        heatmap = tf.reduce_mean(tf.multiply(conv_output, pooled_grads), axis=-1)\n","        heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-10)\n","        heatmap = tf.image.resize(\n","            heatmap[..., tf.newaxis],\n","            [img_array.shape[1], img_array.shape[2]],\n","            method='bilinear'\n","        )\n","        heatmap = tf.squeeze(heatmap).numpy()\n","        return heatmap\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi tạo Grad-CAM: {str(e)}\")\n","        return None\n","\n","# Hàm ensemble predictions\n","def ensemble_predictions(model_configs, generators, test_ids, feature_save_dir, weights=None, meta_classification_model=None):\n","    predictions = []\n","\n","    for model_name, config in model_configs.items():\n","        logging.info(f\"Trích xuất đặc trưng cho {model_name}...\")\n","        base_model = load_model_from_config(\n","            config['config_path'], config['weights_path'], config['base_model']\n","        )\n","        feature_layer = base_model.layers[-2].output\n","        feature_extractor = Model(inputs=base_model.input, outputs=feature_layer)\n","\n","        features_2d, _ = extract_and_save_features(\n","            model_name,\n","            feature_extractor,\n","            generators[model_name],\n","            feature_save_dir,\n","            sample_ids=test_ids\n","        )\n","\n","        probs = meta_classification_model.predict(features_2d, batch_size=32)\n","        predictions.append(probs)\n","\n","        del base_model, feature_extractor\n","        tf.keras.backend.clear_session()\n","        gc.collect()\n","        logging.info(f\"Đã trích xuất {len(features_2d)} đặc trưng cho {model_name}\")\n","\n","    weights = weights or [1.0 / len(predictions)] * len(predictions)\n","    ensemble_probs = np.average(predictions, axis=0, weights=weights)\n","    return ensemble_probs\n","\n","# Hàm tạo pipeline report\n","def generate_pipeline_report(\n","    dataset_stats, cv_results, test_metrics, runtime, save_dir, filename=\"pipeline_report.json\"\n","):\n","    report = {\n","        \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n","        \"dataset_statistics\": dataset_stats,\n","        \"cross_validation_results\": cv_results,\n","        \"test_metrics\": test_metrics,\n","        \"runtime_seconds\": runtime,\n","        \"model_configurations\": list(MODEL_CONFIGS.keys()),\n","        \"num_classes\": NUM_CLASSES,\n","        \"image_size\": SIZE\n","    }\n","\n","    report_path = Path(save_dir) / filename\n","    with open(report_path, 'w') as f:\n","        json.dump(report, f, indent=4)\n","    logging.info(f\"Đã lưu báo cáo pipeline tại: {report_path}\")\n","\n","\n","def prepare_data():\n","    try:\n","        df_train = pd.read_csv(os.path.join(DRIVE_FOLDER, \"train.csv\"))\n","        logging.info(f\"Đã đọc train.csv: {len(df_train)} mẫu\")\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi đọc train.csv: {str(e)}\")\n","        return None, None, None, None, None, None, None, None, None, None, None, None\n","\n","    if not {'id_code', 'diagnosis'}.issubset(df_train.columns):\n","        logging.error(\"File train.csv thiếu cột 'id_code' hoặc 'diagnosis'.\")\n","        return None, None, None, None, None, None, None, None, None, None, None, None\n","\n","    # Xác thực dataset một lần\n","    processed_image_ids = validate_dataset(get_image_ids(PROCESSED_FOLDER), PROCESSED_FOLDER, FEATURE_SAVE_DIR)\n","    if not processed_image_ids:\n","        logging.error(\"Không tìm thấy ảnh trong PROCESSED_FOLDER.\")\n","        return None, None, None, None, None, None, None, None, None, None, None, None\n","    logging.info(f\"Tìm thấy {len(processed_image_ids)} ID ảnh trong PROCESSED_FOLDER: {processed_image_ids[:5]}...\")\n","\n","    # Lọc df_train\n","    df_train_processed = df_train[df_train['id_code'].isin(processed_image_ids)].copy()\n","    logging.info(f\"Số mẫu sau khi lọc với PROCESSED_FOLDER: {len(df_train_processed)}\")\n","\n","    if df_train_processed.empty:\n","        logging.error(\"Không có mẫu hợp lệ sau khi lọc.\")\n","        return None, None, None, None, None, None, None, None, None, None, None, None\n","\n","    x = df_train_processed['id_code']\n","    y = df_train_processed['diagnosis']\n","    x, y = shuffle(x, y, random_state=42)\n","\n","    # Chia dữ liệu\n","    x_temp, test_x, y_temp, test_y = train_test_split(x, y, test_size=0.20, stratify=y, random_state=42)\n","    train_x, valid_x, train_y, valid_y = train_test_split(x_temp, y_temp, test_size=0.15/0.80, stratify=y_temp, random_state=42)\n","\n","    train_ids = np.array(train_x)\n","    valid_ids = np.array(valid_x)\n","    test_ids = np.array(test_x)\n","\n","    # Kiểm tra rò rỉ dữ liệu\n","    if not check_data_leakage(train_ids, valid_ids, test_ids, df_train_processed):\n","        logging.error(\"Phát hiện data leakage.\")\n","        raise ValueError(\"Data leakage được phát hiện.\")\n","\n","    logging.info(f\"Số mẫu: Train={len(train_x)}, Valid={len(valid_x)}, Test={len(test_x)}\")\n","\n","    # Tải ảnh train\n","    train_images = []\n","    train_ids_filtered = []\n","    train_y_filtered = []\n","    train_error_ids = []\n","    for id_code, label in zip(train_x, train_y):\n","        img = load_processed_image(id_code, PROCESSED_FOLDER, model_type=\"efficientnetb1\")\n","        if img is not None:\n","            train_images.append(img)\n","            train_ids_filtered.append(id_code)\n","            train_y_filtered.append(label)\n","        else:\n","            train_error_ids.append(id_code)\n","            logging.warning(f\"Không tải được ảnh train: {id_code}\")\n","    if not train_images:\n","        logging.error(\"Không tải được ảnh train nào.\")\n","        raise ValueError(\"Tập train rỗng sau khi lọc.\")\n","    train_images = np.array(train_images)\n","    train_y_filtered = np.array(train_y_filtered)\n","    train_ids_filtered = np.array(train_ids_filtered)\n","    logging.info(f\"Train: {len(train_images)} ảnh, {len(train_ids_filtered)} IDs, {len(train_y_filtered)} nhãn, {len(train_error_ids)} lỗi\")\n","\n","    # Tải ảnh valid\n","    valid_images = []\n","    valid_ids_filtered = []\n","    valid_y_filtered = []\n","    valid_error_ids = []\n","    for id_code, label in zip(valid_x, valid_y):\n","        img = load_processed_image(id_code, PROCESSED_FOLDER, model_type=\"efficientnetb1\")\n","        if img is not None:\n","            valid_images.append(img)\n","            valid_ids_filtered.append(id_code)\n","            valid_y_filtered.append(label)\n","        else:\n","            valid_error_ids.append(id_code)\n","            logging.warning(f\"Không tải được ảnh valid: {id_code}\")\n","    valid_images = np.array(valid_images)\n","    valid_y_filtered = np.array(valid_y_filtered)\n","    valid_ids_filtered = np.array(valid_ids_filtered)\n","    logging.info(f\"Valid: {len(valid_images)} ảnh, {len(valid_ids_filtered)} IDs, {len(valid_y_filtered)} nhãn, {len(valid_error_ids)} lỗi\")\n","\n","    # Tải ảnh test\n","    test_images = []\n","    test_ids_filtered = []\n","    test_y_filtered = []\n","    test_error_ids = []\n","    for id_code, label in zip(test_x, test_y):\n","        img = load_processed_image(id_code, PROCESSED_FOLDER, model_type=\"efficientnetb1\")\n","        if img is not None:\n","            test_images.append(img)\n","            test_ids_filtered.append(id_code)\n","            test_y_filtered.append(label)\n","        else:\n","            test_error_ids.append(id_code)\n","            logging.warning(f\"Không tải được ảnh test: {id_code}\")\n","    test_images = np.array(test_images)\n","    test_y_filtered = np.array(test_y_filtered)\n","    test_ids_filtered = np.array(test_ids_filtered)\n","    logging.info(f\"Test: {len(test_images)} ảnh, {len(test_ids_filtered)} IDs, {len(test_y_filtered)} nhãn, {len(test_error_ids)} lỗi\")\n","\n","    # Lưu báo cáo lỗi\n","    error_report = {\n","        \"train_error_ids\": train_error_ids,\n","        \"valid_error_ids\": valid_error_ids,\n","        \"test_error_ids\": test_error_ids,\n","        \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n","    }\n","    error_report_path = os.path.join(FEATURE_SAVE_DIR, \"image_load_errors.json\")\n","    with open(error_report_path, 'w') as f:\n","        json.dump(error_report, f, indent=4)\n","    logging.info(f\"Đã lưu báo cáo ảnh lỗi tại: {error_report_path}\")\n","\n","    # Chuyển nhãn sang one-hot encoding\n","    train_y_multi = tf.keras.utils.to_categorical(train_y_filtered, num_classes=NUM_CLASSES)\n","    valid_y_multi = tf.keras.utils.to_categorical(valid_y_filtered, num_classes=NUM_CLASSES)\n","    test_y_multi = tf.keras.utils.to_categorical(test_y_filtered, num_classes=NUM_CLASSES)\n","\n","    # Không cân bằng dữ liệu\n","    balanced_train_x = train_images\n","    balanced_train_y_multi = train_y_multi\n","    balanced_train_ids = train_ids_filtered\n","\n","    # Báo cáo phân bố nhãn\n","    label_indices = np.argmax(balanced_train_y_multi, axis=1)\n","    class_counts = np.bincount(label_indices, minlength=NUM_CLASSES)\n","    logging.info(f\"Phân bố nhãn tập train: {dict(zip(range(NUM_CLASSES), class_counts))}\")\n","\n","    return (balanced_train_x, balanced_train_y_multi, valid_images, valid_y_multi, test_images, test_y_multi,\n","            df_train_processed, train_ids_filtered, valid_ids_filtered, test_ids_filtered, balanced_train_ids, processed_image_ids)\n","\n","def main_pipeline(\n","    balanced_train_x, balanced_train_y_multi, valid_images, valid_y_multi, test_images, test_y_multi,\n","    df_train_processed, train_ids, valid_ids, test_ids, balanced_train_ids, processed_image_ids\n","):\n","    start_time = time.time()\n","    logging.info(\"Starting pipeline...\")\n","\n","    # Initialize dictionaries for features\n","    train_features_dict = {}\n","    valid_features_dict = {}\n","    test_features_dict = {}\n","    meta_models = {}\n","    BATCH_SIZE = 16  # Reduced for memory efficiency\n","\n","    # Filter test data to match processed IDs\n","    test_indices = [i for i, sid in enumerate(test_ids) if sid in processed_image_ids]\n","    if not test_indices:\n","        logging.error(\"No test samples match processed_image_ids.\")\n","        raise ValueError(\"No valid test samples.\")\n","    test_images = test_images[test_indices]\n","    test_y_multi = test_y_multi[test_indices]\n","    test_ids = [test_ids[i] for i in test_indices]\n","    logging.info(f\"Filtered test data: {len(test_indices)} samples\")\n","\n","    # Process each model\n","    for model_name in MODEL_CONFIGS:\n","        logging.info(f\"Processing {model_name}...\")\n","        try:\n","            config = MODEL_CONFIGS[model_name]\n","            input_shape = (config['img_size'], config['img_size'], 3)\n","\n","            # Load base model and create feature extractor\n","            base_model = load_model_from_config(\n","                config['config_path'], config['weights_path'], config['base_model'], input_shape\n","            )\n","            feature_2d_layers = [\n","                layer for layer in base_model.layers\n","                if not isinstance(layer, tf.keras.layers.InputLayer) and len(layer.output.shape) == 2\n","            ]\n","            if not feature_2d_layers:\n","                logging.error(f\"No 2D layers found in {model_name}\")\n","                continue\n","            selected_layer = feature_2d_layers[-1]\n","            feature_extractor = tf.keras.Model(inputs=base_model.input, outputs=selected_layer.output)\n","            logging.info(f\"Feature extractor output shape: {selected_layer.output.shape}\")\n","\n","            # Create generators\n","            train_generator = My_Generator(\n","                images=balanced_train_x, labels=balanced_train_y_multi, batch_size=BATCH_SIZE,\n","                is_train=True, model_type=model_name, preprocess=config['preprocess'],\n","                sample_ids=balanced_train_ids\n","            )\n","            valid_generator = My_Generator(\n","                images=valid_images, labels=valid_y_multi, batch_size=BATCH_SIZE,\n","                model_type=model_name, preprocess=config['preprocess'], sample_ids=valid_ids\n","            )\n","            test_generator = My_Generator(\n","                images=test_images, labels=test_y_multi, batch_size=BATCH_SIZE,\n","                model_type=model_name, preprocess=config['preprocess'], sample_ids=test_ids\n","            )\n","\n","            # Extract features\n","            def extract_features(generator, feature_extractor):\n","                features = []\n","                feature_ids = []\n","                for batch_idx in range(len(generator)):\n","                    batch_images, _, batch_ids = generator[batch_idx]\n","                    if len(batch_images) == 0:\n","                        logging.warning(f\"Empty batch {batch_idx}, skipping\")\n","                        continue\n","                    batch_features = feature_extractor.predict(\n","                        batch_images, batch_size=BATCH_SIZE, verbose=0\n","                    )\n","                    if len(batch_features.shape) > 2:\n","                        batch_features = np.mean(batch_features, axis=(1, 2))\n","                    features.append(batch_features)\n","                    feature_ids.extend(batch_ids)\n","                    tf.keras.backend.clear_session()\n","                    gc.collect()\n","                if not features:\n","                    raise ValueError(\"No features extracted.\")\n","                return np.concatenate(features, axis=0), feature_ids\n","\n","            train_features, train_feature_ids = extract_features(train_generator, feature_extractor)\n","            valid_features, valid_feature_ids = extract_features(valid_generator, feature_extractor)\n","            test_features, test_feature_ids = extract_features(test_generator, feature_extractor)\n","\n","            # Verify feature consistency\n","            if len(train_features) != len(balanced_train_ids) or len(valid_features) != len(valid_ids) or len(test_features) != len(test_ids):\n","                logging.error(f\"Feature count mismatch for {model_name}\")\n","                continue\n","\n","            train_features_dict[model_name] = train_features\n","            valid_features_dict[model_name] = valid_features\n","            test_features_dict[model_name] = test_features\n","            logging.info(f\"Extracted features for {model_name}: train={len(train_features)}, valid={len(valid_features)}, test={len(test_features)}\")\n","\n","            # Save features\n","            os.makedirs(FEATURE_SAVE_DIR, exist_ok=True)\n","            np.save(os.path.join(FEATURE_SAVE_DIR, f\"{model_name}_train_features.npy\"), train_features)\n","            np.save(os.path.join(FEATURE_SAVE_DIR, f\"{model_name}_valid_features.npy\"), valid_features)\n","            np.save(os.path.join(FEATURE_SAVE_DIR, f\"{model_name}_test_features.npy\"), test_features)\n","\n","            # Train meta-model\n","            meta_model = build_meta_conv_model(\n","                img_shape=input_shape,\n","                feature_2d_shape=(train_features.shape[1],),\n","                num_classes=NUM_CLASSES\n","            )\n","            cm_callback = ConfusionMatrixWeightCallback(\n","                valid_features=[config['preprocess'](valid_images), valid_features],\n","                valid_labels=valid_y_multi,\n","                classification_model=meta_model,\n","                num_classes=NUM_CLASSES,\n","                class_counts=np.sum(valid_y_multi, axis=0)\n","            )\n","            checkpoint_callback = MultiMetricCheckpoint(\n","                filepath=os.path.join(FEATURE_SAVE_DIR, f\"meta_model_best_{model_name}_{{epoch}}.weights.h5\"),\n","                monitor_metrics={'qwk': 'max', 'f1': 'max'},\n","                mode='max',\n","                save_best_only=True\n","            )\n","            meta_model, history = maml_fomaml_train_manual(\n","                meta_model=meta_model,\n","                data_df=df_train_processed,\n","                valid_features=valid_features,\n","                valid_labels=valid_y_multi,\n","                valid_images=valid_images,\n","                input_dim=train_features.shape[1],\n","                model_type=model_name,\n","                support_size=16,\n","                query_size=16,\n","                save_dir=FEATURE_SAVE_DIR,\n","                sample_ids=valid_ids,\n","                callbacks=[cm_callback, checkpoint_callback]\n","            )\n","            meta_models[model_name] = meta_model\n","            logging.info(f\"Trained meta-model for {model_name}\")\n","\n","            # Clear memory\n","            del base_model, feature_extractor, train_generator, valid_generator, test_generator\n","            tf.keras.backend.clear_session()\n","            gc.collect()\n","            check_memory()\n","\n","        except Exception as e:\n","            logging.error(f\"Error processing {model_name}: {str(e)}\")\n","            continue\n","\n","    # Ensemble predictions\n","    logging.info(\"Ensembling predictions...\")\n","    ensemble_probs = []\n","    successful_models = []\n","    for model_name in meta_models:\n","        try:\n","            test_features = test_features_dict[model_name]\n","            test_images_preprocessed = MODEL_CONFIGS[model_name]['preprocess'](test_images)\n","            probs = meta_models[model_name].predict(\n","                [test_images_preprocessed, test_features],\n","                batch_size=BATCH_SIZE,\n","                verbose=0\n","            )[1]  # Get softmax probabilities\n","            probs = apply_temperature_scaling(probs, temperature=0.1)\n","            probs = laplace_smoothing(probs)\n","            ensemble_probs.append(probs)\n","            successful_models.append(model_name)\n","            logging.info(f\"Predicted for {model_name}: shape={probs.shape}\")\n","        except Exception as e:\n","            logging.error(f\"Prediction error for {model_name}: {str(e)}\")\n","            continue\n","\n","    # Compute final predictions\n","    if not ensemble_probs:\n","        logging.warning(\"No valid predictions. Using default zero probabilities.\")\n","        final_probs = np.zeros((len(test_y_multi), NUM_CLASSES))\n","        y_pred_classes = np.zeros(len(test_y_multi), dtype=np.int32)\n","        y_true = np.argmax(test_y_multi, axis=1)\n","    else:\n","        weights = np.array([1.0 / len(ensemble_probs)] * len(ensemble_probs))\n","        final_probs = np.average(ensemble_probs, axis=0, weights=weights)\n","        y_pred_classes = np.argmax(final_probs, axis=1)\n","        y_true = np.argmax(test_y_multi, axis=1)\n","\n","    # Evaluate\n","    qwk = cohen_kappa_score(y_true, y_pred_classes, labels=range(NUM_CLASSES), weights='quadratic')\n","    f1 = f1_score(y_true, y_pred_classes, average='weighted')\n","    recall = recall_score(y_true, y_pred_classes, average='weighted')\n","    logging.info(f\"Ensemble results: QWK={qwk:.4f}, F1={f1:.4f}, Recall={recall:.2f}\")\n","\n","    # Generate report\n","    test_metrics = {\n","        \"qwk\": float(qwk),\n","        \"f1_score\": float(f1),\n","        \"recall\": float(recall),\n","        \"successful_models\": successful_models\n","    }\n","    dataset_stats = {\n","        \"train_samples\": len(balanced_train_x),\n","        \"valid_samples\": len(valid_images),\n","        \"test_samples\": len(test_images),\n","        \"class_distribution\": np.sum(test_y_multi, axis=0).tolist()\n","    }\n","    runtime = time.time() - start_time\n","    generate_pipeline_report(dataset_stats, {}, test_metrics, runtime, FEATURE_SAVE_DIR)\n","\n","    logging.info(f\"Pipeline completed in {runtime:.2f} seconds.\")\n","    return {\n","        \"train_features_dict\": train_features_dict,\n","        \"valid_features_dict\": valid_features_dict,\n","        \"test_features_dict\": test_features_dict,\n","        \"meta_models\": meta_models\n","    }\n","\n","def run_pipeline(tune_hyperparameters=False, use_gpu=True):\n","    start_time = time.time()\n","    logging.info(f\"Bắt đầu pipeline tại: {datetime.now().strftime('%H:%M:%S %d/%m/%Y')}\")\n","\n","    try:\n","        # Kiểm tra môi trường\n","        if not os.path.ismount('/content/drive'):\n","            logging.error(\"Google Drive chưa được mount.\")\n","            raise RuntimeError(\"Yêu cầu mount Google Drive.\")\n","        for folder in [FEATURE_SAVE_DIR, PROCESSED_FOLDER, DRIVE_FOLDER]:\n","            if not os.path.exists(folder):\n","                logging.error(f\"Thư mục không tồn tại: {folder}\")\n","                raise FileNotFoundError(f\"Thư mục không tồn tại: {folder}\")\n","            logging.info(f\"Thư mục tồn tại: {folder}\")\n","\n","        # Cấu hình GPU hoặc CPU\n","        if use_gpu:\n","            physical_devices = tf.config.list_physical_devices('GPU')\n","            if physical_devices:\n","                for device in physical_devices:\n","                    tf.config.experimental.set_memory_growth(device, True)\n","                    logging.info(f\"Đã bật memory growth cho {device}\")\n","            else:\n","                logging.warning(\"Không tìm thấy GPU, chuyển sang CPU.\")\n","                use_gpu = False\n","        else:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n","            logging.info(\"Chạy trên CPU theo yêu cầu.\")\n","\n","        os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices=false'\n","        logging.info(\"Đã tắt XLA compilation.\")\n","        from tensorflow.keras.mixed_precision import set_global_policy\n","        set_global_policy('mixed_float16')\n","        logging.info(\"Đã bật mixed precision.\")\n","\n","        # Chuẩn bị dữ liệu\n","        logging.info(\"Chuẩn bị dữ liệu...\")\n","        data = prepare_data()\n","        if data is None or any(x is None for x in data):\n","            logging.error(\"Chuẩn bị dữ liệu thất bại.\")\n","            raise ValueError(\"Chuẩn bị dữ liệu thất bại.\")\n","\n","        (balanced_train_x, balanced_train_y_multi, valid_images, valid_y_multi, test_images, test_y_multi,\n","         df_train_processed, train_ids, valid_ids, test_ids, balanced_train_ids, processed_image_ids) = data\n","\n","        logging.info(f\"Kích thước dataset: train={len(balanced_train_x)}, valid={len(valid_images)}, test={len(test_images)}\")\n","\n","        # Kiểm tra rò rỉ dữ liệu\n","        if not check_data_leakage(train_ids, valid_ids, test_ids, df_train_processed):\n","            logging.error(\"Phát hiện rò rỉ dữ liệu.\")\n","            raise ValueError(\"Rò rỉ dữ liệu được phát hiện.\")\n","        logging.info(\"Không phát hiện rò rỉ dữ liệu.\")\n","\n","        # Kiểm tra cấu hình mô hình\n","        validate_model_configs(MODEL_CONFIGS)\n","        logging.info(\"Xác thực cấu hình mô hình hoàn tất.\")\n","\n","        # Tối ưu siêu tham số\n","        best_params = {'inner_lr': 0.01, 'outer_lr': 0.001, 'batch_size': 8}\n","        if tune_hyperparameters:\n","            logging.info(\"Tối ưu siêu tham số...\")\n","            param_grid = {\n","                'inner_lr': [0.01, 0.001],\n","                'outer_lr': [0.001, 0.0001],\n","                'batch_size': [8, 16]\n","            }\n","            best_params, best_qwk = hyperparameter_tuning(\n","                df_train_processed['id_code'],\n","                df_train_processed['diagnosis'].values,\n","                PROCESSED_FOLDER,\n","                MODEL_CONFIGS,\n","                FEATURE_SAVE_DIR,\n","                param_grid,\n","                n_iter=5,\n","                n_episodes=10\n","            )\n","            logging.info(f\"Tham số tốt nhất: {best_params}, QWK tốt nhất: {best_qwk:.4f}\")\n","\n","        # Kiểm tra bộ nhớ\n","        available_memory = check_memory()\n","        if available_memory is None or available_memory < 1.0:\n","            logging.warning(f\"Bộ nhớ thấp: {available_memory} GB.\")\n","\n","        # Chạy pipeline chính\n","        logging.info(\"Chạy pipeline chính...\")\n","        pipeline_results = main_pipeline(\n","            balanced_train_x,\n","            balanced_train_y_multi,\n","            valid_images,\n","            valid_y_multi,\n","            test_images,\n","            test_y_multi,\n","            df_train_processed,\n","            train_ids,\n","            valid_ids,\n","            test_ids,\n","            balanced_train_ids,\n","            processed_image_ids\n","        )\n","\n","        train_features_dict = pipeline_results['train_features_dict']\n","        valid_features_dict = pipeline_results['valid_features_dict']\n","        test_features_dict = pipeline_results['test_features_dict']\n","\n","        # Tạo báo cáo\n","        dataset_stats = {\n","            'train_samples': len(balanced_train_x),\n","            'valid_samples': len(valid_images),\n","            'test_samples': len(test_images),\n","            'class_distribution': np.bincount(np.argmax(balanced_train_y_multi, axis=1)).tolist()\n","        }\n","        cv_results = {}\n","        test_metrics = {}\n","        runtime = time.time() - start_time\n","        generate_pipeline_report(dataset_stats, cv_results, test_metrics, runtime, FEATURE_SAVE_DIR)\n","\n","        logging.info(f\"Pipeline hoàn tất sau {runtime:.2f} giây!\")\n","        return train_features_dict, valid_features_dict, test_features_dict\n","\n","    except Exception as e:\n","        logging.error(f\"Pipeline thất bại: {str(e)}\")\n","        raise\n","    finally:\n","        logging.info(\"Dọn dẹp tài nguyên...\")\n","        tf.keras.backend.clear_session()\n","        gc.collect()\n","        logging.info(f\"Pipeline kết thúc tại: {datetime.now().strftime('%H:%M:%S %d/%m/%Y')}\")\n","\n","if __name__ == \"__main__\":\n","    # Chạy pipeline với tùy chọn hyperparameter tuning\n","    train_features_dict, valid_features_dict, test_features_dict = run_pipeline(tune_hyperparameters=False)"]},{"cell_type":"code","source":["!pip install GPUtil"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6WqhZ6UtDZ6v","executionInfo":{"status":"ok","timestamp":1749022094058,"user_tz":-420,"elapsed":3988,"user":{"displayName":"Resconnect","userId":"00882996269091038835"}},"outputId":"e9beb35b-0e86-4e09-dd27-ac544e2684b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting GPUtil\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: GPUtil\n","  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=9eb9bb1c2a4699c385210cbaf09bca6ca453f02d1af6995b7b6ea6fe967e853b\n","  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n","Successfully built GPUtil\n","Installing collected packages: GPUtil\n","Successfully installed GPUtil-1.4.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1748749944958,"user":{"displayName":"Resconnect","userId":"00882996269091038835"},"user_tz":-420},"id":"oVrwhQPC9CYm","outputId":"39e0c091-967a-467b-8b99-afd1863c3830"},"outputs":[{"name":"stdout","output_type":"stream","text":["Bắt đầu so sánh id_code với PROCESSED_FOLDER...\n","Đã đọc file CSV: 3662 mẫu\n","Số id_code trong df_train: 3662\n","Mẫu id_code: ['2fde69f20585', '8dc22e65c06f', 'ea05c22d92e9', 'a721efb1e049', '0eced86c9db8']...\n","Số tệp ảnh trong PROCESSED_FOLDER: 3662\n","Mẫu processed_ids: ['2fde69f20585', '8dc22e65c06f', 'ea05c22d92e9', 'a721efb1e049', '0eced86c9db8']...\n","Số ID khớp: 3662\n","Số ID trong df_train nhưng không có trong PROCESSED_FOLDER: 0\n","Số tệp ảnh trong PROCESSED_FOLDER nhưng không có trong df_train: 0\n","Đã lưu báo cáo tại: /content/drive/MyDrive/working/id_code_comparison_report.json\n","Hoàn tất so sánh.\n"]}],"source":["import pandas as pd\n","import os\n","import json\n","from pathlib import Path\n","\n","def compare_id_code_with_processed_folder(csv_path, processed_folder, output_dir):\n","    \"\"\"\n","    So sánh df_train['id_code'] với các tệp ảnh trong PROCESSED_FOLDER.\n","\n","    Args:\n","        csv_path (str): Đường dẫn đến file train.csv\n","        processed_folder (str): Đường dẫn đến thư mục PROCESSED_FOLDER chứa ảnh .png\n","        output_dir (str): Thư mục để lưu báo cáo JSON\n","    \"\"\"\n","    try:\n","        # Kiểm tra và đọc file CSV\n","        if not os.path.exists(csv_path):\n","            print(f\"ERROR: File CSV không tồn tại: {csv_path}\")\n","            return\n","        df_train = pd.read_csv(csv_path)\n","        if 'id_code' not in df_train.columns:\n","            print(\"ERROR: File CSV không có cột 'id_code'\")\n","            return\n","        print(f\"Đã đọc file CSV: {len(df_train)} mẫu\")\n","\n","        # Lấy danh sách id_code từ DataFrame\n","        df_ids = set(df_train['id_code'].astype(str).values)\n","        print(f\"Số id_code trong df_train: {len(df_ids)}\")\n","        print(f\"Mẫu id_code: {list(df_ids)[:5]}...\")\n","\n","        # Lấy danh sách tệp ảnh từ PROCESSED_FOLDER\n","        if not os.path.exists(processed_folder):\n","            print(f\"ERROR: Thư mục PROCESSED_FOLDER không tồn tại: {processed_folder}\")\n","            return\n","        image_files = [f for f in os.listdir(processed_folder) if f.endswith('.png')]\n","        processed_ids = set(os.path.splitext(f)[0] for f in image_files)\n","        print(f\"Số tệp ảnh trong PROCESSED_FOLDER: {len(processed_ids)}\")\n","        print(f\"Mẫu processed_ids: {list(processed_ids)[:5]}...\")\n","\n","        # So sánh id_code và processed_ids\n","        matching_ids = df_ids.intersection(processed_ids)\n","        missing_in_processed = df_ids - processed_ids\n","        missing_in_df = processed_ids - df_ids\n","\n","        # Tạo báo cáo\n","        report = {\n","            \"timestamp\": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n","            \"csv_path\": csv_path,\n","            \"processed_folder\": processed_folder,\n","            \"total_df_ids\": len(df_ids),\n","            \"total_processed_ids\": len(processed_ids),\n","            \"matching_ids_count\": len(matching_ids),\n","            \"matching_ids_sample\": list(matching_ids)[:10],  # Lấy mẫu 10 ID khớp\n","            \"missing_in_processed_count\": len(missing_in_processed),\n","            \"missing_in_processed\": list(missing_in_processed),\n","            \"missing_in_df_count\": len(missing_in_df),\n","            \"missing_in_df\": list(missing_in_df)\n","        }\n","\n","        # In kết quả\n","        print(f\"Số ID khớp: {len(matching_ids)}\")\n","        print(f\"Số ID trong df_train nhưng không có trong PROCESSED_FOLDER: {len(missing_in_processed)}\")\n","        if missing_in_processed:\n","            print(f\"WARNING: Mẫu ID thiếu trong PROCESSED_FOLDER: {list(missing_in_processed)[:5]}...\")\n","        print(f\"Số tệp ảnh trong PROCESSED_FOLDER nhưng không có trong df_train: {len(missing_in_df)}\")\n","        if missing_in_df:\n","            print(f\"WARNING: Mẫu ID thiếu trong df_train: {list(missing_in_df)[:5]}...\")\n","\n","        # Lưu báo cáo vào file JSON\n","        os.makedirs(output_dir, exist_ok=True)\n","        report_path = os.path.join(output_dir, \"id_code_comparison_report.json\")\n","        with open(report_path, 'w', encoding='utf-8') as f:\n","            json.dump(report, f, indent=4)\n","        print(f\"Đã lưu báo cáo tại: {report_path}\")\n","\n","    except Exception as e:\n","        print(f\"ERROR: Lỗi trong quá trình so sánh: {str(e)}\")\n","        raise\n","\n","if __name__ == \"__main__\":\n","    # Thay đổi các đường dẫn này theo cấu hình của bạn\n","    CSV_PATH = \"/content/drive/MyDrive/kaggle_data/aptos2019/train.csv\"\n","    PROCESSED_FOLDER = \"/content/processed_train_images\"\n","    OUTPUT_DIR = \"/content/drive/MyDrive/working\"\n","\n","    print(\"Bắt đầu so sánh id_code với PROCESSED_FOLDER...\")\n","    compare_id_code_with_processed_folder(CSV_PATH, PROCESSED_FOLDER, OUTPUT_DIR)\n","    print(\"Hoàn tất so sánh.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1748707097938,"user":{"displayName":"Resconnect","userId":"00882996269091038835"},"user_tz":-420},"id":"kC9liHzBaRHO","outputId":"e5a56d2d-ddd0-4615-ed6f-fce514400002"},"outputs":[{"name":"stdout","output_type":"stream","text":["Missing images (0): []...\n"]}],"source":["import os\n","\n","PROCESSED_DIR = \"/content/processed_train_images\"\n","sample_ids = df_train_processed['id_code'].values\n","missing_images = []\n","for sample_id in sample_ids:\n","    img_path = os.path.join(PROCESSED_FOLDER, f\"{sample_id}.png\")\n","    if not os.path.exists(img_path):\n","        missing_images.append(sample_id)\n","print(f\"Missing images ({len(missing_images)}): {missing_images[:5]}...\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1748276574990,"user":{"displayName":"Resconnect","userId":"00882996269091038835"},"user_tz":-420},"id":"uZPTMEW3yut3","outputId":"6f0fd3a2-0922-4163-ec8a-fec3d2de2729"},"outputs":[{"name":"stdout","output_type":"stream","text":["Nội dung metadata:\n","{\n","    \"model_name\": \"efficientnetb1\",\n","    \"conv_layer_name\": \"top_conv\",\n","    \"features_2d_path\": \"/content/drive/MyDrive/working/efficientnetb1_features_2d.npy\",\n","    \"features_4d_path\": \"/content/drive/MyDrive/working/efficientnetb1_features_4d.npy\",\n","    \"sample_ids\": [\n","        \"189cbbc9e5e3\",\n","        \"d2901144070c\",\n","        \"b9519abce0c1\",\n","        \"b16dd4483ca5\",\n","        \"82bb8a01935f\",\n","        \"0c55d58bebaf\",\n","        \"80dbeb0fdc75\",\n","        \"2fdfb80ea53c\",\n","        \"239f2c348ea4\",\n","        \"041f09eec1e8\",\n","        \"5712e2aa73a2\",\n","        \"7ccf9d25dc48\",\n","        \"e4d3d437b0a8\",\n","        \"9be71d6d7e59\",\n","        \"9519a590985d\",\n","        \"165cd2070ebd\",\n","        \"437900a99871\",\n","        \"e599151ca14b\",\n","        \"89ed6a0dd53f\",\n","        \"d3e884109b45\",\n","        \"a11bf2edd470\",\n","        \"36a1e3c780a0\",\n","        \"1e8a1fdee5b9\",\n","        \"69df7ade0575\",\n","        \"5efa24b03d5e\",\n","        \"50915e2329a1\",\n","        \"e811f39a1243\",\n","        \"af87d48ffe01\",\n","        \"857230f64a2e\",\n","        \"cd54d022e37d\",\n","        \"780f9daaa24b\",\n","        \"595446774178\",\n","        \"b9b6ee2b9453\",\n","        \"8f10e41a2f02\",\n","        \"1fb455685328\",\n","        \"753b14c27c83\",\n","        \"178412895d5e\",\n","        \"b0c9a492e068\",\n","        \"2bbd1f99ecc3\",\n","        \"b960142a8de7\",\n","        \"de6210f88536\",\n","        \"405b4f78658f\",\n","        \"0790515cf5af\",\n","        \"cd01672507c9\",\n","        \"ae5d31979f19\",\n","        \"43bc7c066dfb\",\n","        \"cae51154e1ce\",\n","        \"a1edf0e66592\",\n","        \"851e40a21f81\",\n","        \"d2fb715b0c41\",\n","        \"6ba5ed791444\",\n","        \"a76b69e443ce\",\n","        \"c334f8688b77\",\n","        \"d6803e467592\",\n","        \"6bf26b777e3a\",\n","        \"4360a112db10\",\n","        \"435d900fa7b2\",\n","        \"d4bc001f7224\",\n","        \"f55e1d2a19e4\",\n","        \"cf8f1bc7a215\",\n","        \"63c0eafd6aa9\",\n","        \"5995321563b7\",\n","        \"03b373718013\",\n","        \"36e4b704b905\",\n","        \"2ef955d6d9ff\",\n","        \"906d02fb822d\",\n","        \"f72ef9ceeaa8\",\n","        \"dee687c6e88a\",\n","        \"10f6ef37fe43\",\n","        \"461fa5292fda\",\n","        \"46923eea9a4e\",\n","        \"a4d41c495666\",\n","        \"369229040a34\",\n","        \"f36cb007a1ef\",\n","        \"a06e5ac695ce\",\n","        \"941d874c8afb\",\n","        \"767d777ee889\",\n","        \"a80dab8eddf4\",\n","        \"35cd9832fc0a\",\n","        \"86baef833ae0\",\n","        \"b9fe7da14a32\",\n","        \"64c6c6ee0d98\",\n","        \"1541226c5d72\",\n","        \"1891698febce\",\n","        \"e42d9a94a66d\",\n","        \"5265dc9acdf8\",\n","        \"807135cbc438\",\n","        \"756b0d6488bb\",\n","        \"4dbce359d0e1\",\n","        \"9a326446c431\",\n","        \"db690e2d02f8\",\n","        \"d3e56584a481\",\n","        \"daff5427c9b2\",\n","        \"8846b09384a4\",\n","        \"857002ed4e49\",\n","        \"b6bfe9db60e5\",\n","        \"57469423a012\",\n","        \"0e75d51152fc\",\n","        \"f9d52509c571\",\n","        \"77e15f213b04\",\n","        \"891329021e12\",\n","        \"2967e578939f\",\n","        \"4da6e2089d57\",\n","        \"4da2961e62fe\",\n","        \"3823acc4e464\",\n","        \"ca0f1a17c8e5\",\n","        \"cbf0394039f8\",\n","        \"248dec89b3a2\",\n","        \"cd941e5bc659\",\n","        \"5b644a403e1f\",\n","        \"ddb222ff7c1d\",\n","        \"be197b663520\",\n","        \"88e5051f65bd\",\n","        \"75238d945315\",\n","        \"79d44db3da2d\",\n","        \"12e6e66c80a7\",\n","        \"086d41d17da8\",\n","        \"1db18bdd43aa\",\n","        \"2a8a9e957a6c\",\n","        \"aa8a1e814811\",\n","        \"3461dc601cc2\",\n","        \"384db24ebbd7\",\n","        \"8bf2d925dc0c\",\n","        \"93d6d20a5ee3\",\n","        \"d25b8a8ad3c4\",\n","        \"b310bd564329\",\n","        \"157d17349cc6\",\n","        \"a2d349f567a6\",\n","        \"0c7e82daf5a0\",\n","        \"ae57c8630249\",\n","        \"1d29cb2f4296\",\n","        \"92d8a7c8e718\",\n","        \"20404ec7b518\",\n","        \"49a4765f8822\",\n","        \"d5ad3362424c\",\n","        \"08c60c647673\",\n","        \"61f403fdb434\",\n","        \"d952dbfb0fe4\",\n","        \"ecb4500285ed\",\n","        \"15f8d769935c\",\n","        \"82e5bc01f8a4\",\n","        \"05339950962e\",\n","        \"a15590a7d774\",\n","        \"3b2b91590590\",\n","        \"d2ffe9287dc7\",\n","        \"260a455692b5\",\n","        \"18cde9649e90\",\n","        \"4c5ab774a381\",\n","        \"830e297965a1\",\n","        \"4b422b48d0d4\",\n","        \"51a1d162e223\",\n","        \"eeaea2c5ff34\",\n","        \"5b32ece9c627\",\n","        \"26453eb7e989\",\n","        \"052d9a3fe55a\",\n","        \"ca891d37a43c\",\n","        \"cfdbaef73a8b\",\n","        \"c1896142a20a\",\n","        \"ffc04fed30e6\",\n","        \"677f087cd697\",\n","        \"cd3fd04d72f5\",\n","        \"ed3ce1674761\",\n","        \"15cc2aef772a\",\n","        \"435414ccccf7\",\n","        \"441848e0f308\",\n","        \"2cacdb0dffae\",\n","        \"5e7630f8438e\",\n","        \"7a06ea127e02\",\n","        \"7a6e384a0846\",\n","        \"df8365d6ac33\",\n","        \"521b5377a727\",\n","        \"7131bf4c9e6f\",\n","        \"08bef347f40d\",\n","        \"a3475dc3ac80\",\n","        \"c21eb81de9fc\",\n","        \"215d2b7c3fde\",\n","        \"66bfec8d6bcd\",\n","        \"2700754f71e9\",\n","        \"00e4ddff966a\",\n","        \"242fc19be06f\",\n","        \"d51b3fe0fa1b\",\n","        \"b4b04d81acbb\",\n","        \"aeab0a63bcaf\",\n","        \"96c699221180\",\n","        \"cc9270f06b65\",\n","        \"61c2fbd16e38\",\n","        \"9ac41b9a809e\",\n","        \"8be6629a6039\",\n","        \"dc6fa1b38b83\",\n","        \"803120c5d287\",\n","        \"62b4be2799ca\",\n","        \"51d780864365\",\n","        \"2a47e5b21791\",\n","        \"9d74428188bb\",\n","        \"8dba09a4e5ed\",\n","        \"32d7d360d891\",\n","        \"4c3c1ed09771\",\n","        \"9785805af1b8\",\n","        \"8c4ceddeb1c6\",\n","        \"aeccef0bdc26\",\n","        \"89d9c071a56f\",\n","        \"7a238a1d3cf3\",\n","        \"3f0d3629d69e\",\n","        \"3796af4d987a\",\n","        \"1ec95179cdfe\",\n","        \"12ab2f6397f0\",\n","        \"e580676516b0\",\n","        \"6d259b5b4c76\",\n","        \"d271d3a2b552\",\n","        \"849a91e9ab28\",\n","        \"283c3aeba594\",\n","        \"25dc1b41ed9c\",\n","        \"6504b703c429\",\n","        \"e5f332efcbc7\",\n","        \"3a1ecf5e2839\",\n","        \"f68690db78d3\",\n","        \"57ce57a8cfb0\",\n","        \"3694e8c8e09a\",\n","        \"8201cab8322d\",\n","        \"d88c4843aec3\",\n","        \"155e2df6bfcf\",\n","        \"a0a0cd8af5a6\",\n","        \"c06024f05a16\",\n","        \"7b29e3783919\",\n","        \"7a77c3eb468c\",\n","        \"3abac0961bfd\",\n","        \"f0a2dc580009\",\n","        \"7269a1d84a57\",\n","        \"bda91b76095b\",\n","        \"6c6505a0c637\",\n","        \"873fe0404d6e\",\n","        \"2221cf5c7935\",\n","        \"f1a761c68559\",\n","        \"1e143fa3de57\",\n","        \"b1197f2cc9b3\",\n","        \"1ca35d483772\",\n","        \"2017cd92c63d\",\n","        \"6f0463c1ff18\",\n","        \"315c1a0d87fd\",\n","        \"0da09e3ce8f1\",\n","        \"35ac70c0d08f\",\n","        \"6a2c3f4ef329\",\n","        \"18b99159a14f\",\n","        \"907aaff827e5\",\n","        \"9a159d4674cd\",\n","        \"207a580de0ea\",\n","        \"26463a5fb949\",\n","        \"789434d095d1\",\n","        \"4c17e85686f0\",\n","        \"190a309f2cc5\",\n","        \"b085caa513a8\",\n","        \"e265c870f9b3\",\n","        \"388279491b5d\",\n","        \"c9e697117f3f\",\n","        \"b66f23ffa730\",\n","        \"576e189d23d4\",\n","        \"3f49f8d100e9\",\n","        \"0097f532ac9f\",\n","        \"4d1cf360b2d7\",\n","        \"e8ddfc9709ce\",\n","        \"e68746d426b2\",\n","        \"1c578b72d7b3\",\n","        \"e019b3e0f33d\",\n","        \"73ba798fee25\",\n","        \"0a85a1e8f9e9\",\n","        \"b0619ca93a5f\",\n","        \"d74ccc796517\",\n","        \"e1900014dabf\",\n","        \"bb9a3d835a94\",\n","        \"4aa07d720638\",\n","        \"9faad91b6578\",\n","        \"58184d6fd087\",\n","        \"76cab26493f1\",\n","        \"16060f05d047\",\n","        \"61bbe8db6f3a\",\n","        \"02cd34a85b24\",\n","        \"9858cc2ae073\",\n","        \"db4ed1e07aa3\",\n","        \"13d411c85ffd\",\n","        \"8d9516ea3587\",\n","        \"3f5b4c2948e8\",\n","        \"76be29bb30b2\",\n","        \"5077cdb88aed\",\n","        \"f61bf44c677c\",\n","        \"f64214bed40e\",\n","        \"23175b7ef453\",\n","        \"e9129ce55fd7\",\n","        \"966c07831334\",\n","        \"094858f005ab\",\n","        \"f5c953bee7cd\",\n","        \"3254e48c8aa0\",\n","        \"c1ebe785503a\",\n","        \"b351ae99413a\",\n","        \"501c319f7a9f\",\n","        \"98e8adcf085c\",\n","        \"c4a8f2fcf6e8\",\n","        \"789c60cba801\",\n","        \"80e6e425f966\",\n","        \"0ef4c61dc056\",\n","        \"f09cfc6a4dbd\",\n","        \"03c85870824c\",\n","        \"d29b37d110f3\",\n","        \"48c72dec46e5\",\n","        \"d81338217fc5\",\n","        \"66cd9c28e636\",\n","        \"3f73c91b7e32\",\n","        \"44e0d56e9d42\",\n","        \"ee6e39319b39\",\n","        \"5b068765e846\",\n","        \"1d37f1c8b6d8\",\n","        \"b87f9c59748b\",\n","        \"4ccfa0b4e96c\",\n","        \"d10d315f123f\",\n","        \"26999ebc21de\",\n","        \"e93394175a19\",\n","        \"f5a8c6426a71\",\n","        \"d968a983d4d2\",\n","        \"73d40ce06a67\",\n","        \"a8c9fcdbc0be\",\n","        \"fd62bd0db4f1\",\n","        \"e540d2e35d15\",\n","        \"aa31bc6b8f4d\",\n","        \"0b8bdec9d869\",\n","        \"848e66b9e199\",\n","        \"47b756014447\",\n","        \"8e3b79e1f1f7\",\n","        \"47d1603a555b\",\n","        \"188a9323be03\",\n","        \"276b14f72328\",\n","        \"27bab1432f61\",\n","        \"3aa2b1ce6700\",\n","        \"fa9f1bc03f21\",\n","        \"63a03880939c\",\n","        \"35df2bc6ae95\",\n","        \"1a19f2ef4472\",\n","        \"dd02d60bef14\",\n","        \"d5c63a8d9e94\",\n","        \"38487e1a5b1f\",\n","        \"be21d8b60e2a\",\n","        \"a688f20f8895\",\n","        \"51cfeccaf40d\",\n","        \"cc12453ea915\",\n","        \"09237bf783a4\",\n","        \"85fce24084da\",\n","        \"ce887b196c23\",\n","        \"d26bb2ed6e71\",\n","        \"e3a7671f787b\",\n","        \"d29096bd94aa\",\n","        \"7b211d8bd249\",\n","        \"6bcce181be65\",\n","        \"6cd606dc52e9\",\n","        \"1c4f3aa4df06\",\n","        \"0cb14014117d\",\n","        \"1f4fb37e0854\",\n","        \"9b57e43b44e7\",\n","        \"ed88faaa325a\",\n","        \"8cb6b5b2f19c\",\n","        \"8bf05909e1e1\",\n","        \"c52bb7343387\",\n","        \"dde43aa22ae6\",\n","        \"360832d84ce0\",\n","        \"d8da9de62743\",\n","        \"48a45619d1a3\",\n","        \"8a3eb86ae4bd\",\n","        \"75ed83dbccce\",\n","        \"80ed04a84a16\",\n","        \"b3a994760537\",\n","        \"0c2e2369dfff\",\n","        \"b99afe7137fb\",\n","        \"80feb1f7ca5e\",\n","        \"c1e6fa1ad314\",\n","        \"d0079cc188e9\",\n","        \"15f440753916\",\n","        \"d473f6fafba0\",\n","        \"034cb07a550f\",\n","        \"e322acd46152\",\n","        \"207dd0487264\",\n","        \"c24bcf7a1bc4\",\n","        \"b13d72ceea26\",\n","        \"5ac7a414560e\",\n","        \"9df31421cdd2\",\n","        \"e4e343eaae2a\",\n","        \"ac5b5dddf91b\",\n","        \"8958a4d17b7e\",\n","        \"735836b1ffa6\",\n","        \"a9e3d186cd1b\",\n","        \"2532613a584a\",\n","        \"cd66754e1b3b\",\n","        \"d26bc6e1230d\",\n","        \"73881f55a3ec\",\n","        \"61da799bf0aa\",\n","        \"af345c68e836\",\n","        \"12025b34deb8\",\n","        \"1844a039b4ea\",\n","        \"5905a9b06a73\",\n","        \"6e092b306fe1\",\n","        \"a06b353e7bed\",\n","        \"da0a83f074f3\",\n","        \"060e00d1e2ab\",\n","        \"8ed586c43023\",\n","        \"5a5d3798c357\",\n","        \"23d7ca170bdb\",\n","        \"3c78bfca247b\",\n","        \"6c30dd481717\",\n","        \"51af8c112682\",\n","        \"e2a47a74e6e1\",\n","        \"afc345cc9145\",\n","        \"7e9081e95bf6\",\n","        \"ec0c9f817b03\",\n","        \"4c60b10a3a6a\",\n","        \"1b862fb6f65d\",\n","        \"423abbaa5fad\",\n","        \"47536db39f00\",\n","        \"2408799a09b2\",\n","        \"573ea80a53be\",\n","        \"9232dc06cfdc\",\n","        \"9f285b3e57ed\",\n","        \"e06cccc08c59\",\n","        \"cf603a9ef2d5\",\n","        \"61e301bd3c25\",\n","        \"e9faf0296643\",\n","        \"6e92b1c5ac8e\",\n","        \"8a81f62320d6\",\n","        \"14515b8f19b6\",\n","        \"a76132e79688\",\n","        \"7877be80901c\",\n","        \"13ab8db8c700\",\n","        \"0a09aa7356c0\",\n","        \"ce6f33a81ad5\",\n","        \"12e3f5f2cb17\",\n","        \"5090917a2676\",\n","        \"21037f5c7790\",\n","        \"d774692d9919\",\n","        \"29f44aea93a4\",\n","        \"8f318a978844\",\n","        \"880edb2cdb69\",\n","        \"9eaf735cf01f\",\n","        \"7e77b61e1639\",\n","        \"7f2cce721e19\",\n","        \"2fdffb6160a6\",\n","        \"709784f7fcc2\",\n","        \"41960d5f58c2\",\n","        \"61ac9b0dc6b9\",\n","        \"d85d052900b4\",\n","        \"3206171db5be\",\n","        \"0ada12c0e78f\",\n","        \"9bd008aab548\",\n","        \"348598d01e18\",\n","        \"6c9c902a97de\",\n","        \"5188a8afa879\",\n","        \"07929d32b5b3\",\n","        \"f18abfa690ab\",\n","        \"2b4c7b5f1f1e\",\n","        \"c96f743915b5\",\n","        \"7d94a000c2d0\",\n","        \"682312e82ee3\",\n","        \"523ff163211b\",\n","        \"e135d7ba9a0e\",\n","        \"1d0b93317aa8\",\n","        \"7aabd768abff\",\n","        \"cc839823755b\",\n","        \"83fda7c0500b\",\n","        \"4036471a1bb7\",\n","        \"1b398c0494d1\",\n","        \"1623e8e3adc4\",\n","        \"821789e9053f\",\n","        \"757e39293591\",\n","        \"89d2a7403a06\",\n","        \"3732de8b416f\",\n","        \"00a8624548a9\",\n","        \"a9a28c37c8c4\",\n","        \"57a710de68a4\",\n","        \"54b322c66d01\",\n","        \"222d0ac042b4\",\n","        \"4b5ffea77373\",\n","        \"bab776139279\",\n","        \"992599744a23\",\n","        \"4fa26d065ad3\",\n","        \"454792eb6e05\",\n","        \"c0a117de7d0a\",\n","        \"fd079d2e93a2\",\n","        \"10f10fd30718\",\n","        \"b191ba0a2b12\",\n","        \"26cd40b57ad1\",\n","        \"ef26625121b3\",\n","        \"4ef7144e24ff\",\n","        \"2b07790a2422\",\n","        \"28503940d10b\",\n","        \"83038ca49b6d\",\n","        \"4246ed634f25\",\n","        \"3601dac9bed7\",\n","        \"27e2be850a99\",\n","        \"82088c6734e6\",\n","        \"1ee1eb7943db\",\n","        \"c67117c6ab3b\",\n","        \"4abca30b676b\",\n","        \"ac1667fac512\",\n","        \"7e9458de5707\",\n","        \"7af4d8704032\",\n","        \"3c1efa38d0da\",\n","        \"4bd5d0b30198\",\n","        \"084c02cf077f\",\n","        \"3b9817a39adf\",\n","        \"a5c9a8c726b2\",\n","        \"ab78a66dee6a\",\n","        \"200d947f75db\",\n","        \"d3de0d313d61\",\n","        \"099021fac3c9\",\n","        \"50d8a8fb7737\",\n","        \"cca626a0e19a\",\n","        \"2bd4d4fbed5c\",\n","        \"4ecd1fdd1435\",\n","        \"97d02a9b94f7\",\n","        \"495255c7492f\",\n","        \"541db13517e2\",\n","        \"b7a1bb106051\",\n","        \"61d9c88a3a4b\",\n","        \"4d7d6928534a\",\n","        \"467b7d9d811c\",\n","        \"4ad8d3ec8789\",\n","        \"a9e984b57556\",\n","        \"46d3316c4857\",\n","        \"16ce555748d8\",\n","        \"d9c9b9786da3\",\n","        \"a0cd7bffdaa0\",\n","        \"7adfb8fc0621\",\n","        \"5b3d41626ec5\",\n","        \"482088e6be44\",\n","        \"cd1c98ec48b1\",\n","        \"b92eacd1392a\",\n","        \"b86fb2d5be1a\",\n","        \"5bf3357a2823\",\n","        \"f5e9a307288c\",\n","        \"6531070bf03c\",\n","        \"2c2aa057afc5\",\n","        \"52ddde91a349\",\n","        \"ec01f0862669\",\n","        \"5e52c9fe676f\",\n","        \"103f97a2ab15\",\n","        \"8b568d47a1fd\",\n","        \"6f923b60934b\",\n","        \"2f143453bb71\",\n","        \"51e656e5a541\",\n","        \"0edadb2aa127\",\n","        \"8273fdb4405e\",\n","        \"7f2123bc89a3\",\n","        \"0af296d2f04a\",\n","        \"45693d027798\",\n","        \"a11c62cb3f86\",\n","        \"10eefba568dd\"\n","    ],\n","    \"timestamp\": \"2025-05-26 15:50:57\"\n","}\n","features_4d_path: /content/drive/MyDrive/working/efficientnetb1_features_4d.npy\n"]}],"source":["import json\n","import os\n","\n","metadata_path = \"/content/drive/MyDrive/working/efficientnetb1_features_metadata.json\"\n","if os.path.exists(metadata_path):\n","    with open(metadata_path, 'r') as f:\n","        metadata = json.load(f)\n","    print(\"Nội dung metadata:\")\n","    print(json.dumps(metadata, indent=4))\n","    print(f\"features_4d_path: {metadata.get('features_4d_path', 'Không tìm thấy')}\")\n","else:\n","    print(f\"Metadata không tồn tại tại: {metadata_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zNChub69POZo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749054793974,"user_tz":-420,"elapsed":132002,"user":{"displayName":"Resconnect","userId":"00882996269091038835"}},"outputId":"42595081-aeb8-4420-dd56-64016d5e85cb"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Đã kích hoạt tăng trưởng bộ nhớ GPU\n","Google Drive đã được mount.\n","Số mẫu lớp 0: 1534\n","Phân bố nhãn ban đầu: {0: np.int64(0), 1: np.int64(314), 2: np.int64(849), 3: np.int64(164), 4: np.int64(251)}\n","Số mẫu mục tiêu mỗi lớp: 1534\n","Lớp 1: 314 mẫu ban đầu\n","Tăng cường 1220 mẫu cho lớp 1\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-8-0b667d742405>:178: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n","  A.GaussNoise(var_limit=(10.0, 20.0), p=0.2),\n"]},{"output_type":"stream","name":"stdout","text":["Lớp 2: 849 mẫu ban đầu\n","Tăng cường 685 mẫu cho lớp 2\n","Lớp 3: 164 mẫu ban đầu\n","Tăng cường 1370 mẫu cho lớp 3\n","Lớp 4: 251 mẫu ban đầu\n","Tăng cường 1283 mẫu cho lớp 4\n","Phân bố nhãn sau cân bằng: {0: np.int64(0), 1: np.int64(1534), 2: np.int64(1534), 3: np.int64(1534), 4: np.int64(1534)}\n","Phân bố nhãn sau khi thêm lớp 0: {0: np.int64(1534), 1: np.int64(1534), 2: np.int64(1534), 3: np.int64(1534), 4: np.int64(1534)}\n","balanced_train_x shape: (7670, 244, 244, 3)\n","balanced_train_y_multi shape: (7670, 5)\n","Xử lý mô hình: efficientnetb1\n","Khởi tạo My_Generator: 7670 mẫu, target_size=(244, 244), is_train=True\n","Khởi tạo My_Generator: 550 mẫu, target_size=(244, 244), is_train=False\n","Khởi tạo My_Generator: 733 mẫu, target_size=(244, 244), is_train=False\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/efficientnetb1_features_2d.npy, shape=(7670, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/efficientnetb1_features_metadata.json\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/efficientnetb1_features_2d.npy, shape=(550, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/efficientnetb1_features_metadata.json\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/efficientnetb1_features_2d.npy, shape=(733, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/efficientnetb1_features_metadata.json\n","Xử lý mô hình: xception\n","Khởi tạo My_Generator: 7670 mẫu, target_size=(244, 244), is_train=True\n","Khởi tạo My_Generator: 550 mẫu, target_size=(244, 244), is_train=False\n","Khởi tạo My_Generator: 733 mẫu, target_size=(244, 244), is_train=False\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/xception_features_2d.npy, shape=(7670, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/xception_features_metadata.json\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/xception_features_2d.npy, shape=(550, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/xception_features_metadata.json\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/xception_features_2d.npy, shape=(733, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/xception_features_metadata.json\n","Xử lý mô hình: inceptionv3\n","Khởi tạo My_Generator: 7670 mẫu, target_size=(299, 299), is_train=True\n","Khởi tạo My_Generator: 550 mẫu, target_size=(299, 299), is_train=False\n","Khởi tạo My_Generator: 733 mẫu, target_size=(299, 299), is_train=False\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/inceptionv3_features_2d.npy, shape=(7670, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/inceptionv3_features_metadata.json\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/inceptionv3_features_2d.npy, shape=(550, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/inceptionv3_features_metadata.json\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/inceptionv3_features_2d.npy, shape=(733, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/inceptionv3_features_metadata.json\n","Xử lý mô hình: resnet50\n","Khởi tạo My_Generator: 7670 mẫu, target_size=(244, 244), is_train=True\n","Khởi tạo My_Generator: 550 mẫu, target_size=(244, 244), is_train=False\n","Khởi tạo My_Generator: 733 mẫu, target_size=(244, 244), is_train=False\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/resnet50_features_2d.npy, shape=(7670, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/resnet50_features_metadata.json\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/resnet50_features_2d.npy, shape=(550, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/resnet50_features_metadata.json\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/resnet50_features_2d.npy, shape=(733, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/resnet50_features_metadata.json\n","Xử lý mô hình: densenet121\n","Khởi tạo My_Generator: 7670 mẫu, target_size=(244, 244), is_train=True\n","Khởi tạo My_Generator: 550 mẫu, target_size=(244, 244), is_train=False\n","Khởi tạo My_Generator: 733 mẫu, target_size=(244, 244), is_train=False\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/densenet121_features_2d.npy, shape=(7670, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/densenet121_features_metadata.json\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/densenet121_features_2d.npy, shape=(550, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/densenet121_features_metadata.json\n","Đã lưu đặc trưng 2D tại: /content/drive/MyDrive/working/densenet121_features_2d.npy, shape=(733, 1024)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/densenet121_features_metadata.json\n","Đã lưu đặc trưng 2D chuẩn hóa cho efficientnetb1 tại: /content/drive/MyDrive/working/efficientnetb1_normalized_features_2d.npy, shape=(3112, 512)\n","Đã lưu đặc trưng 2D chuẩn hóa cho xception tại: /content/drive/MyDrive/working/xception_normalized_features_2d.npy, shape=(3112, 512)\n","Đã lưu đặc trưng 2D chuẩn hóa cho inceptionv3 tại: /content/drive/MyDrive/working/inceptionv3_normalized_features_2d.npy, shape=(3112, 512)\n","Đã lưu đặc trưng 2D chuẩn hóa cho resnet50 tại: /content/drive/MyDrive/working/resnet50_normalized_features_2d.npy, shape=(3112, 512)\n","Đã lưu đặc trưng 2D chuẩn hóa cho densenet121 tại: /content/drive/MyDrive/working/densenet121_normalized_features_2d.npy, shape=(3112, 512)\n","Đã lưu đặc trưng 2D kết hợp (trước PCA) tại: /content/drive/MyDrive/working/combined_features_2d_before_pca.npy, shape=(3112, 2560)\n","Đã lưu đặc trưng 2D kết hợp (sau PCA) tại: /content/drive/MyDrive/working/combined_features_2d_after_pca.npy, shape=(3112, 50)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/combined_features_metadata.json\n","Đã lưu đặc trưng 2D chuẩn hóa cho efficientnetb1 tại: /content/drive/MyDrive/working/efficientnetb1_normalized_features_2d.npy, shape=(550, 512)\n","Đã lưu đặc trưng 2D chuẩn hóa cho xception tại: /content/drive/MyDrive/working/xception_normalized_features_2d.npy, shape=(550, 512)\n","Đã lưu đặc trưng 2D chuẩn hóa cho inceptionv3 tại: /content/drive/MyDrive/working/inceptionv3_normalized_features_2d.npy, shape=(550, 512)\n","Đã lưu đặc trưng 2D chuẩn hóa cho resnet50 tại: /content/drive/MyDrive/working/resnet50_normalized_features_2d.npy, shape=(550, 512)\n","Đã lưu đặc trưng 2D chuẩn hóa cho densenet121 tại: /content/drive/MyDrive/working/densenet121_normalized_features_2d.npy, shape=(550, 512)\n","Đã lưu đặc trưng 2D kết hợp (trước PCA) tại: /content/drive/MyDrive/working/combined_features_2d_before_pca.npy, shape=(550, 2560)\n","Đã lưu đặc trưng 2D kết hợp (sau PCA) tại: /content/drive/MyDrive/working/combined_features_2d_after_pca.npy, shape=(550, 50)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/combined_features_metadata.json\n","Đã lưu đặc trưng 2D chuẩn hóa cho efficientnetb1 tại: /content/drive/MyDrive/working/efficientnetb1_normalized_features_2d.npy, shape=(733, 512)\n","Đã lưu đặc trưng 2D chuẩn hóa cho xception tại: /content/drive/MyDrive/working/xception_normalized_features_2d.npy, shape=(733, 512)\n","Đã lưu đặc trưng 2D chuẩn hóa cho inceptionv3 tại: /content/drive/MyDrive/working/inceptionv3_normalized_features_2d.npy, shape=(733, 512)\n","Đã lưu đặc trưng 2D chuẩn hóa cho resnet50 tại: /content/drive/MyDrive/working/resnet50_normalized_features_2d.npy, shape=(733, 512)\n","Đã lưu đặc trưng 2D chuẩn hóa cho densenet121 tại: /content/drive/MyDrive/working/densenet121_normalized_features_2d.npy, shape=(733, 512)\n","Đã lưu đặc trưng 2D kết hợp (trước PCA) tại: /content/drive/MyDrive/working/combined_features_2d_before_pca.npy, shape=(733, 2560)\n","Đã lưu đặc trưng 2D kết hợp (sau PCA) tại: /content/drive/MyDrive/working/combined_features_2d_after_pca.npy, shape=(733, 50)\n","Đã lưu metadata tại: /content/drive/MyDrive/working/combined_features_metadata.json\n","Huấn luyện meta-model với MAML/FO-MAML...\n","Lưu đặc trưng 2D của meta-learner...\n","Đã lưu đặc trưng 2D của meta-learner tại: /content/drive/MyDrive/working/meta_learner_features_2d.npy, shape=(550, 128)\n","Đã lưu metadata meta-learner tại: /content/drive/MyDrive/working/meta_learner_features_metadata.json\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 1 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_1.png\n","Episode 1/20:\n","  Support Loss: 1.1591, Accuracy: 0.5167\n","  Support QWK: 0.3498, F1: 0.5045, Precision: 0.5259, Recall: 0.5167\n","  Support Confusion Matrix:\n","[[5 0 1 3 1]\n"," [0 8 1 1 0]\n"," [0 1 7 2 0]\n"," [2 5 3 8 2]\n"," [0 2 2 3 3]]\n","  Query Loss: 1.5671, Accuracy: 0.2500\n","  Valid QWK (Ensemble): -0.0308, Precision: 0.3294, Recall: 0.1745\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Đã lưu trọng số tốt nhất tại episode 1 với QWK: -0.0308\n","Đã lưu ma trận nhầm lẫn best_ tại: /content/drive/MyDrive/working/confusion_matrix_best_episode_1.png\n","Ma trận nhầm lẫn cho QWK tốt nhất tại Episode 1:\n","[[ 74   1  31  69  96]\n"," [  3   0   1  46   6]\n"," [ 21   5   2 111  11]\n"," [  3   3   0  19   4]\n"," [ 17   1   0  25   1]]\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 2 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_2.png\n","Episode 2/20:\n","  Support Loss: 1.1488, Accuracy: 0.5500\n","  Support QWK: 0.4364, F1: 0.5483, Precision: 0.5702, Recall: 0.5500\n","  Support Confusion Matrix:\n","[[6 0 3 1 0]\n"," [0 6 1 2 1]\n"," [2 0 7 1 0]\n"," [5 3 3 8 1]\n"," [0 1 1 2 6]]\n","  Query Loss: 1.4751, Accuracy: 0.2667\n","  Valid QWK (Ensemble): 0.1283, Precision: 0.2232, Recall: 0.0927\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Đã lưu trọng số tốt nhất tại episode 2 với QWK: 0.1283\n","Đã lưu ma trận nhầm lẫn best_ tại: /content/drive/MyDrive/working/confusion_matrix_best_episode_2.png\n","Ma trận nhầm lẫn cho QWK tốt nhất tại Episode 2:\n","[[ 29  10 189  19  24]\n"," [  3   0   4  36  13]\n"," [ 10   0   3  55  82]\n"," [  5   1   0  11  12]\n"," [ 21   0   1  14   8]]\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 3 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_3.png\n","Episode 3/20:\n","  Support Loss: 1.2000, Accuracy: 0.6000\n","  Support QWK: 0.4819, F1: 0.5885, Precision: 0.6707, Recall: 0.6000\n","  Support Confusion Matrix:\n","[[ 4  0  4  0  2]\n"," [ 1  8  0  1  0]\n"," [ 3  0  7  0  0]\n"," [ 5  2  3  7  3]\n"," [ 0  0  0  0 10]]\n","  Query Loss: 1.4192, Accuracy: 0.2167\n","  Valid QWK (Ensemble): 0.2487, Precision: 0.4647, Recall: 0.2945\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Đã lưu trọng số tốt nhất tại episode 3 với QWK: 0.2487\n","Đã lưu ma trận nhầm lẫn best_ tại: /content/drive/MyDrive/working/confusion_matrix_best_episode_3.png\n","Ma trận nhầm lẫn cho QWK tốt nhất tại Episode 3:\n","[[113   1 133  11  13]\n"," [  1   1   3  49   2]\n"," [ 10   7  30  82  21]\n"," [  3   7   2  16   1]\n"," [ 11  12   0  19   2]]\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 4 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_4.png\n","Episode 4/20:\n","  Support Loss: 1.1440, Accuracy: 0.7833\n","  Support QWK: 0.5556, F1: 0.7758, Precision: 0.7928, Recall: 0.7833\n","  Support Confusion Matrix:\n","[[ 5  0  2  2  1]\n"," [ 0  9  0  1  0]\n"," [ 0  0 10  0  0]\n"," [ 1  1  1 16  1]\n"," [ 0  3  0  0  7]]\n","  Query Loss: 1.4091, Accuracy: 0.2500\n","  Valid QWK (Ensemble): 0.0494, Precision: 0.2211, Recall: 0.1400\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 5 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_5.png\n","Episode 5/20:\n","  Support Loss: 1.1260, Accuracy: 0.6500\n","  Support QWK: 0.4088, F1: 0.6158, Precision: 0.7179, Recall: 0.6500\n","  Support Confusion Matrix:\n","[[ 7  0  2  1  0]\n"," [ 1  8  0  1  0]\n"," [ 2  0  7  1  0]\n"," [ 1  2  1 16  0]\n"," [ 1  6  0  2  1]]\n","  Query Loss: 1.3782, Accuracy: 0.2333\n","  Valid QWK (Ensemble): 0.1297, Precision: 0.3925, Recall: 0.2364\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 6 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_6.png\n","Episode 6/20:\n","  Support Loss: 1.0181, Accuracy: 0.7000\n","  Support QWK: 0.6741, F1: 0.7077, Precision: 0.7870, Recall: 0.7000\n","  Support Confusion Matrix:\n","[[ 8  0  2  0  0]\n"," [ 1  7  2  0  0]\n"," [ 2  0  8  0  0]\n"," [ 6  0  3 10  1]\n"," [ 0  0  0  1  9]]\n","  Query Loss: 1.3696, Accuracy: 0.2167\n","  Valid QWK (Ensemble): 0.2832, Precision: 0.4893, Recall: 0.3491\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Đã lưu trọng số tốt nhất tại episode 6 với QWK: 0.2832\n","Đã lưu ma trận nhầm lẫn best_ tại: /content/drive/MyDrive/working/confusion_matrix_best_episode_6.png\n","Ma trận nhầm lẫn cho QWK tốt nhất tại Episode 6:\n","[[130   6 130   2   3]\n"," [  2   1  11  42   0]\n"," [ 10   6  50  63  21]\n"," [  4   6   9   8   2]\n"," [ 11  18   4   8   3]]\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 7 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_7.png\n","Episode 7/20:\n","  Support Loss: 1.0708, Accuracy: 0.5500\n","  Support QWK: 0.2410, F1: 0.5012, Precision: 0.5165, Recall: 0.5500\n","  Support Confusion Matrix:\n","[[ 8  0  1  1  0]\n"," [ 0  9  1  0  0]\n"," [ 3  0  6  1  0]\n"," [ 5  3  2 10  0]\n"," [ 1  6  3  0  0]]\n","  Query Loss: 1.4058, Accuracy: 0.2333\n","  Valid QWK (Ensemble): 0.2726, Precision: 0.4782, Recall: 0.2491\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 8 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_8.png\n","Episode 8/20:\n","  Support Loss: 1.0854, Accuracy: 0.5667\n","  Support QWK: 0.2840, F1: 0.5765, Precision: 0.7232, Recall: 0.5667\n","  Support Confusion Matrix:\n","[[10  0  0  0  0]\n"," [ 1  6  0  2  1]\n"," [ 5  0  5  0  0]\n"," [10  1  0  9  0]\n"," [ 2  4  0  0  4]]\n","  Query Loss: 1.3491, Accuracy: 0.3167\n","  Valid QWK (Ensemble): 0.1314, Precision: 0.3142, Recall: 0.1909\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 9 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_9.png\n","Episode 9/20:\n","  Support Loss: 1.2382, Accuracy: 0.4833\n","  Support QWK: 0.1581, F1: 0.4792, Precision: 0.6909, Recall: 0.4833\n","  Support Confusion Matrix:\n","[[ 8  1  0  0  1]\n"," [ 1  8  0  1  0]\n"," [ 5  1  4  0  0]\n"," [11  2  0  7  0]\n"," [ 1  7  0  0  2]]\n","  Query Loss: 1.4969, Accuracy: 0.2000\n","  Valid QWK (Ensemble): 0.0892, Precision: 0.4664, Recall: 0.3382\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 10 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_10.png\n","Episode 10/20:\n","  Support Loss: 1.1493, Accuracy: 0.5500\n","  Support QWK: 0.4052, F1: 0.5461, Precision: 0.5996, Recall: 0.5500\n","  Support Confusion Matrix:\n","[[7 1 1 1 0]\n"," [2 4 1 3 0]\n"," [1 0 9 0 0]\n"," [6 4 2 8 0]\n"," [1 1 1 2 5]]\n","  Query Loss: 1.5172, Accuracy: 0.1667\n","  Valid QWK (Ensemble): 0.3156, Precision: 0.5271, Recall: 0.4164\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Đã lưu trọng số tốt nhất tại episode 10 với QWK: 0.3156\n","Đã lưu ma trận nhầm lẫn best_ tại: /content/drive/MyDrive/working/confusion_matrix_best_episode_10.png\n","Ma trận nhầm lẫn cho QWK tốt nhất tại Episode 10:\n","[[140  30  74  14  13]\n"," [  2   0  32  20   2]\n"," [ 10   7  81  10  42]\n"," [  3   7  11   3   5]\n"," [ 12   7  12   8   5]]\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 11 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_11.png\n","Episode 11/20:\n","  Support Loss: 1.0822, Accuracy: 0.5167\n","  Support QWK: 0.2519, F1: 0.4761, Precision: 0.6749, Recall: 0.5167\n","  Support Confusion Matrix:\n","[[9 0 0 0 1]\n"," [1 9 0 0 0]\n"," [3 0 6 0 1]\n"," [8 4 3 4 1]\n"," [1 6 0 0 3]]\n","  Query Loss: 1.4840, Accuracy: 0.2167\n","  Valid QWK (Ensemble): 0.1758, Precision: 0.4997, Recall: 0.2436\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 12 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_12.png\n","Episode 12/20:\n","  Support Loss: 1.1152, Accuracy: 0.6000\n","  Support QWK: 0.4156, F1: 0.5860, Precision: 0.7767, Recall: 0.6000\n","  Support Confusion Matrix:\n","[[10  0  0  0  0]\n"," [ 0  9  1  0  0]\n"," [ 5  0  5  0  0]\n"," [ 8  5  1  6  0]\n"," [ 1  3  0  0  6]]\n","  Query Loss: 1.3773, Accuracy: 0.2667\n","  Valid QWK (Ensemble): 0.2886, Precision: 0.4738, Recall: 0.2927\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 13 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_13.png\n","Episode 13/20:\n","  Support Loss: 1.1347, Accuracy: 0.5833\n","  Support QWK: 0.4480, F1: 0.5550, Precision: 0.6640, Recall: 0.5833\n","  Support Confusion Matrix:\n","[[10  0  0  0  0]\n"," [ 0  9  0  0  1]\n"," [ 3  0  6  1  0]\n"," [ 5  8  1  5  1]\n"," [ 0  4  0  1  5]]\n","  Query Loss: 1.3359, Accuracy: 0.3667\n","  Valid QWK (Ensemble): 0.3764, Precision: 0.5526, Recall: 0.3618\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Đã lưu trọng số tốt nhất tại episode 13 với QWK: 0.3764\n","Đã lưu ma trận nhầm lẫn best_ tại: /content/drive/MyDrive/working/confusion_matrix_best_episode_13.png\n","Ma trận nhầm lẫn cho QWK tốt nhất tại Episode 13:\n","[[135  38  82   2  14]\n"," [  1  10  21  18   6]\n"," [  3  15  45   9  78]\n"," [  0   9   4   1  15]\n"," [  7  20   3   6   8]]\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 14 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_14.png\n","Episode 14/20:\n","  Support Loss: 1.0907, Accuracy: 0.7833\n","  Support QWK: 0.5721, F1: 0.7730, Precision: 0.8329, Recall: 0.7833\n","  Support Confusion Matrix:\n","[[ 9  0  0  1  0]\n"," [ 0 10  0  0  0]\n"," [ 0  0 10  0  0]\n"," [ 3  2  1 14  0]\n"," [ 0  5  0  1  4]]\n","  Query Loss: 1.5028, Accuracy: 0.1667\n","  Valid QWK (Ensemble): 0.2097, Precision: 0.4771, Recall: 0.2473\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 15 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_15.png\n","Episode 15/20:\n","  Support Loss: 1.1721, Accuracy: 0.6000\n","  Support QWK: 0.2622, F1: 0.5973, Precision: 0.7216, Recall: 0.6000\n","  Support Confusion Matrix:\n","[[ 6  2  1  0  1]\n"," [ 0  9  0  0  1]\n"," [ 0  0 10  0  0]\n"," [ 2  7  1  9  1]\n"," [ 0  8  0  0  2]]\n","  Query Loss: 1.4403, Accuracy: 0.2000\n","  Valid QWK (Ensemble): 0.2821, Precision: 0.4600, Recall: 0.2236\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 16 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_16.png\n","Episode 16/20:\n","  Support Loss: 1.1821, Accuracy: 0.6667\n","  Support QWK: 0.4072, F1: 0.6700, Precision: 0.7778, Recall: 0.6667\n","  Support Confusion Matrix:\n","[[9 0 0 0 1]\n"," [1 8 0 0 1]\n"," [1 0 8 0 1]\n"," [7 4 0 9 0]\n"," [0 4 0 0 6]]\n","  Query Loss: 1.4174, Accuracy: 0.2000\n","  Valid QWK (Ensemble): 0.4237, Precision: 0.5729, Recall: 0.3000\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Đã lưu trọng số tốt nhất tại episode 16 với QWK: 0.4237\n","Đã lưu ma trận nhầm lẫn best_ tại: /content/drive/MyDrive/working/confusion_matrix_best_episode_16.png\n","Ma trận nhầm lẫn cho QWK tốt nhất tại Episode 16:\n","[[103 105  28   3  32]\n"," [  1   9  20  19   7]\n"," [  5  15  34   6  90]\n"," [  1   3   2   6  17]\n"," [  3   8   5  15  13]]\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 17 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_17.png\n","Episode 17/20:\n","  Support Loss: 1.1603, Accuracy: 0.6500\n","  Support QWK: 0.4273, F1: 0.6564, Precision: 0.7933, Recall: 0.6500\n","  Support Confusion Matrix:\n","[[ 8  0  1  1  0]\n"," [ 0 10  0  0  0]\n"," [ 2  1  7  0  0]\n"," [ 2  8  0 10  0]\n"," [ 0  6  0  0  4]]\n","  Query Loss: 1.4453, Accuracy: 0.2000\n","  Valid QWK (Ensemble): 0.3002, Precision: 0.3685, Recall: 0.1545\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 18 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_18.png\n","Episode 18/20:\n","  Support Loss: 1.1229, Accuracy: 0.5167\n","  Support QWK: 0.3727, F1: 0.4913, Precision: 0.7130, Recall: 0.5167\n","  Support Confusion Matrix:\n","[[8 2 0 0 0]\n"," [0 9 0 0 1]\n"," [5 0 5 0 0]\n"," [5 8 3 4 0]\n"," [0 5 0 0 5]]\n","  Query Loss: 1.4878, Accuracy: 0.1833\n","  Valid QWK (Ensemble): 0.3183, Precision: 0.4531, Recall: 0.1891\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 19 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_19.png\n","Episode 19/20:\n","  Support Loss: 1.0847, Accuracy: 0.6500\n","  Support QWK: 0.4248, F1: 0.6349, Precision: 0.7849, Recall: 0.6500\n","  Support Confusion Matrix:\n","[[ 9  1  0  0  0]\n"," [ 0 10  0  0  0]\n"," [ 1  0  9  0  0]\n"," [ 4  6  1  8  1]\n"," [ 0  7  0  0  3]]\n","  Query Loss: 1.3603, Accuracy: 0.2500\n","  Valid QWK (Ensemble): 0.2655, Precision: 0.5066, Recall: 0.2182\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Episode distribution - Support: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode distribution - Query: {0: np.int64(10), 1: np.int64(10), 2: np.int64(10), 3: np.int64(20), 4: np.int64(10)}\n","Episode 20 - Trọng số lớp: {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.5, 4: 1.0}\n","Đã lưu ma trận nhầm lẫn support_ tại: /content/drive/MyDrive/working/confusion_matrix_support_episode_20.png\n","Episode 20/20:\n","  Support Loss: 1.1570, Accuracy: 0.5500\n","  Support QWK: 0.4266, F1: 0.5281, Precision: 0.6682, Recall: 0.5500\n","  Support Confusion Matrix:\n","[[8 2 0 0 0]\n"," [0 8 1 1 0]\n"," [2 0 7 0 1]\n"," [5 9 1 4 1]\n"," [0 4 0 0 6]]\n","  Query Loss: 1.4693, Accuracy: 0.2000\n","  Valid QWK (Ensemble): 0.2651, Precision: 0.4061, Recall: 0.1927\n","  Inner LR: 0.001000, Outer LR: 0.001000, Fine-tune LR: 0.000100\n","Fine-tuning trên tập valid...\n","Epoch 1/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 261ms/step - accuracy: 0.2059 - loss: 61.6283 - precision: 0.1651 - recall: 0.0148 - val_accuracy: 0.2309 - val_loss: 59.5195 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-04\n","Epoch 2/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3222 - loss: 58.9407 - precision: 0.5042 - recall: 0.0497 - val_accuracy: 0.3855 - val_loss: 57.0166 - val_precision: 1.0000 - val_recall: 0.0018 - learning_rate: 1.0000e-04\n","Epoch 3/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4058 - loss: 56.4690 - precision: 0.5170 - recall: 0.0699 - val_accuracy: 0.6473 - val_loss: 54.6249 - val_precision: 1.0000 - val_recall: 0.0036 - learning_rate: 1.0000e-04\n","Epoch 4/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4650 - loss: 54.2175 - precision: 0.6384 - recall: 0.0970 - val_accuracy: 0.7564 - val_loss: 52.3275 - val_precision: 1.0000 - val_recall: 0.0491 - learning_rate: 1.0000e-04\n","Epoch 5/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5936 - loss: 51.9122 - precision: 0.7379 - recall: 0.1639 - val_accuracy: 0.7800 - val_loss: 50.1516 - val_precision: 0.9903 - val_recall: 0.1855 - learning_rate: 1.0000e-04\n","Epoch 6/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6216 - loss: 49.7980 - precision: 0.8782 - recall: 0.2412 - val_accuracy: 0.8000 - val_loss: 48.0833 - val_precision: 0.9842 - val_recall: 0.3400 - learning_rate: 1.0000e-04\n","Epoch 7/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6455 - loss: 47.7337 - precision: 0.8997 - recall: 0.3115 - val_accuracy: 0.8091 - val_loss: 46.0973 - val_precision: 0.9670 - val_recall: 0.4800 - learning_rate: 1.0000e-04\n","Epoch 8/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6820 - loss: 45.7820 - precision: 0.8917 - recall: 0.3620 - val_accuracy: 0.8127 - val_loss: 44.1917 - val_precision: 0.9605 - val_recall: 0.5745 - learning_rate: 1.0000e-04\n","Epoch 9/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6746 - loss: 43.9207 - precision: 0.8828 - recall: 0.3985 - val_accuracy: 0.8145 - val_loss: 42.3576 - val_precision: 0.9423 - val_recall: 0.6236 - learning_rate: 1.0000e-04\n","Epoch 10/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7217 - loss: 42.0953 - precision: 0.8917 - recall: 0.4385 - val_accuracy: 0.8236 - val_loss: 40.6064 - val_precision: 0.9278 - val_recall: 0.6545 - learning_rate: 1.0000e-04\n","Epoch 11/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7476 - loss: 40.3737 - precision: 0.8772 - recall: 0.5117 - val_accuracy: 0.8273 - val_loss: 38.9188 - val_precision: 0.9225 - val_recall: 0.6709 - learning_rate: 1.0000e-04\n","Epoch 12/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7605 - loss: 38.6506 - precision: 0.8932 - recall: 0.5685 - val_accuracy: 0.8327 - val_loss: 37.3012 - val_precision: 0.9207 - val_recall: 0.6964 - learning_rate: 1.0000e-04\n","Epoch 13/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7731 - loss: 37.0557 - precision: 0.8949 - recall: 0.5524 - val_accuracy: 0.8345 - val_loss: 35.7531 - val_precision: 0.9204 - val_recall: 0.7145 - learning_rate: 1.0000e-04\n","Epoch 14/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8077 - loss: 35.4904 - precision: 0.9014 - recall: 0.6056 - val_accuracy: 0.8364 - val_loss: 34.2729 - val_precision: 0.9171 - val_recall: 0.7236 - learning_rate: 1.0000e-04\n","Epoch 15/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7813 - loss: 34.0534 - precision: 0.9007 - recall: 0.6196 - val_accuracy: 0.8418 - val_loss: 32.8533 - val_precision: 0.9159 - val_recall: 0.7327 - learning_rate: 1.0000e-04\n","Epoch 16/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7990 - loss: 32.6147 - precision: 0.8886 - recall: 0.6544 - val_accuracy: 0.8455 - val_loss: 31.4852 - val_precision: 0.9148 - val_recall: 0.7418 - learning_rate: 1.0000e-04\n","Epoch 17/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8066 - loss: 31.2332 - precision: 0.9211 - recall: 0.6982 - val_accuracy: 0.8455 - val_loss: 30.1703 - val_precision: 0.9081 - val_recall: 0.7545 - learning_rate: 1.0000e-04\n","Epoch 18/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7958 - loss: 29.9735 - precision: 0.9222 - recall: 0.6803 - val_accuracy: 0.8455 - val_loss: 28.9048 - val_precision: 0.9048 - val_recall: 0.7600 - learning_rate: 1.0000e-04\n","Epoch 19/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8129 - loss: 28.7047 - precision: 0.8954 - recall: 0.7032 - val_accuracy: 0.8455 - val_loss: 27.6850 - val_precision: 0.9017 - val_recall: 0.7673 - learning_rate: 1.0000e-04\n","Epoch 20/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8182 - loss: 27.5072 - precision: 0.9011 - recall: 0.7162 - val_accuracy: 0.8509 - val_loss: 26.5212 - val_precision: 0.9002 - val_recall: 0.7709 - learning_rate: 1.0000e-04\n","Epoch 21/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8393 - loss: 26.3208 - precision: 0.8951 - recall: 0.7213 - val_accuracy: 0.8491 - val_loss: 25.4061 - val_precision: 0.8987 - val_recall: 0.7745 - learning_rate: 1.0000e-04\n","Epoch 22/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8334 - loss: 25.2087 - precision: 0.8965 - recall: 0.7343 - val_accuracy: 0.8491 - val_loss: 24.3345 - val_precision: 0.8971 - val_recall: 0.7764 - learning_rate: 1.0000e-04\n","Epoch 23/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8068 - loss: 24.1696 - precision: 0.8793 - recall: 0.7003 - val_accuracy: 0.8545 - val_loss: 23.3073 - val_precision: 0.8975 - val_recall: 0.7800 - learning_rate: 1.0000e-04\n","Epoch 24/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8048 - loss: 23.1908 - precision: 0.8892 - recall: 0.7275 - val_accuracy: 0.8545 - val_loss: 22.3193 - val_precision: 0.8926 - val_recall: 0.7855 - learning_rate: 1.0000e-04\n","Epoch 25/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8517 - loss: 22.1286 - precision: 0.9316 - recall: 0.7669 - val_accuracy: 0.8564 - val_loss: 21.3726 - val_precision: 0.8914 - val_recall: 0.7909 - learning_rate: 1.0000e-04\n","Epoch 26/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8485 - loss: 21.1795 - precision: 0.9241 - recall: 0.7807 - val_accuracy: 0.8564 - val_loss: 20.4616 - val_precision: 0.8921 - val_recall: 0.7964 - learning_rate: 1.0000e-04\n","Epoch 27/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8553 - loss: 20.2961 - precision: 0.8961 - recall: 0.7646 - val_accuracy: 0.8564 - val_loss: 19.5872 - val_precision: 0.8855 - val_recall: 0.8018 - learning_rate: 1.0000e-04\n","Epoch 28/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8280 - loss: 19.4756 - precision: 0.8815 - recall: 0.7450 - val_accuracy: 0.8582 - val_loss: 18.7498 - val_precision: 0.8855 - val_recall: 0.8018 - learning_rate: 1.0000e-04\n","Epoch 29/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8251 - loss: 18.6379 - precision: 0.8770 - recall: 0.7387 - val_accuracy: 0.8564 - val_loss: 17.9467 - val_precision: 0.8865 - val_recall: 0.8091 - learning_rate: 1.0000e-04\n","Epoch 30/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8344 - loss: 17.8205 - precision: 0.8848 - recall: 0.7795 - val_accuracy: 0.8545 - val_loss: 17.1800 - val_precision: 0.8891 - val_recall: 0.8164 - learning_rate: 1.0000e-04\n","Epoch 31/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8401 - loss: 17.0727 - precision: 0.8782 - recall: 0.7703 - val_accuracy: 0.8564 - val_loss: 16.4490 - val_precision: 0.8856 - val_recall: 0.8164 - learning_rate: 1.0000e-04\n","Epoch 32/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8179 - loss: 16.3615 - precision: 0.8710 - recall: 0.7717 - val_accuracy: 0.8545 - val_loss: 15.7471 - val_precision: 0.8909 - val_recall: 0.8164 - learning_rate: 1.0000e-04\n","Epoch 33/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8353 - loss: 15.6174 - precision: 0.8716 - recall: 0.7872 - val_accuracy: 0.8545 - val_loss: 15.0791 - val_precision: 0.8926 - val_recall: 0.8164 - learning_rate: 1.0000e-04\n","Epoch 34/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8325 - loss: 14.9888 - precision: 0.8958 - recall: 0.7815 - val_accuracy: 0.8564 - val_loss: 14.4373 - val_precision: 0.8926 - val_recall: 0.8164 - learning_rate: 1.0000e-04\n","Epoch 35/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8627 - loss: 14.3082 - precision: 0.8946 - recall: 0.8101 - val_accuracy: 0.8600 - val_loss: 13.8242 - val_precision: 0.8880 - val_recall: 0.8218 - learning_rate: 1.0000e-04\n","Epoch 36/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8449 - loss: 13.7590 - precision: 0.8873 - recall: 0.7980 - val_accuracy: 0.8582 - val_loss: 13.2421 - val_precision: 0.8880 - val_recall: 0.8218 - learning_rate: 1.0000e-04\n","Epoch 37/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8566 - loss: 13.0980 - precision: 0.9089 - recall: 0.8160 - val_accuracy: 0.8582 - val_loss: 12.6818 - val_precision: 0.8915 - val_recall: 0.8218 - learning_rate: 1.0000e-04\n","Epoch 38/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8343 - loss: 12.6087 - precision: 0.8795 - recall: 0.7872 - val_accuracy: 0.8600 - val_loss: 12.1486 - val_precision: 0.8933 - val_recall: 0.8218 - learning_rate: 1.0000e-04\n","Epoch 39/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8421 - loss: 12.0534 - precision: 0.8816 - recall: 0.7798 - val_accuracy: 0.8582 - val_loss: 11.6361 - val_precision: 0.8935 - val_recall: 0.8236 - learning_rate: 1.0000e-04\n","Epoch 40/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8608 - loss: 11.5286 - precision: 0.8939 - recall: 0.8281 - val_accuracy: 0.8600 - val_loss: 11.1538 - val_precision: 0.8939 - val_recall: 0.8273 - learning_rate: 1.0000e-04\n","Epoch 41/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8560 - loss: 11.0729 - precision: 0.8887 - recall: 0.8078 - val_accuracy: 0.8600 - val_loss: 10.6905 - val_precision: 0.8945 - val_recall: 0.8327 - learning_rate: 1.0000e-04\n","Epoch 42/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8609 - loss: 10.6300 - precision: 0.8940 - recall: 0.8150 - val_accuracy: 0.8600 - val_loss: 10.2476 - val_precision: 0.8949 - val_recall: 0.8364 - learning_rate: 1.0000e-04\n","Epoch 43/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8398 - loss: 10.1999 - precision: 0.8748 - recall: 0.8014 - val_accuracy: 0.8600 - val_loss: 9.8236 - val_precision: 0.8930 - val_recall: 0.8345 - learning_rate: 1.0000e-04\n","Epoch 44/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8555 - loss: 9.7739 - precision: 0.8931 - recall: 0.8154 - val_accuracy: 0.8655 - val_loss: 9.4218 - val_precision: 0.8969 - val_recall: 0.8382 - learning_rate: 1.0000e-04\n","Epoch 45/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8411 - loss: 9.3955 - precision: 0.8941 - recall: 0.7993 - val_accuracy: 0.8655 - val_loss: 9.0385 - val_precision: 0.9018 - val_recall: 0.8345 - learning_rate: 1.0000e-04\n","Epoch 46/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8295 - loss: 9.0086 - precision: 0.8842 - recall: 0.7947 - val_accuracy: 0.8655 - val_loss: 8.6704 - val_precision: 0.9018 - val_recall: 0.8345 - learning_rate: 1.0000e-04\n","Epoch 47/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8347 - loss: 8.6685 - precision: 0.8669 - recall: 0.8007 - val_accuracy: 0.8673 - val_loss: 8.3220 - val_precision: 0.9002 - val_recall: 0.8364 - learning_rate: 1.0000e-04\n","Epoch 48/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8761 - loss: 8.2672 - precision: 0.8882 - recall: 0.8260 - val_accuracy: 0.8691 - val_loss: 7.9879 - val_precision: 0.8967 - val_recall: 0.8364 - learning_rate: 1.0000e-04\n","Epoch 49/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8391 - loss: 7.9640 - precision: 0.8796 - recall: 0.8109 - val_accuracy: 0.8673 - val_loss: 7.6679 - val_precision: 0.8919 - val_recall: 0.8400 - learning_rate: 1.0000e-04\n","Epoch 50/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8586 - loss: 7.6160 - precision: 0.8949 - recall: 0.8180 - val_accuracy: 0.8636 - val_loss: 7.3593 - val_precision: 0.8934 - val_recall: 0.8382 - learning_rate: 1.0000e-04\n","Epoch 51/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8614 - loss: 7.3048 - precision: 0.9008 - recall: 0.8353 - val_accuracy: 0.8691 - val_loss: 7.0626 - val_precision: 0.9006 - val_recall: 0.8400 - learning_rate: 1.0000e-04\n","Epoch 52/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8352 - loss: 7.0471 - precision: 0.8814 - recall: 0.8091 - val_accuracy: 0.8709 - val_loss: 6.7793 - val_precision: 0.9023 - val_recall: 0.8400 - learning_rate: 1.0000e-04\n","Epoch 53/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8647 - loss: 6.7427 - precision: 0.9058 - recall: 0.8384 - val_accuracy: 0.8727 - val_loss: 6.5117 - val_precision: 0.9077 - val_recall: 0.8400 - learning_rate: 1.0000e-04\n","Epoch 54/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8606 - loss: 6.4981 - precision: 0.8936 - recall: 0.8156 - val_accuracy: 0.8709 - val_loss: 6.2592 - val_precision: 0.9043 - val_recall: 0.8418 - learning_rate: 1.0000e-04\n","Epoch 55/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8766 - loss: 6.2092 - precision: 0.9056 - recall: 0.8407 - val_accuracy: 0.8745 - val_loss: 6.0170 - val_precision: 0.8990 - val_recall: 0.8418 - learning_rate: 1.0000e-04\n","Epoch 56/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8397 - loss: 6.0162 - precision: 0.8702 - recall: 0.8105 - val_accuracy: 0.8764 - val_loss: 5.7855 - val_precision: 0.9014 - val_recall: 0.8473 - learning_rate: 1.0000e-04\n","Epoch 57/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8791 - loss: 5.7464 - precision: 0.9052 - recall: 0.8499 - val_accuracy: 0.8800 - val_loss: 5.5637 - val_precision: 0.8998 - val_recall: 0.8491 - learning_rate: 1.0000e-04\n","Epoch 58/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8723 - loss: 5.5586 - precision: 0.9034 - recall: 0.8288 - val_accuracy: 0.8745 - val_loss: 5.3503 - val_precision: 0.9050 - val_recall: 0.8491 - learning_rate: 1.0000e-04\n","Epoch 59/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8480 - loss: 5.3765 - precision: 0.8694 - recall: 0.8080 - val_accuracy: 0.8818 - val_loss: 5.1520 - val_precision: 0.9086 - val_recall: 0.8491 - learning_rate: 1.0000e-04\n","Epoch 60/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8681 - loss: 5.1489 - precision: 0.8940 - recall: 0.8463 - val_accuracy: 0.8836 - val_loss: 4.9572 - val_precision: 0.9089 - val_recall: 0.8527 - learning_rate: 1.0000e-04\n","Epoch 61/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8657 - loss: 4.9549 - precision: 0.9067 - recall: 0.8253 - val_accuracy: 0.8745 - val_loss: 4.7733 - val_precision: 0.9075 - val_recall: 0.8564 - learning_rate: 1.0000e-04\n","Epoch 62/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8763 - loss: 4.7709 - precision: 0.8987 - recall: 0.8480 - val_accuracy: 0.8745 - val_loss: 4.5952 - val_precision: 0.9072 - val_recall: 0.8527 - learning_rate: 1.0000e-04\n","Epoch 63/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8507 - loss: 4.6361 - precision: 0.8933 - recall: 0.8208 - val_accuracy: 0.8782 - val_loss: 4.4258 - val_precision: 0.9054 - val_recall: 0.8527 - learning_rate: 1.0000e-04\n","Epoch 64/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8605 - loss: 4.4340 - precision: 0.8721 - recall: 0.8226 - val_accuracy: 0.8782 - val_loss: 4.2662 - val_precision: 0.9004 - val_recall: 0.8545 - learning_rate: 1.0000e-04\n","Epoch 65/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8639 - loss: 4.2590 - precision: 0.8982 - recall: 0.8389 - val_accuracy: 0.8800 - val_loss: 4.1102 - val_precision: 0.9040 - val_recall: 0.8564 - learning_rate: 1.0000e-04\n","Epoch 66/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8564 - loss: 4.1275 - precision: 0.8955 - recall: 0.8338 - val_accuracy: 0.8764 - val_loss: 3.9661 - val_precision: 0.9027 - val_recall: 0.8600 - learning_rate: 1.0000e-04\n","Epoch 67/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8496 - loss: 3.9904 - precision: 0.8838 - recall: 0.8327 - val_accuracy: 0.8836 - val_loss: 3.8232 - val_precision: 0.9114 - val_recall: 0.8600 - learning_rate: 1.0000e-04\n","Epoch 68/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8720 - loss: 3.8370 - precision: 0.8933 - recall: 0.8511 - val_accuracy: 0.8891 - val_loss: 3.6864 - val_precision: 0.9149 - val_recall: 0.8600 - learning_rate: 1.0000e-04\n","Epoch 69/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8595 - loss: 3.7254 - precision: 0.8861 - recall: 0.8165 - val_accuracy: 0.8836 - val_loss: 3.5557 - val_precision: 0.9065 - val_recall: 0.8636 - learning_rate: 1.0000e-04\n","Epoch 70/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8878 - loss: 3.5321 - precision: 0.9140 - recall: 0.8687 - val_accuracy: 0.8836 - val_loss: 3.4355 - val_precision: 0.8962 - val_recall: 0.8636 - learning_rate: 1.0000e-04\n","Epoch 71/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9060 - loss: 3.3852 - precision: 0.9275 - recall: 0.8797 - val_accuracy: 0.8836 - val_loss: 3.3137 - val_precision: 0.9101 - val_recall: 0.8655 - learning_rate: 1.0000e-04\n","Epoch 72/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8322 - loss: 3.4508 - precision: 0.8623 - recall: 0.8103 - val_accuracy: 0.8891 - val_loss: 3.1990 - val_precision: 0.9138 - val_recall: 0.8673 - learning_rate: 1.0000e-04\n","Epoch 73/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8562 - loss: 3.2547 - precision: 0.8756 - recall: 0.8211 - val_accuracy: 0.8891 - val_loss: 3.0929 - val_precision: 0.9100 - val_recall: 0.8636 - learning_rate: 1.0000e-04\n","Epoch 74/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8549 - loss: 3.1288 - precision: 0.8728 - recall: 0.8311 - val_accuracy: 0.8873 - val_loss: 2.9848 - val_precision: 0.9087 - val_recall: 0.8691 - learning_rate: 1.0000e-04\n","Epoch 75/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8593 - loss: 3.0306 - precision: 0.8777 - recall: 0.8349 - val_accuracy: 0.8873 - val_loss: 2.8886 - val_precision: 0.9140 - val_recall: 0.8691 - learning_rate: 1.0000e-04\n","Epoch 76/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8379 - loss: 3.0048 - precision: 0.8606 - recall: 0.7969 - val_accuracy: 0.8891 - val_loss: 2.7960 - val_precision: 0.9087 - val_recall: 0.8691 - learning_rate: 1.0000e-04\n","Epoch 77/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8711 - loss: 2.8355 - precision: 0.8997 - recall: 0.8499 - val_accuracy: 0.8855 - val_loss: 2.7066 - val_precision: 0.9101 - val_recall: 0.8655 - learning_rate: 1.0000e-04\n","Epoch 78/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8799 - loss: 2.6972 - precision: 0.9021 - recall: 0.8682 - val_accuracy: 0.8891 - val_loss: 2.6161 - val_precision: 0.9212 - val_recall: 0.8709 - learning_rate: 1.0000e-04\n","Epoch 79/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8916 - loss: 2.6227 - precision: 0.9146 - recall: 0.8696 - val_accuracy: 0.8909 - val_loss: 2.5368 - val_precision: 0.9159 - val_recall: 0.8709 - learning_rate: 1.0000e-04\n","Epoch 80/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8989 - loss: 2.5074 - precision: 0.9205 - recall: 0.8790 - val_accuracy: 0.8945 - val_loss: 2.4566 - val_precision: 0.9110 - val_recall: 0.8745 - learning_rate: 1.0000e-04\n","Epoch 81/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8736 - loss: 2.4854 - precision: 0.9093 - recall: 0.8505 - val_accuracy: 0.8982 - val_loss: 2.3804 - val_precision: 0.9229 - val_recall: 0.8709 - learning_rate: 1.0000e-04\n","Epoch 82/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8685 - loss: 2.4234 - precision: 0.8848 - recall: 0.8387 - val_accuracy: 0.9073 - val_loss: 2.3069 - val_precision: 0.9249 - val_recall: 0.8727 - learning_rate: 1.0000e-04\n","Epoch 83/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8560 - loss: 2.3682 - precision: 0.8954 - recall: 0.8282 - val_accuracy: 0.8909 - val_loss: 2.2420 - val_precision: 0.9160 - val_recall: 0.8727 - learning_rate: 1.0000e-04\n","Epoch 84/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8813 - loss: 2.2557 - precision: 0.8954 - recall: 0.8706 - val_accuracy: 0.8982 - val_loss: 2.1717 - val_precision: 0.9250 - val_recall: 0.8745 - learning_rate: 1.0000e-04\n","Epoch 85/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8860 - loss: 2.2081 - precision: 0.9006 - recall: 0.8654 - val_accuracy: 0.9018 - val_loss: 2.1105 - val_precision: 0.9216 - val_recall: 0.8764 - learning_rate: 1.0000e-04\n","Epoch 86/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8771 - loss: 2.1608 - precision: 0.9021 - recall: 0.8350 - val_accuracy: 0.8909 - val_loss: 2.0545 - val_precision: 0.9146 - val_recall: 0.8764 - learning_rate: 1.0000e-04\n","Epoch 87/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8754 - loss: 2.1021 - precision: 0.8976 - recall: 0.8378 - val_accuracy: 0.8945 - val_loss: 1.9923 - val_precision: 0.9205 - val_recall: 0.8836 - learning_rate: 1.0000e-04\n","Epoch 88/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8696 - loss: 2.0573 - precision: 0.8918 - recall: 0.8488 - val_accuracy: 0.9036 - val_loss: 1.9370 - val_precision: 0.9244 - val_recall: 0.8891 - learning_rate: 1.0000e-04\n","Epoch 89/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8908 - loss: 1.9876 - precision: 0.9020 - recall: 0.8575 - val_accuracy: 0.9018 - val_loss: 1.8859 - val_precision: 0.9229 - val_recall: 0.8927 - learning_rate: 1.0000e-04\n","Epoch 90/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8759 - loss: 1.9329 - precision: 0.9004 - recall: 0.8432 - val_accuracy: 0.9055 - val_loss: 1.8364 - val_precision: 0.9242 - val_recall: 0.8873 - learning_rate: 1.0000e-04\n","Epoch 91/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8873 - loss: 1.8553 - precision: 0.9074 - recall: 0.8601 - val_accuracy: 0.9018 - val_loss: 1.7880 - val_precision: 0.9192 - val_recall: 0.8891 - learning_rate: 1.0000e-04\n","Epoch 92/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8604 - loss: 1.8475 - precision: 0.8995 - recall: 0.8458 - val_accuracy: 0.9109 - val_loss: 1.7327 - val_precision: 0.9297 - val_recall: 0.8891 - learning_rate: 1.0000e-04\n","Epoch 93/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8707 - loss: 1.8038 - precision: 0.8919 - recall: 0.8594 - val_accuracy: 0.9073 - val_loss: 1.6848 - val_precision: 0.9303 - val_recall: 0.8982 - learning_rate: 1.0000e-04\n","Epoch 94/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9006 - loss: 1.7370 - precision: 0.9207 - recall: 0.8545 - val_accuracy: 0.9036 - val_loss: 1.6474 - val_precision: 0.9247 - val_recall: 0.8927 - learning_rate: 1.0000e-04\n","Epoch 95/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8574 - loss: 1.7424 - precision: 0.8757 - recall: 0.8281 - val_accuracy: 0.9273 - val_loss: 1.5987 - val_precision: 0.9423 - val_recall: 0.8909 - learning_rate: 1.0000e-04\n","Epoch 96/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8777 - loss: 1.6609 - precision: 0.8964 - recall: 0.8621 - val_accuracy: 0.9145 - val_loss: 1.5569 - val_precision: 0.9390 - val_recall: 0.8964 - learning_rate: 1.0000e-04\n","Epoch 97/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8780 - loss: 1.6349 - precision: 0.9037 - recall: 0.8493 - val_accuracy: 0.9145 - val_loss: 1.5204 - val_precision: 0.9298 - val_recall: 0.8909 - learning_rate: 1.0000e-04\n","Epoch 98/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8608 - loss: 1.6423 - precision: 0.8874 - recall: 0.8421 - val_accuracy: 0.9164 - val_loss: 1.4783 - val_precision: 0.9407 - val_recall: 0.8945 - learning_rate: 1.0000e-04\n","Epoch 99/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8961 - loss: 1.5681 - precision: 0.9085 - recall: 0.8718 - val_accuracy: 0.9182 - val_loss: 1.4451 - val_precision: 0.9362 - val_recall: 0.9073 - learning_rate: 1.0000e-04\n","Epoch 100/100\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9382 - loss: 1.4337 - precision: 0.9491 - recall: 0.9209 - val_accuracy: 0.9200 - val_loss: 1.4011 - val_precision: 0.9449 - val_recall: 0.9036 - learning_rate: 1.0000e-04\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n","Kết quả cuối cùng trên tập valid:\n","  Quadratic Weighted Kappa (QWK): 0.9349\n","  Weighted F1 Score: 0.9161\n","  Weighted Recall: 0.9200\n","  Weighted Precision: 0.9241\n","Đã lưu ma trận nhầm lẫn final_ tại: /content/drive/MyDrive/working/confusion_matrix_final_episode_21.png\n","Ma trận nhầm lẫn cuối cùng:\n","[[271   0   0   0   0]\n"," [  0  43  11   0   2]\n"," [  0   2 146   0   2]\n"," [  0   1  11  15   2]\n"," [  0   2  10   1  31]]\n","Đã lưu trọng số meta-model tại: /content/drive/MyDrive/working/model.weights.h5\n","Đã lưu cấu hình meta-model tại: /content/drive/MyDrive/working/config.json\n","Đã lưu siêu dữ liệu meta-model tại: /content/drive/MyDrive/working/metadata.json\n","Đã lưu các chỉ số đánh giá tại: /content/drive/MyDrive/working/final_metrics.json\n","Đã lưu biểu đồ lịch sử huấn luyện tại: /content/drive/MyDrive/working/training_history.png\n","Đánh giá trên tập test...\n","\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n","Kết quả trên tập test:\n","  Quadratic Weighted Kappa (QWK): 0.9067\n","  Weighted F1 Score: 0.8392\n","  Weighted Precision: 0.8464\n","  Weighted Recall: 0.8472\n","  Accuracy: 0.8472\n","Đã lưu ma trận nhầm lẫn tập test tại: /content/drive/MyDrive/working/confusion_matrix_test.png\n","Ma trận nhầm lẫn tập test:\n","[[356   2   3   0   0]\n"," [  3  37  32   0   2]\n"," [  0  10 176   6   8]\n"," [  0   0  21  12   6]\n"," [  0   2  16   1  40]]\n","Đã lưu các chỉ số đánh giá tập test tại: /content/drive/MyDrive/working/test_metrics.json\n","Hoàn thành quy trình huấn luyện và đánh giá!\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import pandas as pd\n","import cv2\n","import albumentations as A\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import EfficientNetB1, Xception, InceptionV3, ResNet50, DenseNet121\n","from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n","from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess\n","from tensorflow.keras.applications.inception_v3 import preprocess_input as inceptionv3_preprocess\n","from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n","from tensorflow.keras.applications.densenet import preprocess_input as densenet121_preprocess\n","from sklearn.metrics import cohen_kappa_score, f1_score, recall_score, confusion_matrix, precision_score, accuracy_score\n","from sklearn.utils import shuffle\n","from tensorflow.keras.layers import Dense, Input, BatchNormalization, Layer, Dropout\n","from sklearn.decomposition import PCA\n","from sklearn.isotonic import IsotonicRegression\n","import logging\n","from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau\n","import json\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import gc\n","from google.colab import drive\n","import time\n","import subprocess\n","\n","# Thiết lập tăng trưởng bộ nhớ GPU\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        print(\"Đã kích hoạt tăng trưởng bộ nhớ GPU\")\n","    except RuntimeError as e:\n","        print(f\"Lỗi khi thiết lập tăng trưởng bộ nhớ GPU: {e}\")\n","\n","# Thiết lập thư mục lưu trữ\n","feature_save_dir = \"/content/drive/MyDrive/working\"\n","log_dir = os.path.join(feature_save_dir, \"logs\")\n","os.makedirs(log_dir, exist_ok=True)\n","os.makedirs(feature_save_dir, exist_ok=True)\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","SIZE = 244\n","NUM_CLASSES = 5\n","TEMP_AUGMENT_DIR = \"/tmp/temp_augmented_images\"\n","os.makedirs(TEMP_AUGMENT_DIR, exist_ok=True)\n","\n","\n","\n","# Kiểm tra và mount Google Drive\n","if not os.path.ismount('/content/drive'):\n","    drive.mount('/content/drive')\n","else:\n","    print(\"Google Drive đã được mount.\")\n","\n","# Thiết lập thư mục lưu trữ trên Google Drive\n","feature_save_dir = \"/content/drive/MyDrive/working\"\n","log_dir = os.path.join(feature_save_dir, \"logs\")\n","os.makedirs(log_dir, exist_ok=True)\n","os.makedirs(feature_save_dir, exist_ok=True)\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","# Đọc dữ liệu\n","drive_folder = \"/content/drive/MyDrive/kaggle_data/aptos2019\"\n","processed_folder = \"/content/processed_train_images\"\n","df_train = pd.read_csv(os.path.join(drive_folder, \"train.csv\"))\n","processed_ids = [f.replace('.png', '') for f in os.listdir(processed_folder) if f.endswith('.png')]\n","df_train_processed = df_train[df_train['id_code'].isin(processed_ids)].copy()\n","\n","\n","\n","# Chia dữ liệu\n","x = df_train_processed['id_code']  # id_code có đuôi .png\n","y = df_train_processed['diagnosis']\n","if len(x) < 2:\n","    logging.error(\"Số mẫu quá ít để chia dữ liệu.\")\n","    raise ValueError(\"Cần ít nhất 2 mẫu để chia train/valid.\")\n","x, y = shuffle(x, y, random_state=42)\n","train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15, stratify=y, random_state=42)\n","\n","logging.info(f\"Train X shape: {train_x.shape}\")\n","logging.info(f\"Valid X shape: {valid_x.shape}\")\n","\n","# Tải ảnh đã xử lý\n","def load_processed_image(image_id, processed_folder, size=244):\n","    try:\n","        img_path = os.path.join(processed_folder, f\"{image_id}.png\")\n","        if not os.path.exists(img_path):\n","            logging.error(f\"Ảnh không tồn tại: {img_path}\")\n","            return None\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            logging.error(f\"Không đọc được ảnh: {img_path}\")\n","            return None\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n","        return img\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi tải ảnh {image_id}: {str(e)}\")\n","        return None\n","\n","resized_train_x = np.array([load_processed_image(id_code, processed_folder, size=SIZE) for id_code in train_x])\n","resized_valid_x = np.array([load_processed_image(id_code, processed_folder, size=SIZE) for id_code in valid_x])\n","\n","train_y_multi = tf.keras.utils.to_categorical(train_y, num_classes=NUM_CLASSES)\n","valid_y_multi = tf.keras.utils.to_categorical(valid_y, num_classes=NUM_CLASSES)\n","\n","# Tải ảnh đã xử lý\n","def load_processed_image(image_id, processed_folder, size=244):\n","    try:\n","        img_path = os.path.join(processed_folder, f\"{image_id}.png\")\n","        if not os.path.exists(img_path):\n","            logging.error(f\"Ảnh không tồn tại: {img_path}\")\n","            return None\n","        img = cv2.imread(img_path)\n","        if img is None:\n","            logging.error(f\"Không đọc được ảnh: {img_path}\")\n","            return None\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n","        return img\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi tải ảnh {image_id}: {str(e)}\")\n","        return None\n","\n","resized_train_x = np.array([load_processed_image(id_code, processed_folder, size=SIZE) for id_code in train_x])\n","resized_valid_x = np.array([load_processed_image(id_code, processed_folder, size=SIZE) for id_code in valid_x])\n","resized_test_x = np.array([load_processed_image(id_code, processed_folder, size=SIZE) for id_code in test_x])\n","\n","train_y_multi = tf.keras.utils.to_categorical(train_y, num_classes=NUM_CLASSES)\n","valid_y_multi = tf.keras.utils.to_categorical(valid_y, num_classes=NUM_CLASSES)\n","test_y_multi = tf.keras.utils.to_categorical(test_y, num_classes=NUM_CLASSES)\n","\n","# Hàm custom_random_erasing\n","def custom_random_erasing(image, scale=(0.01, 0.05), ratio=(0.5, 2.0), p=0.3, value=None):\n","    if np.random.random() > p:\n","        return image\n","    height, width, channels = image.shape\n","    area = height * width\n","    scale_factor = np.random.uniform(scale[0], scale[1])\n","    erase_area = area * scale_factor\n","    aspect_ratio = np.random.uniform(ratio[0], ratio[1])\n","    erase_height = int(np.sqrt(erase_area / aspect_ratio))\n","    erase_width = int(np.sqrt(erase_area * aspect_ratio))\n","    erase_height = min(erase_height, height)\n","    erase_width = min(erase_width, width)\n","    if erase_height < 1 or erase_width < 1:\n","        return image\n","    x = np.random.randint(0, width - erase_width + 1)\n","    y = np.random.randint(0, height - erase_height + 1)\n","    output = image.copy()\n","    if value is None:\n","        value = np.mean(image, axis=(0, 1))\n","    output[y:y+erase_height, x:x+erase_width, :] = value\n","    return output\n","\n","# Hàm balance_and_augment_data\n","def balance_and_augment_data(images, labels, target_classes=[0, 1, 2, 3, 4], samples_per_class=None):\n","    num_classes = labels.shape[1]\n","    label_indices = np.argmax(labels, axis=1)\n","    keep_indices = np.isin(label_indices, target_classes)\n","    filtered_images = images[keep_indices]\n","    filtered_labels = labels[keep_indices]\n","    filtered_label_indices = label_indices[keep_indices]\n","    class_counts = np.bincount(filtered_label_indices, minlength=num_classes)\n","    print(f\"Phân bố nhãn ban đầu: {dict(zip(range(num_classes), class_counts))}\")\n","    cls_counts = [class_counts[cls] for cls in target_classes]\n","    max_count = samples_per_class or max(cls_counts)\n","    print(f\"Số mẫu mục tiêu mỗi lớp: {max_count}\")\n","    augmenter = A.Compose([\n","        A.HorizontalFlip(p=0.5),\n","        A.Rotate(limit=15, p=0.3),  # Reduced rotation\n","        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),  # Reduced intensity\n","        A.GaussNoise(var_limit=(10.0, 20.0), p=0.2),\n","        A.CLAHE(clip_limit=1.0, tile_grid_size=(8, 8), p=0.2),  # Reduced CLAHE\n","    ])\n","    new_images = []\n","    new_labels = []\n","    for cls in target_classes:\n","        cls_indices = np.where(filtered_label_indices == cls)[0]\n","        cls_images = filtered_images[cls_indices]\n","        cls_labels = filtered_labels[cls_indices]\n","        current_count = len(cls_indices)\n","        new_images.extend(cls_images)\n","        new_labels.extend(cls_labels)\n","        print(f\"Lớp {cls}: {current_count} mẫu ban đầu\")\n","        augment_count = max_count - current_count\n","        if augment_count > 0:\n","            print(f\"Tăng cường {augment_count} mẫu cho lớp {cls}\")\n","            for _ in range(augment_count):\n","                idx = np.random.choice(cls_indices)\n","                img = filtered_images[idx].astype(np.uint8)\n","                aug_img = augmenter(image=img)['image']\n","                aug_img = custom_random_erasing(\n","                    aug_img, scale=(0.01, 0.05), ratio=(0.5, 2.0), p=0.0, value=np.mean(aug_img, axis=(0, 1))  # Disabled\n","                )\n","                new_images.append(aug_img)\n","                new_labels.append(filtered_labels[idx])\n","    new_images = np.array(new_images, dtype=np.float32)\n","    new_labels = np.array(new_labels, dtype=np.float32)\n","    new_images, new_labels = shuffle(new_images, new_labels, random_state=42)\n","    final_class_counts = np.bincount(np.argmax(new_labels, axis=1), minlength=num_classes)\n","    print(f\"Phân bố nhãn sau cân bằng: {dict(zip(range(num_classes), final_class_counts))}\")\n","    return new_images, new_labels\n","\n","# Cân bằng dữ liệu train\n","class_counts = np.bincount(train_y)\n","class_0_count = class_counts[0]\n","print(f\"Số mẫu lớp 0: {class_0_count}\")\n","balanced_train_x, balanced_train_y_multi = balance_and_augment_data(\n","    resized_train_x, train_y_multi, target_classes=[1, 2, 3, 4], samples_per_class=class_0_count\n",")\n","class_0_indices = np.where(np.argmax(train_y_multi, axis=1) == 0)[0]\n","class_0_images = resized_train_x[class_0_indices]\n","class_0_labels = train_y_multi[class_0_indices]\n","balanced_train_x = np.concatenate([balanced_train_x, class_0_images], axis=0)\n","balanced_train_y_multi = np.concatenate([balanced_train_y_multi, class_0_labels], axis=0)\n","balanced_train_x, balanced_train_y_multi = shuffle(balanced_train_x, balanced_train_y_multi, random_state=42)\n","final_class_counts = np.bincount(np.argmax(balanced_train_y_multi, axis=1), minlength=5)\n","print(f\"Phân bố nhãn sau khi thêm lớp 0: {dict(zip(range(5), final_class_counts))}\")\n","print(\"balanced_train_x shape:\", balanced_train_x.shape)\n","print(\"balanced_train_y_multi shape:\", balanced_train_y_multi.shape)\n","\n","# Định nghĩa model_configs\n","model_configs = {\n","    \"efficientnetb1\": {\n","        \"model_type\": \"efficientnetb1\",\n","        \"config_path\": \"/content/drive/MyDrive/working/EfficientNetB1_bestqwk_aptos/config.json\",\n","        \"weights_path\": \"/content/drive/MyDrive/working/EfficientNetB1_bestqwk_aptos/model.weights.h5\",\n","        \"preprocess\": efficientnet_preprocess,\n","        \"img_size\": 244,\n","        \"base_model\": EfficientNetB1\n","    },\n","    \"xception\": {\n","        \"model_type\": \"xception\",\n","        \"config_path\": \"/content/drive/MyDrive/working/Xception_bestqwk_aptos/config.json\",\n","        \"weights_path\": \"/content/drive/MyDrive/working/Xception_bestqwk_aptos/model.weights.h5\",\n","        \"preprocess\": xception_preprocess,\n","        \"img_size\": 244,\n","        \"base_model\": Xception\n","    },\n","    \"inceptionv3\": {\n","        \"model_type\": \"inceptionv3\",\n","        \"config_path\": \"/content/drive/MyDrive/working/InceptionV3_bestqwk_aptos/config.json\",\n","        \"weights_path\": \"/content/drive/MyDrive/working/InceptionV3_bestqwk_aptos/model.weights.h5\",\n","        \"preprocess\": inceptionv3_preprocess,\n","        \"img_size\": 299,\n","        \"base_model\": InceptionV3\n","    },\n","    \"resnet50\": {\n","        \"model_type\": \"resnet50\",\n","        \"config_path\": \"/content/drive/MyDrive/working/ResNet50_bestqwk_aptos/config.json\",\n","        \"weights_path\": \"/content/drive/MyDrive/working/ResNet50_bestqwk_aptos/model.weights.h5\",\n","        \"preprocess\": resnet50_preprocess,\n","        \"img_size\": 244,\n","        \"base_model\": ResNet50\n","    },\n","    \"densenet121\": {\n","        \"model_type\": \"densenet121\",\n","        \"config_path\": \"/content/drive/MyDrive/working/DenseNet121_bestqwk_aptos/config.json\",\n","        \"weights_path\": \"/content/drive/MyDrive/working/DenseNet121_bestqwk_aptos/model.weights.h5\",\n","        \"preprocess\": densenet121_preprocess,\n","        \"img_size\": 244,\n","        \"base_model\": DenseNet121\n","    }\n","}\n","\n","# My_Generator với mixup\n","class My_Generator(tf.keras.utils.Sequence):\n","    def __init__(self, images, labels, batch_size, is_train=False, mix=True, augment=False, size1=244, size2=299, model_type=\"default\", preprocess=None):\n","        self.labels = np.array(labels, dtype=np.float32)\n","        self.batch_size = batch_size\n","        self.is_train = is_train\n","        self.is_augment = augment\n","        self.is_mix = mix\n","        self.model_type = str(model_type).lower()\n","        self.preprocess = preprocess\n","        self.temp_augment_dir = TEMP_AUGMENT_DIR\n","        os.makedirs(self.temp_augment_dir, exist_ok=True)\n","        self.target_size = (size2, size2) if 'inceptionv3' in self.model_type or 'xception' in self.model_type else (size1, size1)\n","        self.image_paths = []\n","        if isinstance(images, np.ndarray):\n","            for i, img in enumerate(images):\n","                img_path = os.path.join(self.temp_augment_dir, f\"img_{i}_{np.random.randint(1000000)}.png\")\n","                try:\n","                    if img.dtype != np.uint8:\n","                        if img.max() <= 1.0:\n","                            img = (img * 255).astype(np.uint8)\n","                        else:\n","                            img = img.astype(np.uint8)\n","                    cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n","                    self.image_paths.append(img_path)\n","                except Exception as e:\n","                    logging.error(f\"Lỗi khi lưu ảnh {img_path}: {str(e)}\")\n","                    continue\n","        else:\n","            self.image_paths = list(images)\n","        unique_paths = []\n","        unique_indices = []\n","        seen = set()\n","        for i, path in enumerate(self.image_paths):\n","            if path not in seen:\n","                seen.add(path)\n","                unique_paths.append(path)\n","                unique_indices.append(i)\n","        self.image_paths = unique_paths\n","        self.labels = self.labels[unique_indices]\n","        if len(self.image_paths) != len(self.labels):\n","            logging.error(f\"Số image_paths ({len(self.image_paths)}) không khớp với số labels ({len(self.labels)})\")\n","            self.labels = self.labels[:len(self.image_paths)]\n","        if not self.image_paths:\n","            raise ValueError(\"Không có image_paths hợp lệ được tạo.\")\n","        print(f\"Khởi tạo My_Generator: {len(self.image_paths)} mẫu, target_size={self.target_size}, is_train={is_train}\")\n","        self.dataset = self._create_dataset()\n","\n","    def _load_image(self, img_path):\n","        img = tf.io.read_file(img_path)\n","        img = tf.image.decode_png(img, channels=3)\n","        img = tf.image.resize(img, self.target_size, method=tf.image.ResizeMethod.BILINEAR)\n","        img = tf.ensure_shape(img, [self.target_size[0], self.target_size[1], 3])\n","        img = tf.cast(img, tf.float32) / 255.0\n","        if self.preprocess is not None:\n","            img = self.preprocess(img)\n","        return img\n","\n","    def _mixup(self, images, labels):\n","        batch_size = tf.shape(images)[0]\n","        lam = tf.random.uniform([], minval=0.2, maxval=0.4, dtype=tf.float32)\n","        indices = tf.random.shuffle(tf.range(batch_size, dtype=tf.int32))\n","        mixed_images = lam * images + (1 - lam) * tf.gather(images, indices)\n","        mixed_labels = lam * labels + (1 - lam) * tf.gather(labels, indices)\n","        return mixed_images, mixed_labels\n","\n","    def _create_dataset(self):\n","        dataset = tf.data.Dataset.from_tensor_slices((self.image_paths, self.labels))\n","        dataset = dataset.map(\n","            lambda img_path, label: (self._load_image(img_path), label),\n","            num_parallel_calls=tf.data.AUTOTUNE\n","        )\n","        if self.is_train:\n","            dataset = dataset.shuffle(buffer_size=len(self.image_paths))\n","        dataset = dataset.batch(self.batch_size, drop_remainder=False)\n","        if self.is_train and self.is_mix:\n","            dataset = dataset.map(\n","                self._mixup,\n","                num_parallel_calls=tf.data.AUTOTUNE\n","            )\n","        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","        return dataset\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.image_paths) / self.batch_size))\n","\n","    def __iter__(self):\n","        self.iterator = iter(self.dataset)\n","        return self\n","\n","    def __next__(self):\n","        return next(self.iterator)\n","\n","# Callback để tính trọng số lớp từ confusion matrix\n","class ConfusionMatrixWeightCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, valid_features, valid_labels, classification_model, num_classes=5, class_counts=None):\n","        super().__init__()\n","        self.valid_features = valid_features\n","        self.valid_labels = valid_labels\n","        self.classification_model = classification_model\n","        self.num_classes = num_classes\n","        self.prev_cm = None\n","        self.class_weights = np.ones(num_classes, dtype=np.float32)\n","        self.class_counts = class_counts\n","        self.history_dir = os.path.join(feature_save_dir, \"history\")\n","        os.makedirs(self.history_dir, exist_ok=True)\n","        self.weights_history = []\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        y_pred = self.classification_model.predict(self.valid_features, verbose=0, batch_size=32)\n","        y_true = np.argmax(self.valid_labels, axis=1)\n","        y_pred_classes = np.argmax(y_pred, axis=1)\n","        cm = confusion_matrix(y_true, y_pred_classes, labels=list(range(self.num_classes)))\n","        print(f\"Epoch {epoch+1} - Ma trận nhầm lẫn:\\n{cm}\")\n","        errors = np.sum(cm * (1 - np.eye(self.num_classes)), axis=1)\n","        total_samples_per_class = np.sum(cm, axis=1)\n","        total_samples_per_class = np.where(total_samples_per_class == 0, 1, total_samples_per_class)\n","        error_rates = errors / total_samples_per_class\n","        weak_classes = []\n","        if self.class_counts is not None:\n","            min_count = np.min(self.class_counts[self.class_counts > 0])\n","            weak_classes = np.where(self.class_counts <= min_count * 1.5)[0]\n","        high_error_classes = np.where(error_rates >= np.percentile(error_rates, 75))[0]\n","        weak_classes = np.unique(np.concatenate([weak_classes, high_error_classes])).astype(int)\n","        self.class_weights = 1.0 + error_rates\n","        for cls in weak_classes:\n","            self.class_weights[cls] *= 2.0\n","        self.class_weights /= self.class_weights.max()\n","        print(f\"Epoch {epoch+1} - Lớp yếu: {weak_classes}\")\n","        print(f\"Epoch {epoch+1} - Trọng số lớp: {self.class_weights}\")\n","        self.weights_history.append({\n","            \"epoch\": epoch + 1,\n","            \"class_weights\": self.class_weights.tolist(),\n","            \"weak_classes\": weak_classes.tolist(),\n","            \"confusion_matrix\": cm.tolist()\n","        })\n","        weights_path = os.path.join(self.history_dir, f\"class_weights_epoch_{epoch+1}.json\")\n","        with open(weights_path, 'w') as f:\n","            json.dump(self.weights_history[-1], f, indent=4)\n","        print(f\"Đã lưu trọng số lớp tại: {weights_path}\")\n","        plt.figure(figsize=(8, 6))\n","        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                    xticklabels=list(range(self.num_classes)),\n","                    yticklabels=list(range(self.num_classes)))\n","        plt.title(f'Ma trận nhầm lẫn - Epoch {epoch+1}')\n","        plt.xlabel('Dự đoán')\n","        plt.ylabel('Thực tế')\n","        cm_path = os.path.join(feature_save_dir, f'confusion_matrix_epoch_{epoch+1}.png')\n","        plt.savefig(cm_path)\n","        plt.close()\n","        print(f\"Đã lưu ma trận nhầm lẫn tại: {cm_path}\")\n","        self.prev_cm = cm.copy()\n","\n","    def get_class_weights(self):\n","        return self.class_weights\n","\n","# Các hàm và lớp hỗ trợ\n","def load_model_from_config(config_path, weights_path, base_model_class):\n","    try:\n","        if config_path and os.path.exists(config_path) and weights_path and os.path.exists(weights_path):\n","            with open(config_path, 'r') as f:\n","                model_config = json.load(f)\n","            model = tf.keras.models.model_from_json(json.dumps(model_config))\n","            model.load_weights(weights_path)\n","            return model\n","        raise FileNotFoundError\n","    except:\n","        return base_model_class(weights='imagenet', include_top=False, pooling='avg')\n","\n","class GradientReversalLayer(Layer):\n","    def __init__(self, lambda_=1.0, **kwargs):\n","        super().__init__(**kwargs)\n","        self.lambda_ = lambda_\n","    def call(self, inputs, training=None):\n","        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n","        return inputs if not training else tf.math.multiply(-self.lambda_, inputs)\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\"lambda_\": self.lambda_})\n","        return config\n","\n","class MemoryAugmentedLayer(tf.keras.layers.Layer):\n","    def __init__(self, memory_size, memory_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.memory_size = memory_size\n","        self.memory_dim = memory_dim\n","    def build(self, input_shape):\n","        self.memory = self.add_weight(\n","            shape=(self.memory_size, self.memory_dim),\n","            initializer='zeros',\n","            trainable=False,\n","            dtype=tf.float32\n","        )\n","        super().build(input_shape)\n","    def call(self, inputs):\n","        batch_size = tf.shape(inputs)[0]\n","        memory_size = tf.shape(self.memory)[0]\n","        memory_sliced = tf.cond(\n","            batch_size > memory_size,\n","            lambda: tf.tile(self.memory, [(batch_size + memory_size - 1) // memory_size, 1])[:batch_size],\n","            lambda: self.memory[:batch_size]\n","        )\n","        return tf.reduce_mean(tf.stack([inputs, memory_sliced], axis=0), axis=0)\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({'memory_size': self.memory_size, 'memory_dim': self.memory_dim})\n","        return config\n","\n","class CustomGridDropout(tf.keras.layers.Layer):\n","    def __init__(self, ratio=0.3, holes_number=4, p=0.5, **kwargs):\n","        super().__init__(**kwargs)\n","        self.ratio = ratio\n","        self.holes_number = holes_number\n","        self.p = p\n","    def call(self, inputs, training=None):\n","        if not training:\n","            return inputs\n","        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n","        batch_size = tf.shape(inputs)[0]\n","        feature_dim = tf.shape(inputs)[1]\n","        hole_size = tf.maximum(1, tf.cast(tf.cast(feature_dim, tf.float32) * self.ratio, tf.int32))\n","        mask = tf.ones_like(inputs, dtype=tf.float32)\n","        random_probs = tf.random.uniform([self.holes_number], 0, 1)\n","        active_holes = tf.cast(random_probs < self.p, tf.int32)\n","        hole_indices = tf.range(self.holes_number)\n","        start_indices = (hole_indices * feature_dim) // self.holes_number\n","        end_indices = tf.minimum(start_indices + hole_size, feature_dim)\n","        all_indices = []\n","        for i in range(self.holes_number):\n","            should_apply = active_holes[i]\n","            indices = tf.cond(\n","                should_apply > 0,\n","                lambda: tf.stack([\n","                    tf.tile(tf.range(batch_size), [end_indices[i] - start_indices[i]]),\n","                    tf.repeat(tf.range(start_indices[i], end_indices[i]), batch_size)\n","                ], axis=1),\n","                lambda: tf.zeros([0, 2], dtype=tf.int32)\n","            )\n","            all_indices.append(indices)\n","        all_indices = tf.concat(all_indices, axis=0)\n","        updates = tf.zeros([tf.shape(all_indices)[0]], dtype=tf.float32)\n","        mask = tf.tensor_scatter_nd_update(mask, all_indices, updates)\n","        return inputs * mask\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"ratio\": self.ratio,\n","            \"holes_number\": self.holes_number,\n","            \"p\": self.p\n","        })\n","        return config\n","\n","from sklearn.preprocessing import StandardScaler\n","def normalize_features(features, target_dim):\n","    try:\n","        if len(features.shape) != 2:\n","            raise ValueError(f\"Expected 2D features, got shape {features.shape}\")\n","        scaler = StandardScaler()\n","        normalized = scaler.fit_transform(features)\n","        current_dim = normalized.shape[1]\n","        if current_dim == target_dim:\n","            return normalized\n","        elif current_dim > target_dim:\n","            return normalized[:, :target_dim]\n","        else:\n","            padding = np.zeros((normalized.shape[0], target_dim - current_dim), dtype=np.float32)\n","            return np.concatenate([normalized, padding], axis=1)\n","    except Exception as e:\n","        logging.error(f\"Error normalizing features: {str(e)}\")\n","        return np.zeros((features.shape[0], target_dim), dtype=np.float32)\n","\n","def extract_and_save_features(model_name, feature_extractor, generator, save_dir, sample_ids):\n","    expected_samples = len(generator.image_paths)\n","    features_2d = []\n","    processed_samples = []\n","    iterator = iter(generator.dataset)\n","    steps = int(np.ceil(expected_samples / generator.batch_size))\n","    for step in range(steps):\n","        try:\n","            batch_data = next(iterator, None)\n","            if batch_data is None:\n","                break\n","            batch_images, _ = batch_data\n","            if batch_images.shape[0] == 0:\n","                continue\n","            batch_features_2d = feature_extractor(batch_images, training=False)\n","            features_2d.append(batch_features_2d.numpy().astype(np.float32))\n","            processed_samples.extend(sample_ids[step * generator.batch_size: (step + 1) * generator.batch_size][:batch_images.shape[0]])\n","        except Exception as e:\n","            logging.error(f\"Lỗi tại batch {step+1}: {str(e)}\")\n","            continue\n","    features_2d = np.concatenate(features_2d, axis=0) if features_2d else np.zeros((expected_samples, 512), dtype=np.float32)\n","    if features_2d.shape[0] != expected_samples:\n","        features_2d = features_2d[:expected_samples] if features_2d.shape[0] > expected_samples else \\\n","                      np.pad(features_2d, ((0, expected_samples - features_2d.shape[0]), (0, 0)), mode='edge')\n","    os.makedirs(save_dir, exist_ok=True)\n","    features_2d_path = os.path.join(save_dir, f\"{model_name}_features_2d.npy\")\n","    try:\n","        np.save(features_2d_path, features_2d)\n","        for _ in range(3):\n","            subprocess.run([\"sync\"])\n","            time.sleep(1)\n","            if os.path.exists(features_2d_path):\n","                print(f\"Đã lưu đặc trưng 2D tại: {features_2d_path}, shape={features_2d.shape}\")\n","                break\n","        else:\n","            logging.error(f\"Không thể lưu tệp 2D tại: {features_2d_path} sau nhiều lần thử\")\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi lưu đặc trưng 2D tại {features_2d_path}: {str(e)}\")\n","        raise\n","    metadata = {\n","        \"model_name\": model_name,\n","        \"features_2d_path\": features_2d_path,\n","        \"sample_ids\": processed_samples,\n","        \"timestamp\": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n","    }\n","    metadata_path = os.path.join(save_dir, f\"{model_name}_features_metadata.json\")\n","    try:\n","        with open(metadata_path, 'w') as f:\n","            json.dump(metadata, f, indent=4)\n","        subprocess.run([\"sync\"])\n","        print(f\"Đã lưu metadata tại: {metadata_path}\")\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi lưu metadata tại {metadata_path}: {str(e)}\")\n","    return features_2d\n","\n","def combine_and_reduce_features(features_dict, labels, sample_ids, save_dir, n_components=50, target_dim=512):\n","    num_samples = len(sample_ids)\n","    normalized_features = {}\n","    for model_name, features in features_dict.items():\n","        if features.shape[0] == num_samples:\n","            normalized_features[model_name] = normalize_features(features, target_dim)\n","        else:\n","            features_adj = features[:num_samples] if features.shape[0] > num_samples else \\\n","                           np.pad(features, ((0, num_samples - features.shape[0]), (0, 0)), mode='edge')\n","            normalized_features[model_name] = normalize_features(features_adj, target_dim)\n","    for model_name, features in normalized_features.items():\n","        features_path = os.path.join(save_dir, f\"{model_name}_normalized_features_2d.npy\")\n","        np.save(features_path, features)\n","        print(f\"Đã lưu đặc trưng 2D chuẩn hóa cho {model_name} tại: {features_path}, shape={features.shape}\")\n","    combined_features = []\n","    valid_indices = []\n","    for i in range(num_samples):\n","        sample_features = [normalized_features[model_name][i] for model_name in normalized_features\n","                          if i < len(normalized_features[model_name])]\n","        if sample_features:\n","            combined_features.append(np.concatenate(sample_features))\n","            valid_indices.append(i)\n","    combined_features = np.array(combined_features, dtype=np.float32) if combined_features else \\\n","                       np.zeros((num_samples, target_dim * len(normalized_features)), dtype=np.float32)\n","    valid_indices = np.array(valid_indices) if valid_indices else np.arange(num_samples)\n","    combined_features_path = os.path.join(save_dir, \"combined_features_2d_before_pca.npy\")\n","    np.save(combined_features_path, combined_features)\n","    print(f\"Đã lưu đặc trưng 2D kết hợp (trước PCA) tại: {combined_features_path}, shape={combined_features.shape}\")\n","    pca = None\n","    reduced_features = combined_features\n","    if n_components is not None:\n","        pca = PCA(n_components=n_components)\n","        reduced_features = pca.fit_transform(combined_features)\n","    reduced_features_path = os.path.join(save_dir, \"combined_features_2d_after_pca.npy\")\n","    np.save(reduced_features_path, reduced_features)\n","    print(f\"Đã lưu đặc trưng 2D kết hợp (sau PCA) tại: {reduced_features_path}, shape={reduced_features.shape}\")\n","    metadata = {\n","        \"model_names\": list(features_dict.keys()),\n","        \"num_samples\": num_samples,\n","        \"target_dim\": target_dim,\n","        \"n_components\": n_components,\n","        \"sample_ids\": sample_ids.tolist(),\n","        \"labels\": labels.tolist(),\n","        \"features_2d_paths\": {model_name: os.path.join(save_dir, f\"{model_name}_normalized_features_2d.npy\")\n","                             for model_name in features_dict},\n","        \"combined_features_before_pca\": combined_features_path,\n","        \"combined_features_after_pca\": reduced_features_path,\n","        \"timestamp\": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n","    }\n","    metadata_path = os.path.join(save_dir, \"combined_features_metadata.json\")\n","    with open(metadata_path, 'w') as f:\n","        json.dump(metadata, f, indent=4)\n","    print(f\"Đã lưu metadata tại: {metadata_path}\")\n","    return reduced_features, pca, valid_indices, reduced_features.shape[1]\n","\n","def save_meta_learner_features(meta_feature_model, features, labels, sample_ids, save_dir):\n","    meta_features_2d = meta_feature_model.predict(features, batch_size=32, verbose=0)\n","    meta_features_2d_path = os.path.join(save_dir, \"meta_learner_features_2d.npy\")\n","    np.save(meta_features_2d_path, meta_features_2d)\n","    print(f\"Đã lưu đặc trưng 2D của meta-learner tại: {meta_features_2d_path}, shape={meta_features_2d.shape}\")\n","    metadata = {\n","        \"model_name\": \"meta_learner\",\n","        \"features_2d_path\": meta_features_2d_path,\n","        \"sample_ids\": sample_ids.tolist(),\n","        \"labels\": labels.tolist(),\n","        \"timestamp\": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n","    }\n","    metadata_path = os.path.join(save_dir, \"meta_learner_features_metadata.json\")\n","    with open(metadata_path, 'w') as f:\n","        json.dump(metadata, f, indent=4)\n","    print(f\"Đã lưu metadata meta-learner tại: {metadata_path}\")\n","    return meta_features_2d\n","\n","def augment_single_class(features, labels, cls, num_samples_needed):\n","    cls_indices = np.where(np.argmax(labels, axis=1) == cls)[0]\n","    if len(cls_indices) == 0:\n","        return [], []\n","    augmenter = A.Compose([\n","        A.HorizontalFlip(p=0.5),\n","        A.VerticalFlip(p=0.5),\n","        A.Rotate(limit=45, p=0.7),\n","        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n","        A.GaussNoise(p=0.5),\n","        A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.3),\n","        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n","        A.RandomCrop(height=int(SIZE*0.9), width=int(SIZE*0.9), p=0.3),\n","        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.5)\n","    ])\n","    aug_features = []\n","    aug_labels = []\n","    for _ in range(num_samples_needed):\n","        idx = np.random.choice(cls_indices)\n","        img = features[idx].astype(np.uint8)\n","        aug_img = augmenter(image=img)['image']\n","        aug_img = custom_random_erasing(\n","            aug_img, scale=(0.01, 0.05), ratio=(0.5, 2.0), p=0.3, value=np.mean(aug_img, axis=(0, 1))\n","        )\n","        aug_features.append(aug_img)\n","        aug_labels.append(labels[idx])\n","    return np.array(aug_features, dtype=np.float32), np.array(aug_labels, dtype=np.float32)\n","\n","def create_episode(features, labels, n_support=10, n_query=10, hard_sample_ratio=0.3, class_3_multiplier=2):\n","    target_classes = [0, 1, 2, 3, 4]\n","    if len(labels.shape) > 1:\n","        label_indices = np.argmax(labels, axis=1)\n","    else:\n","        label_indices = labels\n","    keep_indices = np.isin(label_indices, target_classes)\n","    features = features[keep_indices]\n","    labels = labels[keep_indices]\n","    label_indices = label_indices[keep_indices]\n","    support_features, support_labels, query_features, query_labels = [], [], [], []\n","    hard_indices = []\n","    n_support_class_3 = int(n_support * class_3_multiplier)\n","    n_query_class_3 = int(n_query * class_3_multiplier)\n","    for label in target_classes:\n","        indices = np.where(label_indices == label)[0]\n","        n_support_cls = n_support_class_3 if label == 3 else n_support\n","        n_query_cls = n_query_class_3 if label == 3 else n_query\n","        min_samples_per_class = n_support_cls + n_query_cls\n","        if len(indices) == 0:\n","            logging.warning(f\"Lớp {label} không có mẫu. Bỏ qua.\")\n","            continue\n","        if len(indices) < min_samples_per_class:\n","            logging.info(f\"Lớp {label} chỉ có {len(indices)} mẫu, cần {min_samples_per_class}. Sử dụng oversampling.\")\n","            indices = np.random.choice(indices, size=min_samples_per_class, replace=True)\n","        support_indices = np.random.choice(indices, n_support_cls, replace=False)\n","        remaining_indices = np.setdiff1d(indices, support_indices)\n","        n_hard = int(n_query_cls * hard_sample_ratio)\n","        if len(remaining_indices) < n_hard:\n","            hard_samples = np.random.choice(remaining_indices, n_hard, replace=True)\n","        else:\n","            hard_samples = np.random.choice(remaining_indices, n_hard, replace=False)\n","        easy_samples = np.setdiff1d(remaining_indices, hard_samples)\n","        n_easy = n_query_cls - len(hard_samples)\n","        if n_easy > 0:\n","            if len(easy_samples) < n_easy:\n","                easy_samples = np.random.choice(easy_samples, n_easy, replace=True)\n","            else:\n","                easy_samples = np.random.choice(easy_samples, n_easy, replace=False)\n","            query_indices = np.concatenate([hard_samples, easy_samples])\n","        else:\n","            query_indices = hard_samples\n","        support_features.extend(features[support_indices])\n","        support_labels.extend(labels[support_indices])\n","        query_features.extend(features[query_indices])\n","        query_labels.extend(labels[query_indices])\n","        hard_indices.extend(hard_samples)\n","    support_features = np.array(support_features, dtype=np.float32)\n","    support_labels = np.array(support_labels, dtype=np.float32)\n","    query_features = np.array(query_features, dtype=np.float32)\n","    query_labels = np.array(query_labels, dtype=np.float32)\n","    hard_indices = np.array(hard_indices, dtype=np.int32)\n","    if support_features.size == 0 or query_features.size == 0:\n","        logging.warning(\"Episode rỗng được tạo ra. Trả về episode rỗng.\")\n","        return np.array([]), np.array([]), np.array([]), np.array([]), np.array([])\n","    support_label_counts = np.bincount(np.argmax(support_labels, axis=1), minlength=5)\n","    query_label_counts = np.bincount(np.argmax(query_labels, axis=1), minlength=5)\n","    print(f\"Episode distribution - Support: {dict(zip(range(5), support_label_counts))}\")\n","    print(f\"Episode distribution - Query: {dict(zip(range(5), query_label_counts))}\")\n","    return support_features, support_labels, query_features, query_labels, hard_indices\n","\n","class CustomIsotonicRegression:\n","    def __init__(self):\n","        self.iso_reg = IsotonicRegression()\n","        self.X_min_ = None\n","        self.X_max_ = None\n","    def fit(self, X, y):\n","        self.X_min_ = np.min(X)\n","        self.X_max_ = np.max(X)\n","        self.iso_reg.fit(X, y)\n","        return self\n","    def predict(self, X):\n","        X_clipped = np.clip(X, self.X_min_, self.X_max_)\n","        return self.iso_reg.predict(X_clipped)\n","\n","import tensorflow as tf\n","import numpy as np\n","import logging\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","import pandas as pd\n","import gc\n","from sklearn.metrics import cohen_kappa_score, f1_score, precision_score, recall_score, confusion_matrix\n","from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\n","from tensorflow.keras.models import Model\n","\n","def maml_fomaml_train_manual(features, labels, valid_features, valid_labels, input_dim, n_episodes=20,\n","                             n_support=10, n_query=10, inner_lr=0.0005, outer_lr=0.0005, fine_tune_lr=0.0001,\n","                             use_fomaml=True, memory_size=20, sample_ids=None):\n","    \"\"\"\n","    Huấn luyện meta-learner sử dụng MAML/FO-MAML với log đầy đủ chỉ số trên support set.\n","\n","    Args:\n","        features: Đặc trưng tập train (train_combined_features).\n","        labels: Nhãn tập train (train_y_multi, one-hot).\n","        valid_features: Đặc trưng tập valid.\n","        valid_labels: Nhãn tập valid (one-hot).\n","        input_dim: Kích thước đầu vào của mô hình.\n","        n_episodes: Số episode huấn luyện.\n","        n_support: Số mẫu trong support set mỗi lớp.\n","        n_query: Số mẫu trong query set mỗi lớp.\n","        inner_lr: Learning rate cho inner loop.\n","        outer_lr: Learning rate cho outer loop.\n","        fine_tune_lr: Learning rate cho fine-tuning.\n","        use_fomaml: Sử dụng FO-MAML thay vì MAML.\n","        memory_size: Kích thước bộ nhớ cho MemoryAugmentedLayer.\n","        sample_ids: ID mẫu cho việc lưu đặc trưng meta-learner.\n","\n","    Returns:\n","        meta_model: Mô hình meta-learner đầy đủ.\n","        meta_classification_model: Mô hình phân lớp.\n","        history: Lịch sử huấn luyện với các chỉ số.\n","    \"\"\"\n","    # Định nghĩa thư mục lưu trữ\n","    feature_save_dir = \"/content/drive/MyDrive/working\"\n","    log_dir = os.path.join(feature_save_dir, \"logs\")\n","    os.makedirs(log_dir, exist_ok=True)\n","\n","    # Định nghĩa lớp MemoryAugmentedLayer\n","    class MemoryAugmentedLayer(tf.keras.layers.Layer):\n","        def __init__(self, memory_size, memory_dim, **kwargs):\n","            super().__init__(**kwargs)\n","            self.memory_size = memory_size\n","            self.memory_dim = memory_dim\n","        def build(self, input_shape):\n","            self.memory = self.add_weight(\n","                shape=(self.memory_size, self.memory_dim),\n","                initializer='zeros',\n","                trainable=False,\n","                dtype=tf.float32\n","            )\n","            super().build(input_shape)\n","        def call(self, inputs):\n","            batch_size = tf.shape(inputs)[0]\n","            memory_size = tf.shape(self.memory)[0]\n","            memory_sliced = tf.cond(\n","                batch_size > memory_size,\n","                lambda: tf.tile(self.memory, [(batch_size + memory_size - 1) // memory_size, 1])[:batch_size],\n","                lambda: self.memory[:batch_size]\n","            )\n","            return tf.reduce_mean(tf.stack([inputs, memory_sliced], axis=0), axis=0)\n","        def get_config(self):\n","            config = super().get_config()\n","            config.update({'memory_size': self.memory_size, 'memory_dim': self.memory_dim})\n","            return config\n","\n","    # Định nghĩa lớp GradientReversalLayer\n","    class GradientReversalLayer(tf.keras.layers.Layer):\n","        def __init__(self, lambda_=1.0, **kwargs):\n","            super().__init__(**kwargs)\n","            self.lambda_ = lambda_\n","        def call(self, inputs, training=None):\n","            inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n","            return inputs if not training else tf.math.multiply(-self.lambda_, inputs)\n","        def get_config(self):\n","            config = super().get_config()\n","            config.update({\"lambda_\": self.lambda_})\n","            return config\n","\n","    # Hàm tạo mô hình\n","    def create_model(input_dim):\n","        inputs = Input(shape=(input_dim,))\n","        x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.1), dtype=tf.float32)(inputs)\n","        x = BatchNormalization(dtype=tf.float32)(x)\n","        x = Dropout(0.6)(x)\n","        x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.1), dtype=tf.float32)(x)\n","        x = BatchNormalization(dtype=tf.float32)(x)\n","        x = Dropout(0.6)(x)\n","        x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.1), dtype=tf.float32)(x)\n","        x = BatchNormalization(dtype=tf.float32)(x)\n","        feature_output = x\n","        x = MemoryAugmentedLayer(memory_size=memory_size, memory_dim=128)(x)\n","        classification_output = Dense(5, activation='softmax', name='classification', dtype=tf.float32)(x)\n","        domain_inputs = GradientReversalLayer(lambda_=1.0)(x)\n","        domain_x = Dense(64, activation='relu', dtype=tf.float32)(domain_inputs)\n","        domain_output = Dense(2, activation='softmax', name='domain', dtype=tf.float32)(domain_x)\n","        model = Model(inputs=inputs, outputs=[classification_output, domain_output])\n","        classification_model = Model(inputs=inputs, outputs=classification_output)\n","        feature_model = Model(inputs=inputs, outputs=feature_output)\n","        memory_layer = [layer for layer in model.layers if isinstance(layer, MemoryAugmentedLayer)][0]\n","        return model, classification_model, memory_layer, feature_model\n","\n","    # Hàm tính độ chính xác\n","    def compute_accuracy(y_true, y_pred):\n","        y_pred = tf.argmax(y_pred, axis=1, output_type=tf.int32)\n","        y_true = tf.argmax(y_true, axis=1, output_type=tf.int32)\n","        return tf.reduce_mean(tf.cast(tf.equal(y_true, y_pred), tf.float32))\n","\n","    # Hàm tính prototype\n","    def compute_prototypes(features, labels, feature_model):\n","        features = feature_model(features, training=False)\n","        labels_arg = tf.argmax(labels, axis=1)\n","        prototypes = []\n","        for cls in range(5):\n","            cls_mask = tf.equal(labels_arg, cls)\n","            cls_features = tf.boolean_mask(features, cls_mask)\n","            prototype = tf.reduce_mean(cls_features, axis=0) if tf.shape(cls_features)[0] > 0 else \\\n","                        tf.zeros([features.shape[1]], dtype=tf.float32)\n","            prototypes.append(prototype)\n","        return tf.stack(prototypes)\n","\n","    # Hàm tính prototypical loss\n","    def prototypical_loss(query_features, query_labels, prototypes):\n","        query_labels_arg = tf.argmax(query_labels, axis=1)\n","        query_features_exp = tf.expand_dims(query_features, axis=1)\n","        prototypes_exp = tf.expand_dims(prototypes, axis=0)\n","        distances = tf.reduce_sum(tf.square(query_features_exp - prototypes_exp), axis=-1)\n","        logits = tf.cast(-distances, tf.float32)\n","        return tf.cast(tf.keras.losses.categorical_crossentropy(query_labels, logits, from_logits=True), tf.float32)\n","\n","    # Hàm dự đoán prototypical\n","    def prototypical_predict(query_features, prototypes):\n","        query_features_exp = tf.expand_dims(query_features, axis=1)\n","        prototypes_exp = tf.expand_dims(prototypes, axis=0)\n","        distances = tf.reduce_sum(tf.square(query_features_exp - prototypes_exp), axis=-1)\n","        return tf.cast(tf.nn.softmax(tf.cast(-distances, tf.float32)), tf.float32)\n","\n","    # Hàm áp dụng temperature scaling\n","    def apply_temperature_scaling(logits, temperature=2.0):\n","        logits = tf.convert_to_tensor(logits, dtype=tf.float32)\n","        return tf.nn.softmax(logits / temperature)\n","\n","    # Hàm Laplace smoothing\n","    def laplace_smoothing(probs, epsilon=1e-5):\n","        probs = tf.convert_to_tensor(probs, dtype=tf.float32)\n","        return (probs + epsilon) / (tf.reduce_sum(probs, axis=-1, keepdims=True) + 5 * epsilon)\n","\n","    # Hàm lưu confusion matrix\n","    def save_confusion_matrix(y_true, y_pred, episode, qwk, save_dir, prefix=''):\n","        cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3, 4])\n","        plt.figure(figsize=(8, 6))\n","        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                    xticklabels=[0, 1, 2, 3, 4], yticklabels=[0, 1, 2, 3, 4])\n","        plt.title(f'Ma trận nhầm lẫn - {prefix}QWK: {qwk:.4f} tại Episode {episode+1}')\n","        plt.xlabel('Dự đoán')\n","        plt.ylabel('Thực tế')\n","        cm_path = os.path.join(save_dir, f'confusion_matrix_{prefix}episode_{episode+1}.png')\n","        plt.savefig(cm_path)\n","        plt.close()\n","        print(f\"Đã lưu ma trận nhầm lẫn {prefix} tại: {cm_path}\")\n","        return cm\n","\n","    # Hàm giảm learning rate và early stopping\n","    def reduce_lr_and_early_stop(episode, qwk, best_qwk, patience_lr, patience_stop, lr_patience_counter, stop_patience_counter,\n","                                 inner_lr, outer_lr, fine_tune_lr, min_lr=1e-7, reduce_factor=0.5):\n","        stop_training = False\n","        if qwk > best_qwk:\n","            lr_patience_counter = 0\n","            stop_patience_counter = 0\n","        else:\n","            lr_patience_counter += 1\n","            stop_patience_counter += 1\n","        if lr_patience_counter >= patience_lr:\n","            inner_lr = max(inner_lr * reduce_factor, min_lr)\n","            outer_lr = max(outer_lr * reduce_factor, min_lr)\n","            fine_tune_lr = max(fine_tune_lr * reduce_factor, min_lr)\n","            lr_patience_counter = 0\n","            print(f\"Episode {episode+1}: Giảm learning rate - inner_lr={inner_lr:.6f}, outer_lr={outer_lr:.6f}, fine_tune_lr={fine_tune_lr:.6f}\")\n","        if stop_patience_counter >= patience_stop:\n","            stop_training = True\n","            print(f\"Episode {episode+1}: Early stopping do QWK không cải thiện sau {patience_stop} episode\")\n","        return inner_lr, outer_lr, fine_tune_lr, lr_patience_counter, stop_patience_counter, stop_training\n","\n","    # Khởi tạo mô hình và optimizer\n","    meta_model, meta_classification_model, memory_layer, feature_model = create_model(input_dim)\n","    meta_optimizer = tf.keras.optimizers.Adam(learning_rate=outer_lr)\n","    fine_tune_optimizer = tf.keras.optimizers.Adam(learning_rate=fine_tune_lr)\n","    loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n","    domain_loss_fn = tf.keras.losses.CategoricalCrossentropy()\n","\n","    # Khởi tạo các biến theo dõi\n","    best_qwk = -float('inf')\n","    lr_patience_counter = 0\n","    stop_patience_counter = 0\n","    patience_lr = 10\n","    patience_stop = 50\n","    min_lr = 1e-7\n","    reduce_factor = 0.5\n","    weights_filepath = os.path.join(feature_save_dir, \"meta_model_maml_fomaml_best_weights.weights.h5\")\n","    history = {\n","        'qwk': [], 'loss': [], 'support_loss': [], 'support_accuracy': [], 'query_loss': [], 'query_accuracy': [],\n","        'precision': [], 'recall': [], 'support_qwk': [], 'support_precision': [], 'support_recall': [],\n","        'support_f1': [], 'support_cm': []\n","    }\n","    class_weights = np.ones(5, dtype=np.float32)\n","    class_weights[3] = 10 / (10 * 2)\n","    source_domain_labels = tf.keras.utils.to_categorical(tf.zeros(len(features), dtype=tf.int32), num_classes=2)\n","    source_domain_labels = tf.cast(source_domain_labels, tf.float32)\n","    target_domain_labels = tf.keras.utils.to_categorical(tf.ones(len(valid_features), dtype=tf.int32), num_classes=2)\n","    target_domain_labels = tf.cast(target_domain_labels, tf.float32)\n","\n","    # Lưu đặc trưng meta-learner nếu có sample_ids\n","    if sample_ids is not None:\n","        print(\"Lưu đặc trưng 2D của meta-learner...\")\n","        meta_features_2d = feature_model.predict(valid_features, batch_size=32, verbose=0)\n","        meta_features_2d_path = os.path.join(feature_save_dir, \"meta_learner_features_2d.npy\")\n","        np.save(meta_features_2d_path, meta_features_2d)\n","        print(f\"Đã lưu đặc trưng 2D của meta-learner tại: {meta_features_2d_path}, shape={meta_features_2d.shape}\")\n","        metadata = {\n","            \"model_name\": \"meta_learner\",\n","            \"features_2d_path\": meta_features_2d_path,\n","            \"sample_ids\": sample_ids.tolist(),\n","            \"labels\": valid_labels.tolist(),\n","            \"timestamp\": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n","        }\n","        metadata_path = os.path.join(feature_save_dir, \"meta_learner_features_metadata.json\")\n","        with open(metadata_path, 'w') as f:\n","            json.dump(metadata, f, indent=4)\n","        print(f\"Đã lưu metadata meta-learner tại: {metadata_path}\")\n","\n","    # Vòng lặp huấn luyện\n","    for episode in range(n_episodes):\n","        # Tạo episode\n","        support_features, support_labels, query_features, query_labels, hard_indices = create_episode(\n","            features, labels, n_support, n_query, hard_sample_ratio=0.3, class_3_multiplier=2)\n","        if support_features.size == 0 or query_features.size == 0:\n","            logging.warning(f\"Episode {episode+1}: Không đủ mẫu\")\n","            history['qwk'].append(0.0)\n","            history['support_loss'].append(0.0)\n","            history['support_accuracy'].append(0.0)\n","            history['query_loss'].append(0.0)\n","            history['query_accuracy'].append(0.0)\n","            history['precision'].append(0.0)\n","            history['recall'].append(0.0)\n","            history['support_qwk'].append(0.0)\n","            history['support_precision'].append(0.0)\n","            history['support_recall'].append(0.0)\n","            history['support_f1'].append(0.0)\n","            history['support_cm'].append(np.zeros((5, 5)).tolist())\n","            continue\n","\n","        # Khởi tạo task model\n","        task_model, task_classification_model, task_memory_layer, task_feature_model = create_model(input_dim)\n","        task_model.set_weights(meta_model.get_weights())\n","        task_optimizer = tf.keras.optimizers.Adam(learning_rate=inner_lr)\n","        class_weight_dict = {i: float(w) for i, w in enumerate(class_weights)}\n","        print(f\"Episode {episode+1} - Trọng số lớp: {class_weight_dict}\")\n","        support_prototypes = compute_prototypes(support_features, support_labels, task_feature_model)\n","\n","        # Inner loop training\n","        for _ in range(10):\n","            with tf.GradientTape() as tape:\n","                class_preds, domain_preds = task_model(support_features, training=True)\n","                min_size = min(class_preds.shape[0], support_labels.shape[0])\n","                if not min_size:\n","                    break\n","                class_preds = class_preds[:min_size]\n","                support_labels_adj = support_labels[:min_size]\n","                min_size_domain = min(domain_preds.shape[0], source_domain_labels.shape[0])\n","                domain_preds = domain_preds[:min_size_domain]\n","                source_domain_labels_slice = source_domain_labels[:min_size_domain]\n","                class_loss = tf.cast(loss_fn(support_labels_adj, class_preds, sample_weight=[\n","                    class_weight_dict.get(np.argmax(label), 1.0) for label in support_labels_adj]), tf.float32)\n","                domain_loss = tf.cast(domain_loss_fn(source_domain_labels_slice, domain_preds), tf.float32)\n","                support_features_task = task_feature_model(support_features, training=False)\n","                proto_loss = prototypical_loss(support_features_task, support_labels_adj, support_prototypes)\n","                total_loss = class_loss + 0.5 * domain_loss + 0.5 * proto_loss\n","            task_grads = tape.gradient(total_loss, task_model.trainable_variables)\n","            valid_grads = [(g, v) for g, v in zip(task_grads, task_model.trainable_variables) if g is not None]\n","            task_optimizer.apply_gradients(valid_grads)\n","            task_keys = task_feature_model(support_features, training=False)\n","            if task_keys.shape[1] != 128:\n","                task_keys = Dense(128, use_bias=False, dtype=tf.float32)(task_keys)\n","            task_keys = tf.concat([task_keys, tf.zeros([memory_size - task_keys.shape[0], task_keys.shape[1]], dtype=tf.float32)], axis=0) if task_keys.shape[0] < memory_size else task_keys[:memory_size]\n","            task_memory_layer.memory.assign(task_keys)\n","            del task_grads, valid_grads\n","            gc.collect()\n","\n","        # Đánh giá trên support set\n","        support_preds = task_model(support_features, training=False)[0]\n","        support_loss_value = float(class_loss.numpy())\n","        support_accuracy = float(compute_accuracy(support_labels_adj, support_preds).numpy())\n","        support_preds_classes = np.argmax(support_preds.numpy(), axis=1)\n","        support_true_classes = np.argmax(support_labels_adj, axis=1)\n","        support_qwk = cohen_kappa_score(support_true_classes, support_preds_classes,\n","                                        labels=[0, 1, 2, 3, 4], weights='quadratic')\n","        support_precision = precision_score(support_true_classes, support_preds_classes,\n","                                           average='weighted', zero_division=0)\n","        support_recall = recall_score(support_true_classes, support_preds_classes,\n","                                     average='weighted', zero_division=0)\n","        support_f1 = f1_score(support_true_classes, support_preds_classes,\n","                             average='weighted', zero_division=0)\n","        support_cm = confusion_matrix(support_true_classes, support_preds_classes,\n","                                     labels=[0, 1, 2, 3, 4])\n","        history['support_qwk'].append(float(support_qwk))\n","        history['support_precision'].append(float(support_precision))\n","        history['support_recall'].append(float(support_recall))\n","        history['support_f1'].append(float(support_f1))\n","        history['support_cm'].append(support_cm.tolist())\n","        support_cm = save_confusion_matrix(support_true_classes, support_preds_classes, episode,\n","                                          support_qwk, feature_save_dir, prefix='support_')\n","\n","        # Đánh giá trên query set\n","        with tf.GradientTape() as outer_tape:\n","            query_preds, domain_preds = task_model(query_features, training=True)\n","            min_size = min(query_preds.shape[0], query_labels.shape[0])\n","            if not min_size:\n","                logging.warning(f\"Episode {episode+1}: Không có dữ liệu query hợp lệ\")\n","                history['qwk'].append(0.0)\n","                history['support_loss'].append(support_loss_value)\n","                history['support_accuracy'].append(support_accuracy)\n","                history['query_loss'].append(0.0)\n","                history['query_accuracy'].append(0.0)\n","                history['precision'].append(0.0)\n","                history['recall'].append(0.0)\n","                continue\n","            query_preds = query_preds[:min_size]\n","            query_labels_adj = query_labels[:min_size]\n","            min_size_domain = min(domain_preds.shape[0], source_domain_labels.shape[0])\n","            domain_preds = domain_preds[:min_size_domain]\n","            source_domain_labels_slice = source_domain_labels[:min_size_domain]\n","            query_loss = tf.cast(loss_fn(query_labels_adj, query_preds, sample_weight=[\n","                class_weight_dict.get(np.argmax(label), 1.0) for label in query_labels_adj]), tf.float32)\n","            domain_loss = tf.cast(domain_loss_fn(source_domain_labels_slice, domain_preds), tf.float32)\n","            query_features_task = task_feature_model(query_features, training=False)\n","            proto_loss = prototypical_loss(query_features_task, query_labels_adj, support_prototypes)\n","            total_query_loss = query_loss + 0.5 * domain_loss + 0.5 * proto_loss\n","            query_accuracy = float(compute_accuracy(query_labels_adj, query_preds).numpy())\n","            query_loss_value = float(query_loss.numpy())\n","\n","        # Cập nhật meta-model\n","        meta_grads = outer_tape.gradient(total_query_loss, task_model.trainable_variables)\n","        valid_grads = [(g, v) for g, v in zip(meta_grads, meta_model.trainable_variables) if g is not None]\n","        meta_optimizer.apply_gradients(valid_grads)\n","        memory_keys = feature_model(support_features, training=False)\n","        if memory_keys.shape[1] != 128:\n","            memory_keys = Dense(128, use_bias=False, dtype=tf.float32)(memory_keys)\n","        memory_keys = tf.concat([memory_keys, tf.zeros([memory_size - memory_keys.shape[0], memory_keys.shape[1]], dtype=tf.float32)], axis=0) if memory_keys.shape[0] < memory_size else memory_keys[:memory_size]\n","        memory_layer.memory.assign(memory_keys)\n","        del meta_grads, valid_grads\n","        gc.collect()\n","\n","        # Fine-tuning trên query set\n","        for _ in range(5):\n","            with tf.GradientTape() as fine_tune_tape:\n","                fine_tune_preds = meta_classification_model(query_features, training=True)\n","                min_size = min(fine_tune_preds.shape[0], query_labels.shape[0])\n","                if not min_size:\n","                    continue\n","                fine_tune_preds = fine_tune_preds[:min_size]\n","                query_labels_adj = query_labels[:min_size]\n","                fine_tune_loss = tf.cast(loss_fn(query_labels_adj, fine_tune_preds, sample_weight=[\n","                    class_weight_dict.get(np.argmax(label), 1.0) for label in query_labels_adj]), tf.float32)\n","            fine_tune_grads = fine_tune_tape.gradient(fine_tune_loss, meta_classification_model.trainable_variables)\n","            valid_grads = [(g, v) for g, v in zip(fine_tune_grads, meta_classification_model.trainable_variables) if g is not None]\n","            fine_tune_optimizer.apply_gradients(valid_grads)\n","            del fine_tune_grads, valid_grads\n","            gc.collect()\n","\n","        # Đánh giá trên valid set\n","        valid_preds_maml = tf.cast(meta_classification_model(valid_features, training=False), tf.float32)\n","        min_size = min(valid_preds_maml.shape[0], valid_labels.shape[0])\n","        if not min_size:\n","            logging.warning(f\"Episode {episode+1}: Không có dữ liệu valid hợp lệ\")\n","            history['qwk'].append(0.0)\n","            history['support_loss'].append(support_loss_value)\n","            history['support_accuracy'].append(support_accuracy)\n","            history['query_loss'].append(query_loss_value)\n","            history['query_accuracy'].append(query_accuracy)\n","            history['precision'].append(0.0)\n","            history['recall'].append(0.0)\n","            continue\n","        valid_preds_maml = valid_preds_maml[:min_size]\n","        valid_labels_adj = valid_labels[:min_size]\n","        valid_features_task = task_feature_model(valid_features, training=False)\n","        valid_prototypes = compute_prototypes(features, labels, task_feature_model)\n","        valid_preds_proto = tf.cast(prototypical_predict(valid_features_task, valid_prototypes), tf.float32)\n","        valid_preds_ensemble = (0.5 * valid_preds_maml + 0.5 * valid_preds_proto)\n","        valid_preds_scaled = tf.cast(apply_temperature_scaling(valid_preds_ensemble, temperature=2.0), tf.float32)\n","        valid_preds_scaled = laplace_smoothing(valid_preds_scaled, epsilon=1e-5)\n","        valid_preds_classes = np.argmax(valid_preds_scaled.numpy(), axis=1)\n","        qwk = cohen_kappa_score(np.argmax(valid_labels_adj, axis=1), valid_preds_classes,\n","                                labels=[0, 1, 2, 3, 4], weights='quadratic')\n","        precision = precision_score(np.argmax(valid_labels_adj, axis=1), valid_preds_classes,\n","                                   average='weighted', zero_division=0)\n","        recall = recall_score(np.argmax(valid_labels_adj, axis=1), valid_preds_classes,\n","                             average='weighted', zero_division=0)\n","        history['qwk'].append(float(qwk))\n","        history['precision'].append(float(precision))\n","        history['recall'].append(float(recall))\n","        history['support_loss'].append(float(support_loss_value))\n","        history['support_accuracy'].append(float(support_accuracy))\n","        history['query_loss'].append(float(query_loss_value))\n","        history['query_accuracy'].append(float(query_accuracy))\n","\n","        # Giảm learning rate và early stopping\n","        inner_lr, outer_lr, fine_tune_lr, lr_patience_counter, stop_patience_counter, stop_training = \\\n","            reduce_lr_and_early_stop(\n","                episode, qwk, best_qwk, patience_lr, patience_stop, lr_patience_counter, stop_patience_counter,\n","                inner_lr, outer_lr, fine_tune_lr, min_lr, reduce_factor\n","            )\n","        meta_optimizer.learning_rate.assign(outer_lr)\n","        fine_tune_optimizer.learning_rate.assign(fine_tune_lr)\n","\n","        # Log vào TensorBoard\n","        with tf.summary.create_file_writer(log_dir).as_default():\n","            tf.summary.scalar('support_loss', support_loss_value, step=episode)\n","            tf.summary.scalar('support_accuracy', support_accuracy, step=episode)\n","            tf.summary.scalar('support_qwk', support_qwk, step=episode)\n","            tf.summary.scalar('support_precision', support_precision, step=episode)\n","            tf.summary.scalar('support_recall', support_recall, step=episode)\n","            tf.summary.scalar('support_f1', support_f1, step=episode)\n","            tf.summary.scalar('query_loss', query_loss_value, step=episode)\n","            tf.summary.scalar('query_accuracy', query_accuracy, step=episode)\n","            tf.summary.scalar('qwk', qwk, step=episode)\n","            tf.summary.scalar('precision', precision, step=episode)\n","            tf.summary.scalar('recall', recall, step=episode)\n","            tf.summary.scalar('inner_lr', inner_lr, step=episode)\n","            tf.summary.scalar('outer_lr', outer_lr, step=episode)\n","            tf.summary.scalar('fine_tune_lr', fine_tune_lr, step=episode)\n","\n","        # In kết quả\n","        print(f\"Episode {episode+1}/{n_episodes}:\")\n","        print(f\"  Support Loss: {support_loss_value:.4f}, Accuracy: {support_accuracy:.4f}\")\n","        print(f\"  Support QWK: {support_qwk:.4f}, F1: {support_f1:.4f}, Precision: {support_precision:.4f}, Recall: {support_recall:.4f}\")\n","        print(f\"  Support Confusion Matrix:\\n{support_cm}\")\n","        print(f\"  Query Loss: {query_loss_value:.4f}, Accuracy: {query_accuracy:.4f}\")\n","        print(f\"  Valid QWK (Ensemble): {qwk:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n","        print(f\"  Inner LR: {inner_lr:.6f}, Outer LR: {outer_lr:.6f}, Fine-tune LR: {fine_tune_lr:.6f}\")\n","\n","        # Lưu trọng số nếu QWK tốt hơn\n","        if qwk > best_qwk:\n","            best_qwk = qwk\n","            try:\n","                meta_model.save_weights(weights_filepath, overwrite=True)\n","                print(f\"Đã lưu trọng số tốt nhất tại episode {episode+1} với QWK: {best_qwk:.4f}\")\n","                cm = save_confusion_matrix(\n","                    np.argmax(valid_labels_adj, axis=1), valid_preds_classes, episode,\n","                    best_qwk, feature_save_dir, prefix='best_'\n","                )\n","                print(f\"Ma trận nhầm lẫn cho QWK tốt nhất tại Episode {episode+1}:\\n{cm}\")\n","            except Exception as e:\n","                logging.error(f\"Lỗi khi lưu trọng số: {str(e)}. Thử lưu .h5\")\n","                alt_weights_filepath = os.path.join(feature_save_dir, \"meta_model_maml_fomaml_best_weights.h5\")\n","                meta_model.save_weights(alt_weights_filepath, overwrite=True)\n","                print(f\"Đã lưu trọng số (dạng thay thế) tại: {alt_weights_filepath}\")\n","\n","        if stop_training:\n","            print(f\"Early stopping kích hoạt tại episode {episode+1}\")\n","            break\n","        gc.collect()\n","\n","    # Fine-tuning trên tập valid\n","    print(\"Fine-tuning trên tập valid...\")\n","    meta_classification_model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_lr),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n","    )\n","    meta_classification_model.fit(\n","        valid_features, valid_labels,\n","        validation_data=(valid_features, valid_labels),\n","        epochs=100,\n","        batch_size=32,\n","        verbose=1,\n","        callbacks=[\n","            tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n","            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3),\n","            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","        ]\n","    )\n","\n","    # Đánh giá cuối cùng trên valid set\n","    valid_preds = meta_classification_model.predict(valid_features, batch_size=32)\n","    valid_preds = apply_temperature_scaling(valid_preds, temperature=2.0)\n","    valid_preds = laplace_smoothing(valid_preds, epsilon=1e-5)\n","    valid_preds_classes = np.argmax(valid_preds, axis=1)\n","    valid_true_classes = np.argmax(valid_labels, axis=1)\n","    qwk_final = cohen_kappa_score(valid_true_classes, valid_preds_classes,\n","                                  labels=[0, 1, 2, 3, 4], weights='quadratic')\n","    f1_final = f1_score(valid_true_classes, valid_preds_classes, average='weighted')\n","    recall_final = recall_score(valid_true_classes, valid_preds_classes, average='weighted')\n","    precision_final = precision_score(valid_true_classes, valid_preds_classes, average='weighted')\n","    print(f\"Kết quả cuối cùng trên tập valid:\")\n","    print(f\"  Quadratic Weighted Kappa (QWK): {qwk_final:.4f}\")\n","    print(f\"  Weighted F1 Score: {f1_final:.4f}\")\n","    print(f\"  Weighted Recall: {recall_final:.4f}\")\n","    print(f\"  Weighted Precision: {precision_final:.4f}\")\n","    cm_final = save_confusion_matrix(\n","        valid_true_classes, valid_preds_classes, n_episodes, qwk_final, feature_save_dir, prefix='final_'\n","    )\n","    print(f\"Ma trận nhầm lẫn cuối cùng:\\n{cm_final}\")\n","\n","    # Lưu trữ số\n","    final_weights_filepath = os.path.join(feature_save_dir, \"model.weights.h5\")\n","    final_config_filepath = os.path.join(feature_save_dir, \"config.json\")\n","    final_metadata_filepath = os.path.join(feature_save_dir, \"metadata.json\")\n","    try:\n","        meta_model.save_weights(final_weights_filepath, overwrite=True)\n","        print(f\"Đã lưu trọng số meta-model tại: {final_weights_filepath}\")\n","    except Exception as e:\n","        logging.error(\"fLỗi khi lưu trọng số meta-model: {str(e)}\")\n","        alt_final_weights_filepath = os.path.join(feature_save_dir, \"f{model_weights_alt.h5}\")\n","        meta_model.save_weights(alt_final_weights_filepath, overwrite=True)\n","        print(f\"Đã lưu trọng số (dạng thay thế) tại: {alt_final_weights_filepath}\")\n","\n","    try:\n","        model_config = meta_model.to_json()\n","        with open(final_config_filepath, 'w') as f:\n","            json.dump(json.loads(model_config), f, indent=2)\n","        print(f\"Đã lưu cấu hình meta-model tại: {final_config_filepath}\")\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi lưu config meta-model: {str(e)}\")\n","\n","    metadata = {\n","        \"model_type\": \"meta_model_maml_fomaml\",\n","        \"num_classes\": 5,\n","        \"input_dim\": input_dim,\n","        \"training_episodes\": n_episodes,\n","        \"timestamp\": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n","    }\n","    try:\n","        with open(final_metadata_filepath, 'w') as f:\n","            json.dump(metadata, f, indent=4)\n","        print(f\"Đã lưu siêu dữ liệu meta-model tại: {final_metadata_filepath}\")\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi lưu metadata: {str(e)}\")\n","\n","    metrics_history = {\n","        'qwk': float(qwk_final),\n","        'f1_score': float(f1_final),\n","        'recall': float(recall_final),\n","        'precision': float(precision_final),\n","        'training_history': {\n","            'qwk': [float(q) for q in history['qwk']],\n","            'support_loss': [float(l) for l in history['support_loss']],\n","            'support_accuracy': [float(a) for a in history['support_accuracy']],\n","            'query_loss': [float(l) for l in history['query_loss']],\n","            'query_accuracy': [float(a) for a in history['query_accuracy']],\n","            'precision': [float(p) for p in history['precision']],\n","            'recall': [float(r) for r in history['recall']],\n","            'support_qwk': [float(q) for q in history['support_qwk']],\n","            'support_precision': [float(p) for p in history['support_precision']],\n","            'support_recall': [float(r) for r in history['support_recall']],\n","            'support_f1': [float(f) for f in history['support_f1']],\n","            'support_cm': history['support_cm']\n","        }\n","    }\n","\n","    metrics_filepath = os.path.join(feature_save_dir, 'final_metrics.json')\n","    try:\n","        with open(metrics_filepath, 'w') as f:\n","            json.dump(metrics_history, f, indent=4)\n","        print(f\"Đã lưu các chỉ số đánh giá tại: {metrics_filepath}\")\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi lưu metrics: {str(e)}\")\n","\n","    # Vẽ biểu đồ lịch sử huấn luyện\n","    plt.figure(figsize=(15, 10))\n","    plt.subplot(2, 3, 1)\n","    plt.plot(history['qwk'], label='Valid QWK')\n","    plt.title('QWK theo Episode')\n","    plt.xlabel('Episode')\n","    plt.ylabel('QWK')\n","    plt.legend()\n","    plt.subplot(2, 3, 2)\n","    plt.plot(history['support_loss'], label='Support Loss')\n","    plt.plot(history['query_loss'], label='Query Loss')\n","    plt.title('Loss theo Episode')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.subplot(2, 3, 3)\n","    plt.plot(history['support_accuracy'], label='Support Accuracy')\n","    plt.plot(history['query_accuracy'], label='Query Accuracy')\n","    plt.title('Accuracy theo Episode')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.subplot(2, 3, 4)\n","    plt.plot(history['support_qwk'], label='Support QWK')\n","    plt.title('Support QWK theo Episode')\n","    plt.xlabel('Episode')\n","    plt.ylabel('QWK')\n","    plt.legend()\n","    plt.subplot(2, 3, 5)\n","    plt.plot(history['support_precision'], label='Support Precision')\n","    plt.plot(history['support_recall'], label='Support Recall')\n","    plt.plot(history['support_f1'], label='Support F1')\n","    plt.title('Support Metrics theo Episode')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Score')\n","    plt.legend()\n","    plt.tight_layout()\n","    history_path = os.path.join(feature_save_dir, 'training_history.png')\n","    plt.savefig(history_path)\n","    plt.close()\n","    print(f\"Đã lưu biểu đồ lịch sử huấn luyện tại: {history_path}\")\n","\n","    return meta_model, meta_classification_model, history\n","\n","def evaluate_test_set(meta_classification_model, test_features, test_labels, save_dir):\n","    test_preds = meta_classification_model.predict(test_features, batch_size=32)\n","    test_preds = apply_temperature_scaling(test_preds, temperature=2.0)\n","    test_preds = laplace_smoothing(test_preds, epsilon=1e-5)\n","    test_probs = np.max(test_preds.numpy(), axis=1)\n","    test_probs = np.clip(test_probs, 0.0, 1.0)\n","    test_preds_classes = np.argmax(test_preds, axis=1)\n","    test_true_classes = np.argmax(test_labels, axis=1)\n","    qwk_test = cohen_kappa_score(test_true_classes, test_preds_classes, labels=[0, 1, 2, 3, 4], weights='quadratic')\n","    f1_test = f1_score(test_true_classes, test_preds_classes, average='weighted')\n","    precision_test = precision_score(test_true_classes, test_preds_classes, average='weighted')\n","    recall_test = recall_score(test_true_classes, test_preds_classes, average='weighted')\n","    accuracy_test = accuracy_score(test_true_classes, test_preds_classes)\n","    print(f\"Kết quả trên tập test:\")\n","    print(f\"  Quadratic Weighted Kappa (QWK): {qwk_test:.4f}\")\n","    print(f\"  Weighted F1 Score: {f1_test:.4f}\")\n","    print(f\"  Weighted Precision: {precision_test:.4f}\")\n","    print(f\"  Weighted Recall: {recall_test:.4f}\")\n","    print(f\"  Accuracy: {accuracy_test:.4f}\")\n","    cm_test = confusion_matrix(test_true_classes, test_preds_classes, labels=[0, 1, 2, 3, 4])\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=[0, 1, 2, 3, 4], yticklabels=[0, 1, 2, 3, 4])\n","    plt.title(f'Ma trận nhầm lẫn - Test Set, QWK: {qwk_test:.4f}')\n","    plt.xlabel('Dự đoán')\n","    plt.ylabel('Thực tế')\n","    cm_path = os.path.join(save_dir, 'confusion_matrix_test.png')\n","    plt.savefig(cm_path)\n","    plt.close()\n","    print(f\"Đã lưu ma trận nhầm lẫn tập test tại: {cm_path}\")\n","    print(f\"Ma trận nhầm lẫn tập test:\\n{cm_test}\")\n","    test_metrics = {\n","        'qwk': float(qwk_test),\n","        'f1_score': float(f1_test),\n","        'precision': float(precision_test),\n","        'recall': float(recall_test),\n","        'accuracy': float(accuracy_test),\n","        'confusion_matrix': cm_test.tolist()\n","    }\n","    metrics_filepath = os.path.join(save_dir, 'test_metrics.json')\n","    try:\n","        with open(metrics_filepath, 'w') as f:\n","            json.dump(test_metrics, f, indent=4)\n","        print(f\"Đã lưu các chỉ số đánh giá tập test tại: {metrics_filepath}\")\n","    except Exception as e:\n","        logging.error(f\"Lỗi khi lưu test metrics: {str(e)}\")\n","    return test_metrics\n","\n","def apply_temperature_scaling(logits, temperature=2.0):\n","    logits = tf.convert_to_tensor(logits, dtype=tf.float32)\n","    return tf.nn.softmax(logits / temperature)\n","\n","def laplace_smoothing(probs, epsilon=1e-5):\n","    probs = tf.convert_to_tensor(probs, dtype=tf.float32)\n","    return (probs + epsilon) / (tf.reduce_sum(probs, axis=-1, keepdims=True) + NUM_CLASSES * epsilon)\n","\n","def save_confusion_matrix(y_true, y_pred, episode, qwk, save_dir, prefix=''):\n","    cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3, 4])\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=[0, 1, 2, 3, 4], yticklabels=[0, 1, 2, 3, 4])\n","    plt.title(f'Ma trận nhầm lẫn - {prefix}QWK: {qwk:.4f} tại Episode {episode+1}')\n","    plt.xlabel('Dự đoán')\n","    plt.ylabel('Thực tế')\n","    cm_path = os.path.join(save_dir, f'confusion_matrix_{prefix}qwk_episode_{episode+1}.png')\n","    plt.savefig(cm_path)\n","    plt.close()\n","    print(f\"Đã lưu ma trận nhầm lẫn {prefix}QWK tại: {cm_path}\")\n","    return cm\n","\n","def compute_prototypes(features, labels, feature_model):\n","    features = feature_model(features, training=False)\n","    labels_arg = tf.argmax(labels, axis=1)\n","    prototypes = []\n","    for cls in range(NUM_CLASSES):\n","        cls_mask = tf.equal(labels_arg, cls)\n","        cls_features = tf.boolean_mask(features, cls_mask)\n","        prototype = tf.reduce_mean(cls_features, axis=0) if tf.shape(cls_features)[0] > 0 else \\\n","                    tf.zeros([features.shape[1]], dtype=tf.float32)\n","        prototypes.append(prototype)\n","    return tf.stack(prototypes)\n","\n","def prototypical_loss(query_features, query_labels, prototypes):\n","    query_labels_arg = tf.argmax(query_labels, axis=1)\n","    query_features_exp = tf.expand_dims(query_features, axis=1)\n","    prototypes_exp = tf.expand_dims(prototypes, axis=0)\n","    distances = tf.reduce_sum(tf.square(query_features_exp - prototypes_exp), axis=-1)\n","    logits = tf.cast(-distances, tf.float32)\n","    return tf.cast(tf.keras.losses.categorical_crossentropy(query_labels, logits, from_logits=True), tf.float32)\n","\n","def prototypical_predict(query_features, prototypes):\n","    query_features_exp = tf.expand_dims(query_features, axis=1)\n","    prototypes_exp = tf.expand_dims(prototypes, axis=0)\n","    distances = tf.reduce_sum(tf.square(query_features_exp - prototypes_exp), axis=-1)\n","    return tf.cast(tf.nn.softmax(tf.cast(-distances, tf.float32)), tf.float32)\n","\n","def reduce_lr_and_early_stop(episode, qwk, best_qwk, patience_lr, patience_stop, lr_patience_counter, stop_patience_counter,\n","                             inner_lr, outer_lr, fine_tune_lr, min_lr=1e-7, reduce_factor=0.5):\n","    stop_training = False\n","    if qwk > best_qwk:\n","        lr_patience_counter = 0\n","        stop_patience_counter = 0\n","    else:\n","        lr_patience_counter += 1\n","        stop_patience_counter += 1\n","    if lr_patience_counter >= patience_lr:\n","        inner_lr = max(inner_lr * reduce_factor, min_lr)\n","        outer_lr = max(outer_lr * reduce_factor, min_lr)\n","        fine_tune_lr = max(fine_tune_lr * reduce_factor, min_lr)\n","        lr_patience_counter = 0\n","        print(f\"Episode {episode+1}: Giảm learning rate - inner_lr={inner_lr:.6f}, outer_lr={outer_lr:.6f}, fine_tune_lr={fine_tune_lr:.6f}\")\n","    if stop_patience_counter >= patience_stop:\n","        stop_training = True\n","        print(f\"Episode {episode+1}: Early stopping do QWK không cải thiện sau {patience_stop} episode\")\n","    return inner_lr, outer_lr, fine_tune_lr, lr_patience_counter, stop_patience_counter, stop_training\n","\n","# Trích xuất và lưu đặc trưng\n","train_features_dict = {}\n","valid_features_dict = {}\n","test_features_dict = {}\n","for model_name, config in model_configs.items():\n","    print(f\"Xử lý mô hình: {model_name}\")\n","    base_model = load_model_from_config(\n","        config['config_path'], config['weights_path'], config['base_model']\n","    )\n","    feature_layer = base_model.layers[-2].output if len(base_model.layers) > 1 else base_model.output\n","    feature_extractor = Model(inputs=base_model.input, outputs=feature_layer)\n","    feature_extractor.trainable = False\n","    train_generator = My_Generator(\n","        balanced_train_x, balanced_train_y_multi, batch_size=32, is_train=True,\n","        mix=True, augment=True, size1=SIZE, size2=config['img_size'],\n","        model_type=config['model_type'], preprocess=config['preprocess']\n","    )\n","    valid_generator = My_Generator(\n","        resized_valid_x, valid_y_multi, batch_size=32, is_train=False,\n","        mix=False, augment=False, size1=SIZE, size2=config['img_size'],\n","        model_type=config['model_type'], preprocess=config['preprocess']\n","    )\n","    test_generator = My_Generator(\n","        resized_test_x, test_y_multi, batch_size=32, is_train=False,\n","        mix=False, augment=False, size1=SIZE, size2=config['img_size'],\n","        model_type=config['model_type'], preprocess=config['preprocess']\n","    )\n","    train_features_2d = extract_and_save_features(\n","        model_name, feature_extractor, train_generator, feature_save_dir, sample_ids=train_x.values\n","    )\n","    valid_features_2d = extract_and_save_features(\n","        model_name, feature_extractor, valid_generator, feature_save_dir, sample_ids=valid_x.values\n","    )\n","    test_features_2d = extract_and_save_features(\n","        model_name, feature_extractor, test_generator, feature_save_dir, sample_ids=test_x.values\n","    )\n","    train_features_dict[model_name] = train_features_2d\n","    valid_features_dict[model_name] = valid_features_2d\n","    test_features_dict[model_name] = test_features_2d\n","    del base_model, feature_extractor\n","    tf.keras.backend.clear_session()\n","    gc.collect()\n","\n","# Kết hợp và giảm chiều đặc trưng\n","train_combined_features, train_pca, train_valid_indices, input_dim = combine_and_reduce_features(\n","    train_features_dict, balanced_train_y_multi, train_x.values, feature_save_dir, n_components=50\n",")\n","valid_combined_features, _, valid_valid_indices, _ = combine_and_reduce_features(\n","    valid_features_dict, valid_y_multi, valid_x.values, feature_save_dir, n_components=50\n",")\n","test_combined_features, _, test_valid_indices, _ = combine_and_reduce_features(\n","    test_features_dict, test_y_multi, test_x.values, feature_save_dir, n_components=50\n",")\n","train_y_multi = balanced_train_y_multi[train_valid_indices]\n","valid_y_multi = valid_y_multi[valid_valid_indices]\n","test_y_multi = test_y_multi[test_valid_indices]\n","\n","# Huấn luyện meta-model\n","print(\"Huấn luyện meta-model với MAML/FO-MAML...\")\n","meta_model, meta_classification_model, history = maml_fomaml_train_manual(\n","    train_combined_features, train_y_multi, valid_combined_features, valid_y_multi,\n","    input_dim=input_dim, n_episodes=20, n_support=10, n_query=10, inner_lr=0.001,\n","    outer_lr=0.001, fine_tune_lr=0.0001, use_fomaml=True, memory_size=20,\n","    sample_ids=valid_x.values[valid_valid_indices]\n",")\n","\n","# Đánh giá trên tập test\n","print(\"Đánh giá trên tập test...\")\n","test_metrics = evaluate_test_set(\n","    meta_classification_model, test_combined_features, test_y_multi, feature_save_dir\n",")\n","\n","print(\"Hoàn thành quy trình huấn luyện và đánh giá!\")"]},{"cell_type":"code","source":["print(processed_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dhgrsaOPtjR5","executionInfo":{"status":"ok","timestamp":1749053514219,"user_tz":-420,"elapsed":224,"user":{"displayName":"Resconnect","userId":"00882996269091038835"}},"outputId":"504cd840-06b8-4623-fc84-0ccdd1ff5696"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['cb2f3c5d71a7.png', '5c6194562ed2.png', 'e893e86dde94.png', '58059e73d2d4.png', '8ee50c26fc13.png', '6cee2e148520.png', 'd035c2bd9104.png', '22098b1fe461.png', '0a1076183736.png', 'b576c5269ad1.png', 'f4d3777f2710.png', 'd881c04f01fe.png', '14c3b41d289c.png', 'cb68fce07789.png', 'fcc55ae641ae.png', '64c6c6ee0d98.png', '4cae247d9909.png', '6b7cf869622a.png', 'e7291472109b.png', '90bde2ff8953.png', 'c0a117de7d0a.png', '7c2e852171c0.png', '42af7282349b.png', '674057ab250c.png', '8688f3d0fcaf.png', 'd6f6bdfd8011.png', '7adfb8fc0621.png', 'cc3d2e961768.png', '8958a4d17b7e.png', '26999ebc21de.png', '07a1c7073982.png', 'a8dea22ef903.png', '41345cec5957.png', '35beb47fe159.png', '79ade634c633.png', '7e4019ac7f5a.png', '79d44db3da2d.png', 'a4d41c495666.png', '415d5c5e785f.png', '6c6505a0c637.png', '0fb1053285cf.png', '838b3e4d0bb4.png', '13d411c85ffd.png', '8e76054f0831.png', '32d7d360d891.png', '6f460f9968c7.png', 'd801c0a66738.png', '38e0e28d35d3.png', '51269b77d312.png', '2927665214e1.png', 'd1b279cc02ae.png', '9b7b6e4db1d5.png', '7a46cfa69bae.png', 'f7defe70afc3.png', 'd911dd40c63b.png', '8bdb891661a8.png', 'dc3c0d8ee20b.png', '54f57cf26126.png', 'f3b27ac2d371.png', 'e540d2e35d15.png', 'fa3e544a7401.png', '62318d514160.png', '5a091e8cd95c.png', '855f0a5442b6.png', 'da6389d129aa.png', 'f7edc074f06b.png', 'fca931da5c5e.png', '12ef75375322.png', '8b26d3cd61e8.png', '6180920bc224.png', '61bbe8db6f3a.png', '1ab8d3431ffc.png', 'd29096bd94aa.png', '89b044cbaf85.png', 'f092febbf5c0.png', '0a38b552372d.png', '501c319f7a9f.png', '9faad91b6578.png', 'd0ffa0425ef1.png', 'c85b79d70079.png', 'b3f31c371e59.png', '67c03349bb31.png', '1b329a127307.png', '1a03a7970337.png', '527bea76116c.png', '5b804948e35f.png', 'ea4dcb055139.png', 'b92eacd1392a.png', '306c841af3fc.png', 'f7e9fa75c7c1.png', '1d0b93317aa8.png', 'f233638e0e90.png', 'ed246ae1ed08.png', '4b5ffea77373.png', '054b1b305160.png', '3b018e8b7303.png', '3ee4841936ef.png', '436e7a7af761.png', '4d7d6928534a.png', 'e3a7671f787b.png', '757572337fd0.png', '13ab8db8c700.png', '8d8aca52c07b.png', '878e356c8fc9.png', '17188c13e635.png', 'ad20080452de.png', 'ea15a290eb96.png', '9ac2e3e9fca5.png', '7d3835e4e63a.png', 'f85fd4fac887.png', '8e67f2d7e0ee.png', 'a12ca80bb8c7.png', 'fe2df69676cf.png', '4b422b48d0d4.png', '6ccfdb031184.png', '9859e2a6cc24.png', '6cbc3dad809c.png', '8241e43408a8.png', '9e7a63b2fc6a.png', '788ddb0b70b7.png', '6b91e99c9408.png', '0a74c92e287c.png', '9519a590985d.png', '39aa3cd93c50.png', 'd0926ed2c8e5.png', '44976c3b11a6.png', '1a19f2ef4472.png', 'cf603a9ef2d5.png', 'cd563556cb57.png', '5c8482926a08.png', '09237bf783a4.png', '18b7e34eab8f.png', 'c1437a7a52c9.png', 'f0546a45ef10.png', 'c4a8f2fcf6e8.png', 'ba735b286d62.png', '73ef3c3dcbe4.png', '3599029efeb3.png', '63b4d030b016.png', '7cc4b7aabe04.png', 'f55e1d2a19e4.png', '2821998fc002.png', '1b398c0494d1.png', 'b963a11638f2.png', '61d9c88a3a4b.png', 'e16af45285e5.png', '9b093fe95d6b.png', '06024377d573.png', 'a0cd7bffdaa0.png', '810ed108f5b7.png', 'a8582e346df0.png', '3079490a4b9c.png', '98d41bce73a8.png', '3c9529918097.png', 'fc898dfeb24f.png', '8c0d05233238.png', '7a238a1d3cf3.png', 'fca1a8738b8a.png', '596f4fdb0004.png', '76df141d966b.png', '7efc91af4ae6.png', '1dfbede13143.png', 'c739ff9580d3.png', '891392c9683c.png', 'e5197d77ec68.png', '3218a6d8eb2c.png', '1782142e17d9.png', '0d0b8fc9ab5c.png', '06be1092a062.png', '7247a2c97f71.png', '7ccb267fd394.png', '9878db94d9f3.png', 'd6dbb0820ea5.png', '875a2fc5fe23.png', '19113e5f45ec.png', 'eae70f527755.png', '30db694bee42.png', '0fd16b64697e.png', '6a2642131e4a.png', 'eadc57064154.png', '5a0fe0ee4301.png', '9b57e43b44e7.png', '55034b1dbff2.png', '09934421c79e.png', 'b927a9238434.png', '3fe282197c1c.png', 'b762c29cf2f3.png', 'cb2201c226d6.png', '6e092b306fe1.png', 'e3e490babc0c.png', '1411c8ab7161.png', '49eb73968c44.png', '7663aba8d762.png', 'ff8a0b45c789.png', '1c578b72d7b3.png', '33ffddea8c6e.png', '25dc1b41ed9c.png', 'cf0824f53dd9.png', '276b14f72328.png', '5b2648ad455e.png', '4dd5d5ccddcf.png', 'e6f0ce5bf282.png', 'cff262ed8f4c.png', 'f549294e12e1.png', '4b237b958555.png', '17eb5d4ad740.png', '65e120143825.png', '8cb6b0efaaac.png', '5077cdb88aed.png', '3bf2deaa5ef0.png', 'eeaea2c5ff34.png', 'b019a49787c1.png', 'e62490b7d0e9.png', '2a93334f663a.png', '465c618f7b23.png', 'e30a890600e1.png', '1ae3c58759fb.png', 'ce6f33a81ad5.png', '08bef347f40d.png', '6d6fcf49e515.png', '876e1dd12d38.png', '00a8624548a9.png', '524f240e0c90.png', 'e8d1c6c07cf2.png', '2221cf5c7935.png', '13063d1bc4ea.png', '89ee1fa16f90.png', '27e2be850a99.png', 'b7278b4f2448.png', '9c088d2d1559.png', '8e63fc4ab532.png', '917f76f360b6.png', 'a9d0c900b6a9.png', '5dd2e26fc244.png', 'ee74c3b177e0.png', '1c9521878baf.png', '47536db39f00.png', '40c24aded50c.png', '194814669fee.png', '5de4615a5161.png', '98e8adcf085c.png', '687759336b0d.png', 'c2f3281cf528.png', '750e0168399d.png', '3f6bccf21ce8.png', 'e594c19e2e1d.png', '7116128c65ab.png', '6ea07d19b4ce.png', 'b6a0e348a01e.png', '6028a575dc27.png', '99132193eaa0.png', '5188a8afa879.png', '51d780864365.png', 'ad312ca98202.png', 'c06024f05a16.png', '3c53198519f7.png', 'fc8fce67fbf8.png', '6d0c0531083f.png', '35362d43e753.png', 'd516f77d4516.png', '10f36b0239fb.png', '1d3e9b939732.png', 'dd90c321d7bc.png', 'd99b0f7dd9b9.png', '6110ecb3bb1c.png', 'c38dec54a9f7.png', '6cfb7b44ef6f.png', 'c2d2b4f536da.png', 'eeb231c3ef1f.png', '94b1d8ad35ec.png', 'df8365d6ac33.png', 'f576e45d1da2.png', '76cfe8967f7d.png', 'a3706ce27869.png', 'c56293f53191.png', '57469423a012.png', '3435fd8675a2.png', 'd1afdb8cf70d.png', '1d674e2e32e0.png', '5d9c841eb245.png', 'e93394175a19.png', 'd18f6431ebce.png', 'e81f4a2fbbdc.png', '1c3a6b4449e9.png', '2a099b247b10.png', '6a244e855d0e.png', 'b2748ac28fc1.png', '5cbe88914a72.png', 'bb5083fae98f.png', 'f5650eb52640.png', '991a0b7a8c87.png', '8ac0c44bbf24.png', '6fe67482bfae.png', '8191ae701985.png', 'fcc6aa6755e6.png', '0551676cc2aa.png', '1509d097b69a.png', 'b759cbef90c5.png', '9a28d4e8aef0.png', '959bb2d01091.png', '1df1530b9b8d.png', '0da321efbce6.png', '67844c46bc61.png', '4dd9d29eae5d.png', '76095c338728.png', '9c6512166557.png', 'a49b0b4484ea.png', '613028ede6a0.png', '73e83a07a16d.png', '9a3109657ac1.png', '1c0e5dd1b14c.png', '7d11dbc1e738.png', '4fa26d065ad3.png', '2ecbc2e3f239.png', 'cc9270f06b65.png', '72d98188648f.png', '2b88cb6e31cd.png', '650104ede84c.png', 'fc603cbedb41.png', 'a6b6d27c1b32.png', '2d07162a13b1.png', '36b5b3c9fb32.png', '8b58f9a338e8.png', '4ecd1fdd1435.png', 'a2ddabee14e9.png', 'e2c39ed0c941.png', '15b21c80cc31.png', 'ccd6dcb2f568.png', '4dd14c380696.png', '9a94e0316ee3.png', 'bfd5c0e55420.png', 'db3cd58aa315.png', '2585bbc91909.png', '684dd88a0d49.png', 'cb602182cde3.png', '36041171f441.png', '789f0ec1eab8.png', 'd2ffe9287dc7.png', '6c4ec95dd8ba.png', 'b5bf7b84fc66.png', 'ca30a97e9d13.png', '91b7a4179ecf.png', '6810410187a0.png', 'd6283ded6aea.png', 'dee31065f8fe.png', '504a69096fcb.png', 'dad71ba27a9b.png', '62cc7ddb53b6.png', '8ae049175db6.png', 'fb61230b99dd.png', '8ead17dfb6a6.png', '3694e8c8e09a.png', '0ac436400db4.png', '8f318a978844.png', '35777eb7859d.png', 'be6cbf6e5b10.png', '8446826853d0.png', 'de2eb5c8aa83.png', '8a3eb86ae4bd.png', 'b8e20c076b03.png', '15cd5f52d300.png', '6cd606dc52e9.png', 'a6d45de20e4d.png', '975252e325e3.png', '234399352d36.png', 'ff344e5c9341.png', '1f63d44d9e3c.png', 'e529c5757d64.png', 'bebfbd907cac.png', '3b9c1f42c2f2.png', 'c8905b8d5cf1.png', '84b88e8d3bca.png', '356304d15a5c.png', 'ed2c52c14493.png', 'd4bc001f7224.png', 'b3819a805dca.png', 'bfb578c0e8d8.png', '69df7ade0575.png', '51af8a689511.png', '7dee6bf8b9c1.png', '09f6ab477654.png', '10f6ef37fe43.png', '1e4b3b823b95.png', 'ace287a5c991.png', 'eb6b1f1c09db.png', '07a2b8cabf6b.png', '5c85d22bd0de.png', '52886bed8a07.png', 'b2aaa81cc8f0.png', '857002ed4e49.png', '282bc792d23a.png', 'e77a93c3d9a9.png', 'b17f0b81dab3.png', 'a0a0cd8af5a6.png', 'b8e9a8f4617d.png', '012a242ac6ff.png', '7b691d9ced34.png', '1d14dd912671.png', '5ba156a35ff2.png', 'e1900014dabf.png', '4a693dd3921a.png', 'dd3176bacfe2.png', 'b640e3bdff75.png', '61e301bd3c25.png', '0304bedad8fe.png', '1632c4311fc9.png', 'f580566e27f5.png', '9d1feed37610.png', 'b87f9c59748b.png', '14e3f84445f7.png', 'e2161692a0b4.png', '9fa02dfb5553.png', 'f5a8c6426a71.png', 'db52626d450c.png', '0dc031c94225.png', '2cbfc6182ba2.png', '38f1901f214a.png', 'f1979147aad4.png', '578109578b46.png', '5b47043942f4.png', 'd9ba044671e1.png', '33105f9b3a04.png', '064af6592ba6.png', 'c9485c38fdd5.png', '2da82d14e1b7.png', '92587e494d51.png', 'aba3063c5413.png', 'c8a3eb9a5b52.png', '6298468d7d75.png', '33596a635b53.png', 'd8cdb7d7283a.png', '23175b7ef453.png', '12025b34deb8.png', '36e4b704b905.png', '328d141ed3aa.png', '57a5f1015504.png', 'ea68b58a6e8f.png', '103abbd8b63e.png', '885fa5fc5da8.png', 'f1d719c97838.png', 'e4730ddde408.png', '31452ad8808c.png', '6cb96a6fb029.png', '54334705a34d.png', '9a3c03a5ad0f.png', 'a7673ac44509.png', '4d1e7def7624.png', 'e322acd46152.png', '033f2b43de6d.png', '8c87bd748996.png', '8a7765e785fb.png', 'd7ac4a0c9760.png', '9cc6b1f9bcbd.png', 'cfd1bd0fcbb4.png', 'ab78a66dee6a.png', 'cca626a0e19a.png', 'c97472ef2c66.png', '8a759f94613a.png', '7f43becd3e83.png', 'e9f82b5bbaf4.png', 'ab32db41c409.png', '36677b70b1ef.png', '5293576816aa.png', 'e6552b7432b3.png', '35d6c4c50072.png', '1faf8664816c.png', '9a56cfb980ec.png', 'ff77e8e5b5f3.png', '91e2c2890c9f.png', '4bd941611343.png', '46acc506fa61.png', 'fba493e17448.png', 'c67117c6ab3b.png', 'bf1b7e21e774.png', '247e98aba610.png', '50d8249f7bc9.png', '5e7cc6ab4ac4.png', '5ea9e447bb62.png', '03c85870824c.png', '0a4e1a29ffff.png', '55f7f018c61c.png', '3f44d749cd0b.png', '281d7b7c7676.png', '8871e6a26596.png', '0d8f60ed9280.png', 'bb08949dd70a.png', '4ef0b485a7da.png', '67ed8cc78b97.png', 'c546670d9684.png', 'bdff5d8bddf8.png', '8693ab1fd2be.png', '57a710de68a4.png', '9e2058917304.png', '4f20f9a9a65b.png', 'fb767cea406c.png', 'fd48cf452e9d.png', '8fc09fecd22f.png', 'a19507501b40.png', '3f82631e9080.png', 'aeab0a63bcaf.png', '33d72035c27a.png', '272d9c043c81.png', 'b5e6ae31493c.png', '4c5ab774a381.png', '31cb39681f6a.png', '3b58b02c89ed.png', 'f30f203ef51e.png', '2af1bf226f51.png', 'eb32a815f78c.png', '4ce74e5eb51d.png', 'ffec9a18a3ce.png', '401fdfd0db07.png', 'bda8c973b09d.png', 'dd285d9e97fe.png', '4a3da369b227.png', '511fd66b2df8.png', '23d7ca170bdb.png', 'e26bcae6c67b.png', '4b1001050f1d.png', '01eb826f6467.png', '6253f23229b1.png', '38fe9f854046.png', '5a2c27b95c7c.png', '81d79d53ed7b.png', 'ab88081e5654.png', 'a9a28c37c8c4.png', '0eff8eacb2f7.png', '66460ecab347.png', '86b3a7929bec.png', 'b6bf847fbcb2.png', 'a1822dd8d05d.png', '274f5029189b.png', '7270367410a1.png', '0851d6a69589.png', 'd9c9b9786da3.png', 'df0886f1e76b.png', '5b76117c4bcb.png', 'f9ecf1795804.png', '0d9a9896f801.png', 'a150ff5dfe07.png', '28751f290ba3.png', '2fdfb80ea53c.png', 'ed2ef440d22c.png', '8ffa608170d3.png', '453a1e2754b2.png', 'fefded6bf135.png', '12ce6a1a1f31.png', '2c2aa057afc5.png', 'fb696a8e055a.png', '6e0f78e188ff.png', 'bf8092e4001d.png', '53704c80f0d8.png', '959dc602febc.png', '525acfea47e8.png', 'cffc50047828.png', '1177d583c807.png', '8846b09384a4.png', 'f66c4ee86629.png', '780f9daaa24b.png', '1cc58b15f466.png', 'a4ee03ecff60.png', 'a125377fb985.png', '09662e462531.png', '237c078d00fc.png', '3e1f8fecb06f.png', '36865bbc64d6.png', '613bacb35c05.png', '3d3e288d490e.png', '586f5c56081e.png', '66d2ca47aa44.png', '870f433e8f37.png', '1633f8291a80.png', '7f6690fa390a.png', '45e4b7eada54.png', 'ea9e0fb6fb0b.png', 'd0079cc188e9.png', 'b8dab47a260e.png', '901a3552fe26.png', '4d17559ac1e2.png', 'f56ff0440ed1.png', '0a9ec1e99ce4.png', 'f80118bbda18.png', 'ee1ec90b980f.png', 'e1c02f6c3362.png', '22895c89792f.png', 'b37aae3c8fe1.png', 'af7a36454670.png', '0104b032c141.png', 'b09101adb478.png', '96793edb1003.png', '54bbe3da103e.png', '96ea316ed0ab.png', '7102f29e052e.png', 'd48178e4a49b.png', 'a15470303941.png', 'a4012932e18d.png', '4661006f3ba6.png', '81bc03e2ff2b.png', '934104859e68.png', '03a7f4a5786f.png', '5e5275ddee29.png', '13c191b59ed0.png', '88e5051f65bd.png', '851e40a21f81.png', 'b9bc81fcb075.png', '3a6e9730b298.png', 'bdb98063fe84.png', 'e06cccc08c59.png', 'ffd97f8cd5aa.png', '4403538fb50f.png', 'a96ff96bbae5.png', '84c663f39632.png', '78bcdffb8785.png', '2cef97083e6f.png', '8ed586c43023.png', '962c0fc85e13.png', 'bc73ce76ec43.png', 'e32a359be36d.png', '47b756014447.png', '874f8c1929f6.png', 'a0adbe677508.png', '0b64a0a06f9a.png', '4a558a1cd243.png', 'ca63fe4f4b52.png', '2f284b6a1940.png', 'ab03d50bba2f.png', 'c0968d41eb93.png', '51131b48f9d4.png', '46923eea9a4e.png', 'd67374d3fa2a.png', '0f364b7d4384.png', '3cdda8b3df19.png', 'c80f79579fed.png', 'fa573163dd8b.png', '08ee569d4721.png', 'a3957df90a78.png', '042470a92154.png', '70f5caf5f305.png', 'ca891d37a43c.png', 'eedae6b28f96.png', '23fca0693e2a.png', 'a8aed92940fb.png', 'e4f12411fd85.png', '7a6495a39d87.png', 'bfefa7344e7d.png', 'd41b33fcb94f.png', '88e4399d207c.png', '10fca1abf338.png', '7d37a2939f12.png', '6d259b5b4c76.png', '196e6a186452.png', 'abbb8791785e.png', 'bb45257258cc.png', 'c096131ad065.png', '4a0890b08532.png', '7e6e90a93aa5.png', 'b4b04d81acbb.png', '14515b8f19b6.png', '0c7e82daf5a0.png', '82bb8a01935f.png', '96b5474ae604.png', '7743f4e04a6d.png', '5f6db235c04d.png', 'd88806d9ece9.png', '144a1a426137.png', 'd868acdccb5b.png', 'a2b995b81692.png', '032d7b0b4bf6.png', '946545473380.png', 'a5a2a7003d60.png', '26d60db3bbfd.png', 'c6229222bf22.png', '8a482c024fc2.png', '7a6e384a0846.png', 'd9311f7497cb.png', 'b549af91bd30.png', '82ac8463fadd.png', '27fca9f12b3c.png', 'e4b0df29b96f.png', '43823561c3f0.png', 'eae901557a84.png', '9568eb7e9c08.png', '0e94cd271c00.png', '222f3ee3a1e8.png', 'f4ea2a2cfbb9.png', '1bf30c84bbad.png', '0c2e2369dfff.png', '784d6d302f98.png', '8b76c3c5cb3e.png', '4134b290f5f3.png', 'a3b2e93d058b.png', '6c3745a222da.png', 'fb1b8771c70a.png', '1d46f1326394.png', '8785b71238d8.png', 'acc9f29538c4.png', '64fedbf97473.png', '69fff98cb32a.png', '7635921c5efb.png', 'eed4afc8ec83.png', '3ddb86eb530e.png', '4e8585a96739.png', '60f15dd68d30.png', '5265dc9acdf8.png', '4dc2211a1c31.png', '5b3e7197ac1c.png', '31b5d6fb0256.png', '9e5ec293267c.png', '43ddd0ab0cc4.png', '49419f8d5cb4.png', '35df2bc6ae95.png', 'daad7b617f21.png', '01c7808d901d.png', 'ce754234d760.png', '2209daf71aab.png', '25a0a1e41afd.png', 'b10fca20c885.png', '29b52f64d2db.png', 'c3acf47700ea.png', 'f8fc411092c7.png', '5cc6dea19614.png', '27bab1432f61.png', '42985aa2e32f.png', '966c07831334.png', '9b95d6203406.png', 'c5a0e84e955d.png', 'a688f20f8895.png', 'cd01672507c9.png', '39923b29988a.png', '260a455692b5.png', 'a2696f444ecb.png', 'f3a4751af42e.png', 'e12df54e0d1e.png', 'ddb222ff7c1d.png', '97fdee242fea.png', '720b5f62ce80.png', '1638404f385c.png', '7427dedafccf.png', '664b1f9a2087.png', 'ef5155990874.png', '21abd36095a1.png', 'fb88783de055.png', 'ababe19ed448.png', 'e47770a2e5d1.png', 'c3b15bf9b4bc.png', '207dd0487264.png', '7179f85bfd6f.png', '24f3e70f0419.png', 'c5ba9e455d5e.png', 'e663c6627a95.png', '42b9c1977681.png', '9a4f370d341b.png', '435414ccccf7.png', '9837048b85dc.png', '59e5212f7139.png', 'e9ab8413e771.png', '12b57dac703e.png', 'e69b48516577.png', '83b61051737f.png', '2c9dfc270f1b.png', '962cf85e4f6d.png', 'a7b0d0c51731.png', 'fbfa925506f6.png', '4145dcb25053.png', 'bab776139279.png', '8bbd7835e9aa.png', '880edb2cdb69.png', 'bed8296c8dfe.png', '7828dd083cdc.png', '518e880613de.png', '3a122851e526.png', '8564b7aa3c1a.png', '64678182d8a8.png', 'f5733f77273d.png', 'a015ce4f51ad.png', '02da652c74b8.png', 'f9e779a13204.png', '34acae864963.png', '157d17349cc6.png', '20688cb25704.png', '6630f8675a97.png', 'f4de9620e3f2.png', '4e7694eebb91.png', 'e868c3da340b.png', 'cbf0394039f8.png', 'ec4649213ccf.png', '913b1890ed1e.png', 'aae8f9f3ef8c.png', '4fef9ed8a4c5.png', 'fa0c87bd75ce.png', '6061f5b7378d.png', '6bcce181be65.png', '7ed4128b2a4e.png', '52dbec057cc8.png', '9a7bd084395e.png', '799cb4c816ae.png', 'b46b09a45f39.png', 'ae61e19fb766.png', '762d6e5d5068.png', '531b39880c32.png', '188219f2d9c6.png', '7f0ffeb0a333.png', '24de56d433cd.png', '0519b934f6b1.png', '85cbb84ac8e0.png', 'c3d12a23f451.png', 'ea05c22d92e9.png', 'b7983cb3f270.png', '61a62b1dcc36.png', '1a0dbc6c0cda.png', '248dec89b3a2.png', '5e7db41b3bee.png', '0e3572b5884a.png', '3a4cfea0a766.png', '6dc0281f11e3.png', '51d0034d177d.png', '2df07eb5779f.png', 'ad6b07d5c338.png', 'bb9a3d835a94.png', '0f6e645466a2.png', '46d3316c4857.png', 'a85cda5f725d.png', '461fa5292fda.png', '50840c36f0b4.png', '0151781fe50b.png', 'cd4e7f9fa1a9.png', 'b3d135bd3bb5.png', '5eb8fb1aad41.png', '3748349334f6.png', '4dd4a4bf2421.png', '8f10e41a2f02.png', '436e1793d240.png', 'b085caa513a8.png', 'ed6bd9293a89.png', '639915f58a2f.png', 'd25b8a8ad3c4.png', 'f42b693a9414.png', '283c3aeba594.png', '201f6e10c108.png', 'aafb0c944f14.png', 'efff2f1a35f5.png', '4a1afe4044f4.png', '191a711852bd.png', '94f9ecf4b8d2.png', '7a9f45fdf29b.png', 'f7fec8935126.png', '2994f17f58a5.png', 'a44345b27804.png', 'c7c0470bcf87.png', 'b98f77098b9d.png', '3178559fbf57.png', '958c1fa044ba.png', 'e2a47a74e6e1.png', 'ef8c39eb9157.png', 'b8f1b30877db.png', '4246ed634f25.png', '5b1c4cefeb24.png', '453d553b0a94.png', 'f025f33b2c9b.png', '7ccf9d25dc48.png', '0124dffecf29.png', '096436d68d06.png', '63c3c571b8ee.png', 'e4e343eaae2a.png', '60edda7b4871.png', '735836b1ffa6.png', '5b32ece9c627.png', 'b71428739d4e.png', '1f4fb37e0854.png', '4f0866b90c27.png', '362c4a96cebb.png', '8676427e4625.png', '04efb1a284cc.png', '384631079d1e.png', 'cfed7c1172ec.png', '894a37fc3738.png', 'f6d760566a51.png', 'e0b5a982a018.png', '54cab3596214.png', '2a7373eeb352.png', 'fa9f1bc03f21.png', '72a867980067.png', '9cedf5c7016b.png', 'c1e6fa1ad314.png', '4da2961e62fe.png', '201f882365d3.png', '80e6e425f966.png', '4c17e85686f0.png', 'd7bc62d60e8c.png', '1c5ad36fb799.png', '5baed382f062.png', 'dce73d90c00c.png', '79be2ff796bf.png', 'a28bfb772f50.png', '19e350c7c83c.png', '519c6e8f78dc.png', 'e2ec22b3d07e.png', 'a77dbec966d4.png', '07e827469099.png', '92b0d27fc0ec.png', 'bb733062f494.png', '4c570172778b.png', '0cb14014117d.png', 'c8fc0df22999.png', 'b468ebf5cb11.png', 'e019b3e0f33d.png', '4ccee4db09b6.png', 'dd02d60bef14.png', 'fdd18ccbbdc5.png', '3ac3fbfca7d4.png', 'd18e5b68f6d2.png', 'b86fb2d5be1a.png', 'e966850247f4.png', 'fc4c2d35c6f8.png', 'ac17cc18a994.png', '697538183db5.png', 'd81338217fc5.png', '001639a390f0.png', '5777ef74c9ec.png', 'a07d571bf7ba.png', 'd3be5346684b.png', 'ad2f0b9d059c.png', 'c68dfa021d62.png', '9232dc06cfdc.png', 'd1a60c3b9fe5.png', '62e6f814c8f5.png', '5d5b5da5f939.png', 'b7aca95b97b9.png', '093cf723fede.png', 'f3cd489acbee.png', '7d94a000c2d0.png', 'f1dc26c4bfa3.png', '96c3e3db68bc.png', '22ce8ef69357.png', '4eabad7948cf.png', '0db1d8dcf219.png', '8aab201c0691.png', '976082127e2a.png', 'd2d523e9f669.png', '3132556f5352.png', '211518c46162.png', '9e3510963315.png', 'e9129ce55fd7.png', 'd85588ff2ebd.png', 'b22cc1bf0b8a.png', 'fce73678f650.png', 'e65f94ad9be3.png', 'f8f5942b690e.png', '04a6fc58dabc.png', 'fe0fc67c7980.png', '5bda2ed09e62.png', '65e530ee2e79.png', 'e1fb532f55df.png', 'f002ce614c59.png', '155e2df6bfcf.png', '499c8df39222.png', '1d37f1c8b6d8.png', 'a7b03e58a6e1.png', '308f7fce6f0d.png', '9041eb43456e.png', 'a8263d248523.png', 'ec6659926105.png', 'e06d3d4733f0.png', '367c7049929c.png', 'd8da9de62743.png', 'ca6842bfcbc9.png', '2608e1dac5b1.png', '7c90ab025331.png', 'b60dbf9f0744.png', '3044022c6969.png', '86d58f850a0c.png', '5327f88a1919.png', 'f999c6921e6d.png', 'c8d2d32f7f29.png', '18d8fdb140b7.png', 'e229aca862c7.png', '274f4de2a59d.png', 'f4df3d86688d.png', '01b3aed3ed4c.png', 'c027e5482e8c.png', 'ee2c2a5f7d0e.png', 'dbd062558b81.png', '1e7ccd4a1c87.png', '6d7d26025122.png', '5e18af29d812.png', '76cb010f7aa0.png', 'cd29c88c9e36.png', 'a47878630dc2.png', 'ef81cd8854cb.png', '13d014ccd136.png', 'abf09c44d5f4.png', '187f6ccda87a.png', '11b5c77fbf79.png', '3e3a3955b9c5.png', 'c9ea9d5eab65.png', '48fda42bd5d4.png', 'a9c7b83caf81.png', 'cf0575534cec.png', 'c1ebe785503a.png', '2b4c7b5f1f1e.png', 'b187b3c93afb.png', '612f2df37a1d.png', 'f36cb007a1ef.png', '1124ffcd76c2.png', '75a7bc945b7d.png', 'a963ac561580.png', '242fc19be06f.png', '4528fbbd43a3.png', '1f9ccda4ddf2.png', '5cf9127f251a.png', '222d0ac042b4.png', '97a5ad7548b7.png', 'c6d4e4a3bd4c.png', 'e23add229074.png', 'f4c7ae514c54.png', '7455e2b5fc57.png', 'd38cf0f4a9af.png', '873fe0404d6e.png', '847b04287c9c.png', 'e2856afe62c5.png', '3fd7df6099e3.png', '0a85a1e8f9e9.png', '8344c783da65.png', '026dcd9af143.png', 'd3dfd0a2dee6.png', '6e018411ba4a.png', '0953c0ac1735.png', 'aa6242f9e08c.png', '731b19a460ad.png', '8acdf12f412a.png', '5d6239c0fd39.png', '43fb6eda9b97.png', '2a08ed6bbcbc.png', '4f7755e74a9e.png', '1ca62b3e4fd3.png', '5671eb95512b.png', '0dbaa09a458c.png', '510aa0a898fa.png', 'f18abfa690ab.png', '1891698febce.png', '4a213b405ee4.png', '6e44f6d04fc9.png', 'b200c23b299b.png', 'ecad6845f630.png', '2d3f4094c08a.png', 'c6a145742708.png', 'f7116e7b2f4e.png', 'e50b0174690d.png', 'af831c158744.png', 'ae2c3f6312ef.png', 'b1b3e7d0a5f3.png', '16060f05d047.png', '9f5a8665cf2e.png', '4704dbb59536.png', '27e4c800a449.png', '3ac92ac3d65a.png', 'cd01f4f83336.png', 'd567a1a22d33.png', '895fe2bfc5b6.png', 'dd3dad6ca78f.png', 'e756495c11cb.png', '96a9706b8534.png', 'b7e0f95353f2.png', '0ceb222f6629.png', '15e24b73d4a7.png', '2f81ee5f2926.png', '38487e1a5b1f.png', '9e99ae6ee7af.png', '3b0190bbe615.png', '709784f7fcc2.png', '6f4e0538d1e4.png', 'c6a8f8f998a2.png', '0daddc45d832.png', '8e20b8fac7c3.png', '4cddfc22b0ad.png', 'bd34a0639575.png', 'ffcf7b45f213.png', '3732de8b416f.png', '34723fae6475.png', 'c24bcf7a1bc4.png', '587146a55885.png', '6f4719c6bb4b.png', 'f71333204618.png', 'd83c3efade75.png', 'da8900ac7f29.png', 'e387311a840e.png', '9b0eb9f41da4.png', 'f64b6e85f1c9.png', '1541226c5d72.png', 'b07bc463b718.png', '79059d0592c4.png', '8b079e79035f.png', '77f69c7ff324.png', '8906c9ed54a2.png', '5347b4c8e9b3.png', '3232b34cbe99.png', '870fbe6eaa68.png', 'a06a63d866b2.png', '33b91def2035.png', '2735be026d44.png', 'de50dfa745f8.png', '31616ff6b53b.png', '571bbdbf585e.png', '78a577c3e0bf.png', '30cab14951ac.png', '1d55e689cf84.png', '467b7d9d811c.png', '5e7630f8438e.png', 'bca2bdc15fc5.png', 'b69c224edd6e.png', '1002f3fe38f0.png', '269b44e628eb.png', '902dc5a91a3f.png', 'add1d681d712.png', 'f0800723bc63.png', 'ed3ce1674761.png', '2b10f138e67d.png', '2408799a09b2.png', '4f5dd7660b17.png', '3ca12e02dd4e.png', '8e3b79e1f1f7.png', '94ef1d14597f.png', 'd2cd47ed2c1d.png', 'b77b88926843.png', 'c1896142a20a.png', '72606afaf3da.png', '6fbaaf8eb67a.png', '00b74780d31d.png', 'd7bc00091cfc.png', 'cc1eebed9276.png', '6e1db8711879.png', 'bfa30ebf63a8.png', 'b67ae80f7eba.png', 'ed3a0fc5b546.png', '310c27067ac0.png', '68332fdcaa70.png', 'b06dabab4f09.png', 'ac720570dd0f.png', 'ff4cd992667b.png', '6987804eb464.png', 'c31651ea04c6.png', '6e092caa065f.png', '7fdb177b8f7d.png', '62b826899151.png', '9ce46d400cd6.png', '61c667663f2f.png', 'b2b7ccd34cbd.png', 'd436c06f0490.png', '50f5201fd18a.png', '2bb063318cf1.png', 'd952dbfb0fe4.png', 'c64c0966b4cf.png', '197af0de76e2.png', 'abdb365cacbc.png', '6a905a7202d2.png', '6bf2a81a5d91.png', 'f47a2a4a0411.png', '0c43c79e8cfb.png', '8f1e7433a95d.png', 'cd45bfa07d41.png', 'b598bc9753c2.png', '0097f532ac9f.png', '18621b9ca978.png', 'e6a58edc5b42.png', '28f98cfe3858.png', '5b068765e846.png', '32ed318235b8.png', 'a4d4b69f7404.png', 'af3b0115aad1.png', 'cf6551521a35.png', 'f03d3c4ce7fb.png', 'a64273801bde.png', '359bab5d784b.png', '1e8c31e29dd3.png', 'f58d37d48e42.png', 'f3a268d2726d.png', '8dba09a4e5ed.png', '810d3779abd9.png', '9eaac43744f5.png', 'd9ad2a0ec026.png', 'bebb3f167654.png', 'd8404680bba6.png', '8ff2733f6aef.png', '4e82c3c8d31f.png', '0f495d87656a.png', 'e135d7ba9a0e.png', '025a169a0bb0.png', '6cb98da77e3e.png', 'b553e7909535.png', '2cacdb0dffae.png', '50d8a8fb7737.png', '08a3875063c3.png', '0a61bddab956.png', 'e4c799738a19.png', 'a419fcb2dfb5.png', '9f935fb38440.png', 'dfea19863428.png', 'a1eb88562239.png', 'a3bd2e034614.png', '47d1603a555b.png', '03fd50da928d.png', '5e97cb2b0888.png', 'f1a761c68559.png', '52ae917fcea4.png', '3c78bfca247b.png', '930fee99213a.png', 'f0a2dc580009.png', 'a21b37719f9b.png', '921433215353.png', '1002b5151b8e.png', 'b4e15102cd7a.png', '4ee1ad981a6d.png', 'c0e509786f7f.png', '8dafa62f9322.png', '6d292ca4c9ad.png', '66bae1ba227f.png', 'cd48cfab4e44.png', '24b943fe725e.png', '4e54ccfd49b2.png', '408ea9d5e082.png', '65cf00be6fb4.png', 'e38f3a65b02b.png', '0c917c372572.png', '7a06ea127e02.png', '4c60b10a3a6a.png', 'cd3fd04d72f5.png', 'e933923aab15.png', 'b49b2fac2514.png', '3ccf96c1dd6d.png', '98277aeb96a7.png', '63e041a757eb.png', 'd28bd830c171.png', '61f403fdb434.png', 'a56230242a95.png', '4a44cc840ebe.png', 'ae58ccb5905e.png', 'a5bb85afc6e8.png', 'bff51afc76d4.png', 'bb783d8e496f.png', '7a42443ed106.png', 'fb6b8200b7f8.png', '5b72ff04333d.png', 'f762c272c522.png', '4c52922f3bfd.png', 'c21eb81de9fc.png', '6fe4751a3b42.png', 'e65a2ff90494.png', '5173d54fc214.png', '44a4d04162cc.png', '3e61703b5ab2.png', 'e3ec668f6fad.png', 'a8e08e7fe016.png', '3af9aaa880e9.png', 'fe674c2f73f5.png', 'b086c7cd3868.png', '437900a99871.png', 'c62585bd68fb.png', '041f09eec1e8.png', '4beeca5cc859.png', '7fc3a8bb40de.png', '3a643599f852.png', '5486da4273d7.png', 'c406325360b1.png', '922586d86cd8.png', '525d0dd8dc45.png', '144b01e7b993.png', '9a159d4674cd.png', '5299a532f0e0.png', '882a71de424e.png', 'ce887b196c23.png', 'e47452069ea1.png', '4ab8c0cece7f.png', 'ae49cc60f251.png', '84a72e15b23c.png', '07419eddd6be.png', '7e9081e95bf6.png', 'e4ae1ee6aada.png', '3710ff45299c.png', 'cf1b9d26d38d.png', 'e39b627cf648.png', '28f73575e1f2.png', 'db690e2d02f8.png', '33778d136069.png', 'b82d5f1f1145.png', '58a9e0d7f7af.png', '8273fdb4405e.png', '17d997fe1090.png', '3325b1fe55d2.png', '1ffaa51a6245.png', '02685f13cefd.png', 'f2ee81781411.png', 'bb752b179751.png', 'd3d578fe433f.png', '87774aafe068.png', '974c7d7b9c64.png', 'ace2281f00c4.png', '0e43c8298fc0.png', 'b9b6ee2b9453.png', '58f07741ee3b.png', '6e73acb2cf60.png', '83d81ba5959c.png', '65e51e18242b.png', '599498e9e4bc.png', 'f0c13be90519.png', '1f3f32efaf20.png', 'd160ebef4117.png', 'c87493ed320c.png', '6c2555a9cae4.png', 'd4583e9525dc.png', '91f3c4c1e72b.png', '76f3473df8a6.png', 'bc23f74e14dd.png', 'fdc685055659.png', 'ed648b9bcd95.png', 'd51b3fe0fa1b.png', 'b0eeae01b8ab.png', 'df9cb3729eb1.png', 'e59c5f345bb0.png', 'ad1f7445b1a8.png', '291e2ff3d834.png', '5d024177e214.png', '7e5a76c4e103.png', '4bcee3cbe232.png', '7347bd23ba80.png', '99240ee00485.png', '9e2a8135f471.png', '4409965eb2a4.png', '54bdcdecd8f3.png', '4c129470cec4.png', '2d04cead4d3a.png', 'e12d41e7b221.png', '87a9f4d20f07.png', '07929d32b5b3.png', '2967e578939f.png', 'bda91b76095b.png', '51e656e5a541.png', '76cab26493f1.png', 'ea4ce9516144.png', '3286073a976e.png', '57f5ad4b5b29.png', 'b835b6e31a59.png', '87d46b1cc4e9.png', 'a664d2055886.png', 'e17507a4a1f5.png', 'a08a0133754a.png', '90960ddf4d14.png', '8d4d14a4ab07.png', '07a3be30563b.png', '1f5496352859.png', '0c38940e1f80.png', '29bc0e721cfe.png', '582f739b8f62.png', '55fd453001cc.png', '6b07971c3bf6.png', 'd844a7252f4e.png', '6df8b7b6e837.png', '4e1e252317b5.png', '174db0854291.png', 'c5a9ebef1517.png', 'beb2ad14fd2d.png', '996f57c86ba5.png', '30263a7d5609.png', '22449af52060.png', '4158c340fa49.png', '760b6f4c6d82.png', 'b94c58d063bf.png', '8be6629a6039.png', '565f3404f9b2.png', 'e3b47ed5b511.png', 'ed6704e3b72e.png', '1594ca6c30d3.png', 'e7a372a1c3a4.png', '19545647508e.png', 'e9678824215d.png', 'd30d079e6f9a.png', '545df1bbcd61.png', 'b21abe5d9722.png', 'c561bcd519e9.png', '92889b863ae6.png', '48c49f662f7d.png', 'f5e6226bd2e0.png', 'eabf421f94d0.png', '55092c0071eb.png', 'a9bc2f892cb3.png', '756b0d6488bb.png', '7214fc7cbe03.png', '12e6e66c80a7.png', '3e6bfc4d5c65.png', '5814cbd2e9bf.png', '4abca30b676b.png', 'f7735b6d47f7.png', '2bb3c492d6d3.png', 'f72ef9ceeaa8.png', '19722bff5a09.png', '44e951e45dca.png', 'f58cdfa968be.png', '05cd0178ccfe.png', 'f9156aeffc5e.png', '8bf05909e1e1.png', 'e4d3d437b0a8.png', 'bdc6c60e9133.png', 'f2c0b41acd05.png', '3c42512c81e0.png', '3cd9713c0ecb.png', '9f436886e056.png', '59fee5bc3479.png', 'ec363f48867b.png', '2ef955d6d9ff.png', 'da1fb35f5df9.png', '35aa7f5c2ec0.png', '239f2c348ea4.png', 'da949aa67a4f.png', '71a39c660432.png', '00f6c1be5a33.png', '2d7666b8884f.png', '62b4be2799ca.png', 'df4aec4a0eaf.png', 'd93b61dc8f64.png', '98f48850ebce.png', '2e79041ef722.png', 'd4be0403e6ab.png', '7525ebb3434d.png', '3fd45879afe6.png', 'eb1ad14dd281.png', 'd91635f380b4.png', 'ec0c9f817b03.png', '7569ac24762e.png', '0a902c80d5da.png', 'e66ad813a508.png', 'e087bd4b88f2.png', 'f633c474e8b8.png', 'ccea49708830.png', '7f84284598f5.png', 'c7c3d363bc86.png', '76bc31e0d3be.png', '9b32e8ef0ca0.png', '4478b870e549.png', '513b0a4651fa.png', 'c90c6b94cf40.png', '2fb3a8606a77.png', 'a73c3d516c59.png', '0318598cfd16.png', 'c252da9b41d8.png', 'd51c2153d151.png', '7b29e3783919.png', '0125fbd2e791.png', '9985375d709f.png', '165cd2070ebd.png', 'b7f0bc7d399e.png', '00cc2b75cddd.png', 'c0e15e8e2b46.png', '1d74c4713e21.png', 'f9d8ff3e6592.png', 'acf976efd7ce.png', '29f44aea93a4.png', '2cf18033da31.png', '365f8c01d994.png', 'a04fb36db784.png', 'e2265c383348.png', '254052cf3e48.png', '3dfc50108072.png', '26d9576e8043.png', 'a06e5ac695ce.png', '0cd31078cd08.png', '25d069089c5e.png', '96c699221180.png', '1438288bb2e1.png', '2dd28ac497d2.png', '26fc2358a38d.png', '08f8838d69bb.png', '85f99e7e4052.png', 'c9e697117f3f.png', '3908b3cfd620.png', '606daaf0bfc7.png', '87b671c6d4c5.png', '5056fa7d505f.png', '77a1f1398fdb.png', '60eeae3ba23d.png', '898f0bc8acfa.png', '07751b94a88a.png', '086d41d17da8.png', '77e7c7a160c8.png', '4927945ecfed.png', 'e7578d8dba72.png', 'c334f8688b77.png', '217dad18a5ed.png', 'f6f7dba7104d.png', 'ea1d045f9fea.png', 'd5c63a8d9e94.png', '4c53cc97ea13.png', 'a34fc5376669.png', 'd1f7ea924a01.png', 'c3c8fdda50c0.png', 'd9a475dfe59a.png', '6dc07f968794.png', '188a9323be03.png', '3c326543fff6.png', 'aa60813e1a8d.png', 'bc8c6a778cde.png', 'e6a6acf7fca1.png', 'ad93d88c87ea.png', 'e1ab92228e60.png', '523d0c2cb4d6.png', 'ac5b5dddf91b.png', 'abe940882578.png', 'b13d72ceea26.png', 'bc34f52c37c7.png', 'a45d77edf8d9.png', '5b5b80a3edee.png', 'f02057c41256.png', 'cfb17a7cc8d4.png', '4c635a01593d.png', 'a26f50218b84.png', 'b9519abce0c1.png', 'b532dedd928c.png', 'bfaa0080ab61.png', '52ddde91a349.png', 'c94f37085d0f.png', '69591ebb198d.png', '6d5a8362dd1e.png', 'de6210f88536.png', '454a944eb557.png', 'd144144a2f3f.png', '4fd5ec0dca09.png', 'bcc762618e7d.png', '1f07dae3cadb.png', '7e77b61e1639.png', '90a786abe58e.png', 'aa6673241154.png', 'c12e9ca420a5.png', '2a2a6435f7f3.png', '9d74428188bb.png', 'a8a6588c8eb7.png', '374535e0adb8.png', 'dd19428c3d29.png', 'bec0acd539b2.png', '45369821d6a3.png', '39fd8ef3a45c.png', '03b373718013.png', 'be68322c7223.png', 'd2c5fb82fe5f.png', 'f5e9a307288c.png', '9ed6c2b25767.png', '2cdcc910778d.png', '462937ece243.png', '65dda202653d.png', '8bed09514c3b.png', 'aaaadb174012.png', 'dc0eea0b68a7.png', 'd94e10f42861.png', 'c18a006f7f1d.png', '342edf9b889d.png', 'f58f0b2fd718.png', '357f02a779d7.png', 'f4e68b61f480.png', 'f0e1201b5c1f.png', 'b191ba0a2b12.png', '24b87f744598.png', 'cd9e2190c73f.png', 'fda39982a810.png', '1c9c583c10bf.png', '1f15ca672675.png', '2665f72e2dd3.png', '8114d6a160df.png', '4dd71fc7f22b.png', '521b5377a727.png', 'd18b1d8ac4de.png', 'f57cf3b6f48e.png', 'f952ad2e4356.png', '83df53d58f28.png', '6666c4f18396.png', '495255c7492f.png', '3b73a3a4a734.png', '82e5bc01f8a4.png', '767d777ee889.png', '493d99f030e2.png', 'ec57cc20d776.png', 'b0f8613305a3.png', 'c05b7b4c22fe.png', 'e10190a9d52f.png', '8421107255ae.png', 'a86128b601a7.png', '9095d43fb132.png', '40527a5e95dd.png', '289a47dcbb82.png', '180afe1d5ef7.png', '96d48b073f18.png', 'daff5427c9b2.png', '18b99159a14f.png', 'a47432cd41e7.png', 'd66b6f333dc7.png', '13073f075a56.png', '59928f999ae7.png', '6531070bf03c.png', 'aed4e743c230.png', '7f1f3269f546.png', '1b32e1d775ea.png', 'a9e3d186cd1b.png', '878a3a097436.png', 'f298b7d05958.png', 'fdbc252813b1.png', 'ae1344610ebe.png', '378963f9df22.png', '7ce671f952be.png', 'a70d0f12a641.png', 'ac1667fac512.png', 'ef247f28004f.png', '75ed83dbccce.png', '52230bbef30e.png', 'c1819db0aece.png', 'd3de0d313d61.png', '05b1bb2bdb81.png', 'd9d2631f043c.png', 'f72adcac5638.png', 'c52bb7343387.png', '0b00f8a77510.png', '314862758acf.png', 'f85c78201a50.png', '1269ab57c2e6.png', '4e6071b73120.png', 'd271d3a2b552.png', '4982378d72f9.png', '80ca40196225.png', 'bd06028eb7dd.png', '1844a039b4ea.png', 'd51e5d7484ea.png', '069f43616fab.png', '3ca8be3b40d6.png', '0ae2dd2e09ea.png', '10f10fd30718.png', 'da3a2275c850.png', 'f451eee2b66b.png', '8d7bb0649a02.png', '3461dc601cc2.png', 'ae8472f8d310.png', 'ba4d2c4b3039.png', 'badb5ff8d3c7.png', '03747397839f.png', '5ad3dabeb2cd.png', '0f96c358a250.png', 'c5e238aa18be.png', 'ba2624883599.png', '0a09aa7356c0.png', '95a4cc805c7b.png', '62ecdc90dd42.png', 'b4f41b5bf0ef.png', 'edceb0657d77.png', '76fe19ff64fb.png', 'a3475dc3ac80.png', 'f4874247ede6.png', '4689b739d240.png', 'ceb32a193eff.png', '115e42dd6a81.png', '2b5bb6d33959.png', '90b8bf342032.png', '0243404e8a00.png', 'f0c0f7b5e820.png', 'a0e635689259.png', 'afc744fad65e.png', '07596907347b.png', '97c6cb55866d.png', '7ea756985353.png', 'df84e7113003.png', '15c24478ac72.png', '184a185e7447.png', '8aa3c4681542.png', '290ecdba359f.png', '7bda86d95c5b.png', '1df3e03a8f5f.png', 'dec5595e6154.png', 'de38adaae009.png', '78937523f7a8.png', 'ce8d2efd9d4f.png', '8e6df9eedcd8.png', '0da09e3ce8f1.png', '7ee6de71c140.png', 'af133a85ea0c.png', '58ccba7eec9c.png', 'f02babb3a023.png', '1409ab48175a.png', 'a15590a7d774.png', '080ee76c958c.png', 'd803598dabda.png', '08037e4490e5.png', '0d0a21fd354f.png', '0b3efe669365.png', '830e297965a1.png', 'b8ebedd382de.png', 'e1b8acb1cea1.png', 'e76a9cbb2a8c.png', 'e32dc722eca5.png', '711d1480d2e3.png', 'a8b637abd96b.png', 'f45f1485c940.png', '3f3de2a6b0f5.png', '8ead8f37423c.png', 'd5a39339ff3d.png', 'e0d229db881a.png', '27b68863349f.png', '3246f07e65b4.png', '1623e8e3adc4.png', '9688c6ef5dc5.png', 'a14fcf84bfe1.png', '842d697884f6.png', 'd78b7401096f.png', 'ae8424cdb029.png', '445a8a6da55c.png', '2db0cd3e30da.png', '94111ed3d276.png', 'daeaa5d8cf70.png', '8dc22e65c06f.png', '0fb560f9adb2.png', '43f22d1be8dd.png', 'fdd534271f3d.png', '1b4625877527.png', '3580a545016d.png', '3f98be586fe3.png', 'f8cf7ed8ef00.png', '165634a6167e.png', '53ddae6a619e.png', 'ff631653374e.png', '29d059522fa1.png', '441117562359.png', 'b7ce561a7328.png', '495106ae3b68.png', 'cf8f1bc7a215.png', '496155f71d0a.png', '3f47f83217b5.png', '77543f66a84a.png', 'e150935f66a6.png', '253e96488cfb.png', '2923971566fe.png', 'b460ca9fa26f.png', 'da9574d35b82.png', '54b322c66d01.png', '44878f34e31f.png', '5b3d41626ec5.png', '7f39c36469b5.png', '1608c82a263f.png', '41ab357d103f.png', '573ea80a53be.png', '57db4781e7ec.png', '0b2ea8f268cf.png', '710b05a96e0f.png', '9858cc2ae073.png', 'd0d59ed675b5.png', 'b033ab4fb723.png', 'aad0c0ee9268.png', '2b2f5a0f880d.png', '80b5a9519aec.png', 'b99794a0beed.png', 'c40976189f22.png', 'd865997a6280.png', '052d9a3fe55a.png', '4cf4d528c08e.png', '12e3f5f2cb17.png', '3f8d5c940ba4.png', '034cb07a550f.png', 'c597ef460944.png', '1bb0ddfe753a.png', '91e8af9ceee9.png', '5e505e25cd3e.png', 'da9262d9f5d9.png', '8c2f0f04e1ed.png', 'd26bc6e1230d.png', 'ba4e62c11cc0.png', '4e231670b48c.png', 'd99dd99be001.png', '5bf3357a2823.png', 'cf8ae5501bd6.png', 'c365c598ad4e.png', '7ad0c4975890.png', '576e189d23d4.png', '6a2c3f4ef329.png', 'e5f73f2855c0.png', '15bed5adde74.png', 'c1c8550508e0.png', '7a39c91416e2.png', '389552047476.png', '4e4a6224a04e.png', '6181aa9f75f4.png', 'c6e1e9fbf39b.png', 'eaa0dfbd5024.png', '78d53c82a23e.png', 'df841a0440d8.png', '785777558f05.png', 'ab724603ee93.png', '4a589edaea60.png', 'c0a0828e01b4.png', '6b00cb764237.png', '3b10191dfd25.png', '6653ad026901.png', 'e9faf0296643.png', 'bd500a73beae.png', 'e9ff9352ccb3.png', '3cab32dd6ef9.png', 'e29e54ff921e.png', '4ed31cc07366.png', 'da9fe02dead3.png', '80ed04a84a16.png', '34a7dbd3f05c.png', 'a1faeb4d5f10.png', '5b0e53f53ef3.png', '0afbeeef0ff7.png', 'b65ff67743b2.png', 'f71aca5a7dc3.png', '8f2996b8d855.png', 'c373b73a80c8.png', 'bacfb1029f6b.png', 'c01eae4b4939.png', '0fe31196e0e8.png', '093a42649c29.png', 'ae975c43bd8b.png', '22d843b2bbd1.png', '9a496b1e20f9.png', 'ef7eb85b75fc.png', '4860f7813654.png', 'ebd96d853918.png', 'bcd503c726ba.png', '4242c0d87f57.png', '8f06ca4642bd.png', '6504b703c429.png', '4d3de40ced3a.png', '7ec1ffe8220b.png', '97a235367f9d.png', '7f6ce40f306b.png', 'e13412678eff.png', '599b89048034.png', 'bfdee9be1f1d.png', 'cd5714db652d.png', '1fb455685328.png', '705f508d1e42.png', 'b64e1eef3d63.png', '33e8e26a75d4.png', 'a80dab8eddf4.png', '7131bf4c9e6f.png', 'a3802934bad7.png', '668a319c2d23.png', 'e724866f5084.png', '657859f893d9.png', '5c7ab966a3ee.png', '7bf981d9c7fe.png', '9fab29e69a6b.png', 'b72f59b85f7c.png', 'a88f68b0b114.png', '675de69373f8.png', '80feb1f7ca5e.png', '9d98a0b585f2.png', '3c28fd846b43.png', 'ee3fe7809e6a.png', 'c3789c1dab96.png', '143db89c11c8.png', 'a32b5ce3d48a.png', '74418f620068.png', '2fefb720869a.png', 'a4b8de38eac1.png', '302bcdb635ff.png', '12a82fc7d73e.png', '1e143fa3de57.png', 'dde43aa22ae6.png', 'cd93a472e5cd.png', 'b35cad8fe2d7.png', '457c7c927e27.png', '9287e57326d0.png', '269f0792f11f.png', '0c76fd494af6.png', 'd9bbdc33db83.png', 'b99afe7137fb.png', '887c26fc0e1f.png', 'b0f0fa677d5f.png', 'c704bd669f36.png', '7c6594b50690.png', 'b1197f2cc9b3.png', '80964d8e0863.png', 'd332d7b8a26e.png', 'a30a143a53a3.png', '04ac765f91a1.png', '3486f7096276.png', '80d24897669f.png', '03676c71ed1b.png', '1601c939412f.png', 'f06e7a9df795.png', '226c6ceb9185.png', '15cc2aef772a.png', '224c14366e11.png', 'ca2b54b95ade.png', '879744b9dc65.png', 'a9e984b57556.png', 'fa6f3d8bb1d5.png', 'ff03f74667df.png', '98fbe56dcc2c.png', '9eaf735cf01f.png', '2ba0b0d9bda2.png', '598b8f5b3822.png', 'c8823cdaf7fa.png', '4a5a6efc0bef.png', '91e82fe4e434.png', '44f4ae58990e.png', '3b185ac445d0.png', '5728b8aa98ef.png', '81371b0c01ad.png', 'ff52392372d3.png', '5e52c9fe676f.png', '1a7e3356b39c.png', '5152bf091152.png', '2d558de2cabe.png', 'b73d0bcd3d33.png', '1b8ad0afe9fb.png', '4f46d7ee61ed.png', 'c70d09370109.png', '40140a925c43.png', '4c60f6fcea75.png', '71f6a6e4620a.png', '75c180e04f65.png', '1ec95179cdfe.png', '4ef16a53d899.png', 'e97ecf4355cb.png', '98e44127872f.png', 'e79e10907295.png', 'ef7a4ed8d5d1.png', 'fd62bd0db4f1.png', 'bcb0498ed2c1.png', 'bfda2fd0533a.png', '5cde55f745af.png', '8d62ba9cb22a.png', '07083738b75e.png', '2f5c9cdfb333.png', '8543a801dce0.png', 'c9c563864ab1.png', '6dcde47060f9.png', '81b0a2651c45.png', '09f1111a388a.png', '7be1b9aa78aa.png', 'c76664770c07.png', 'bda7ff3b1562.png', '85cc6d636898.png', '54038e56131d.png', '848e66b9e199.png', 'cc839823755b.png', '3b2b91590590.png', '896ad584a841.png', '3c72f580d4ba.png', '07a0be6b347f.png', 'd866c26d76f0.png', '6d10709053ae.png', '57a5e4274275.png', '70d0392397de.png', '33e7bf536fc5.png', '2c827005b8f8.png', '07f5d7baf907.png', 'b96b518596b3.png', '0182152c50de.png', '50a2aef380c8.png', '74211a2b6dcf.png', 'c755a0c4edcc.png', '6d9effbcde78.png', '929cd3867815.png', '655cafb4c932.png', 'd1fb4efb117c.png', 'a8c950a99107.png', '1c47815f4a6b.png', 'ccd34029493d.png', '6165081b9021.png', '9274e75dc4d5.png', '54dc6e8107cd.png', '4c78d9d18da9.png', '84b79243e430.png', '8d9516ea3587.png', '8650d32f4a9e.png', '0edadb2aa127.png', 'd6f36ec5564a.png', 'c5431b81cbc9.png', '9f1efb799b7b.png', 'a95858e052d6.png', '9ba469af2980.png', '28dc010a0780.png', 'aa841de1ee82.png', '7526c59c36d3.png', 'a1872f9c0cba.png', '757e39293591.png', '22325552a4e3.png', '6966abf40b8c.png', '059bc89df7f4.png', '48543037d0b3.png', '6889bc64ab09.png', '4a05f81b3aba.png', 'd994203deb64.png', 'baaca2f7e1f0.png', 'eb175669d789.png', '5ca73d28f17f.png', '876deb29f000.png', 'b55d2ddb3e75.png', '8a25a080f28f.png', '77a9538b8362.png', '6294b378d09f.png', '21037f5c7790.png', 'b70e7c26f51e.png', 'a87f53bc984a.png', '51da6aebba8f.png', '7c3747c0b2c3.png', '5bf6f2958e53.png', '1da4a17c18c9.png', '42a67337fa8e.png', '0684311afdfc.png', 'f6f3ea0d2693.png', '780be525036d.png', '763ad1236efe.png', '11d8e5eaee5b.png', '64ac539f58cb.png', 'f0267c42907c.png', '0dce95217626.png', '86e7f98f73f1.png', 'e16fc934069f.png', '5fcff7280019.png', 'd15ca3469b87.png', 'f91cfa82b9d4.png', '07a0e34c8d20.png', '084c02cf077f.png', 'a9dc80cba9a4.png', '141735b57ec0.png', 'ad029ba7fa8b.png', '42c65af5ab16.png', 'a11c62cb3f86.png', '8e2a3978c244.png', '1c5e6cdc7ee1.png', '349f3c0ac83e.png', '8db2ce991101.png', '77acc2cafee1.png', 'e25ccfe38e44.png', 'ca7f5caddf96.png', '2fe06bedb2c4.png', '0e0fc1d9810c.png', '5a93c0f783c4.png', '5889a0c75cac.png', '0cb6b898389f.png', '663a923d5398.png', 'cbc23af521f3.png', '6f0463c1ff18.png', 'bf811911acf9.png', 'bf6cbccacf39.png', '4da6e2089d57.png', '48afe8c47454.png', '90a9a41eec6d.png', '9f285b3e57ed.png', 'be7bc89f5fec.png', 'de4cdabbce6d.png', '48a45619d1a3.png', '02358b47ea89.png', '523ff163211b.png', '58af2c054ced.png', '5a179c123fd8.png', 'a00b4cb250a7.png', '594f69b503ad.png', '6f689fced922.png', 'e4210e7fe587.png', '000c1434d8d7.png', 'a6356a3c5d11.png', '873dcc0b468f.png', '44c869174e3a.png', '2a47e5b21791.png', '7ec0e61a7e29.png', 'b498b84d383f.png', '06586082a24d.png', 'b56340f472d2.png', '9f4132bd6ed6.png', '2f9b66784109.png', 'e7b5dd5bab1f.png', '92f313287a29.png', '7c52fe73e748.png', '0afdfe5f422c.png', 'd1cad012a254.png', '8a67f1efa315.png', 'a62e995f167c.png', '7e980424868e.png', 'b0d35981708b.png', '7d0a871c45db.png', '4c6c5a1bf5ab.png', '80e7cc0a0649.png', '94076a9fb9b5.png', '28824d12d31d.png', '90c982cc2d96.png', 'c9d42d7534e0.png', '80dbeb0fdc75.png', '05e9126dfa5c.png', '4d21ce39c905.png', 'f2d2a0c92034.png', '5548a7961a3e.png', 'a82a12ad3fb1.png', '0ad7f631dedb.png', '1f543a86c4d4.png', '7e9458de5707.png', '2a2274bcb00a.png', 'e83d315d8f98.png', 'bf7221a016b5.png', 'dea7538bb91a.png', '9c72ed6befa0.png', 'b1c6f0997e27.png', '022f820027b8.png', 'fa9bece586fc.png', '9782c0489eca.png', 'b402b18d99a5.png', '8a87dd2a784e.png', '0ce062f26edc.png', '4189d4e631ec.png', '4aa07d720638.png', '1ca35d483772.png', 'aa0afc41ed19.png', '555d0bef3c5b.png', 'f080a22008be.png', 'dee1031a76ae.png', '1e742358e0b9.png', '0dbe6c26cedc.png', 'a6731dd737af.png', '2628305cbb29.png', 'ad1aa75d5630.png', '2a5a8b744f08.png', '2e26762daed5.png', 'ee6e39319b39.png', 'e9ce5bf645ab.png', '04d029cfb612.png', '3810040096cb.png', 'bba38f2294a3.png', '7e70344b0c25.png', 'aabd867043cf.png', 'd264396d8d1a.png', '19244004583f.png', '6324d77cf926.png', '3a1d3ce00f0c.png', '73d40ce06a67.png', '8c7c26c52a6c.png', '4faf4063db8c.png', '58c12863f33d.png', '486e852a3b4d.png', 'c6a2975228af.png', '61c2fbd16e38.png', '1b8701231c8f.png', '6c9c902a97de.png', 'ab686895533e.png', '49a4765f8822.png', '3cd801ffdbf0.png', 'fc1b1841eadf.png', '4ad8d3ec8789.png', '91cf56d3d1af.png', '0415fc68b176.png', 'ef48780f5d5f.png', '93a1b984de84.png', 'f460608cf4cc.png', 'b5204c0decc7.png', 'f90f8931a9bc.png', 'c568e5245ea5.png', '76e6a9238570.png', 'be161517d3ac.png', '8a81f62320d6.png', 'b7bd4a6627b6.png', '9ad92f1c1542.png', 'df3adfd6ba36.png', '6363b360aefb.png', 'e96099b961b4.png', 'eba3acc42197.png', '203275daf46d.png', '44f7f3ef9d50.png', '9dab2e6ba44b.png', 'd2c2f02bb313.png', '18af532e7e1e.png', 'd6df4fe492ec.png', '3ca637fddd56.png', '4c389d033cb0.png', '15f8d769935c.png', 'e5d56f4f359b.png', 'f00ce9b9d6f4.png', '175dd560810a.png', '61da799bf0aa.png', '12058bbb8299.png', 'a07d9a5045cb.png', '9c14ce27cbfc.png', '9b4fc15df3c8.png', 'a1edf0e66592.png', '295fdc964f6e.png', '9b70f84400af.png', 'ab3c505b624f.png', '7a77c3eb468c.png', '2d9d97a6e713.png', 'bc92a61a1f9c.png', '68ddb15a74de.png', 'd16398c971e9.png', '3254e48c8aa0.png', '77ab222bf85c.png', 'df6d13d04da1.png', '20d5fdd450ae.png', '29a13e666266.png', 'fa748b57262b.png', 'ea5c42a78979.png', '0efc93ec838b.png', '97da093947e8.png', '7356dd08b0ae.png', 'd2dc86021c67.png', 'd16e39b9d6f0.png', '7aabd768abff.png', 'b351ae99413a.png', 'b0c9a492e068.png', 'aa9b8f05f4bf.png', '71e43b4f8ba6.png', '58eb3809f456.png', 'f8d62557ad0c.png', 'd1fa0f744620.png', 'd5ad3362424c.png', '240b25a7debe.png', '291f581d365e.png', 'b0acd3593310.png', '7eeb191ad06b.png', '2b074afdf626.png', 'ad570b850a4f.png', '0024cdab0c1e.png', '932181b93b2f.png', '3abac0961bfd.png', 'cd972e5639e0.png', '6d6be4cfc73f.png', 'a66c3165876f.png', '1120f6d08d95.png', 'd1a24527a15d.png', 'aa31bc6b8f4d.png', '348598d01e18.png', '46f56c38051f.png', 'ae2e888905ba.png', '4a7dc013e802.png', '64a13949e879.png', '53273d664cd8.png', '4731e708ede3.png', 'a2163f0c2af5.png', '207a580de0ea.png', '6efa36d59ada.png', '4210809074c1.png', '1caba2fb38f6.png', '5ca779ace6e7.png', '75369248dba0.png', '1116271db4ea.png', 'c947bb6cf9f6.png', 'dbee04ae6426.png', 'b90bc89ce8d8.png', '683023cda6a5.png', '50ddd7d976df.png', '1bea04b2bb2d.png', 'fa7fa797c650.png', '807135cbc438.png', '849a91e9ab28.png', '4aa3d771c5e4.png', 'f3bb996b45ce.png', '75a071608ea6.png', '799214e8b07c.png', '04aef84a2cc1.png', 'beb00fa6e7c9.png', '3ee17aa12e46.png', 'a8c9fcdbc0be.png', '7a3ea1779b13.png', 'e251bdf05b85.png', '4eaf2f81819d.png', 'a93f1ea3ff4a.png', 'a61723fc38c2.png', 'd990a3f0cbdb.png', '9a1029536d78.png', '47e51065b819.png', '66bfec8d6bcd.png', 'a2811f512c1c.png', '9a9b21215c55.png', 'c280730cc211.png', 'a07efb1ecfc0.png', '5879285f9d8d.png', 'a987aa7aac37.png', '58b866484a05.png', '101b9ebfc720.png', 'afc345cc9145.png', '6f3b62e5b7f5.png', '7b20210d9120.png', '15e96e848b46.png', '4276b82e4489.png', 'd4f32b9c07df.png', 'f850cb51fdba.png', '26463a5fb949.png', '9be71d6d7e59.png', 'a0b7ad98df57.png', '02dda30d3acf.png', 'd97911a32918.png', '5a27b9b2a9c1.png', 'be197b663520.png', 'a0fd94e2ad76.png', '4036471a1bb7.png', 'b74de20d73de.png', '12bc439d373a.png', '27933cdbe0cc.png', '3a61e690f4bb.png', '312694ea8e6a.png', '529906ff9dfa.png', '9904939ab83d.png', 'f69835dc7c50.png', '4ffa38550c95.png', 'cb75210abebe.png', 'c81c6911f5e0.png', '436fa3fd145a.png', '4554062fa836.png', '789434d095d1.png', '2a4520f1f9a3.png', 'c4e8b1ec8893.png', '6d454444f17c.png', '5bea250d8bf5.png', 'ba25f947f4ec.png', 'e4dcca36ceb4.png', '15528e740543.png', '22a6da005395.png', 'c58e5c0c5b33.png', '7e160c8b611e.png', '6c30dd481717.png', '60e269e3e188.png', '5321ab64f9ea.png', '1e1fb019710d.png', 'cd54d022e37d.png', 'fecf4c5ae84b.png', '191cf5668f33.png', '2700754f71e9.png', '977e1ca77653.png', 'ff1e940105f9.png', '1a90fad9ffa2.png', '3c311c9109b0.png', '482088e6be44.png', 'f252046c0fe6.png', '388279491b5d.png', '45693d027798.png', '99c626e58464.png', '3b4a5fcbe5e0.png', 'dccdf750c962.png', '66a0bf258013.png', '387138ddf43d.png', '2f7fbdcc9a4b.png', '05195a3db5e2.png', 'd364423ec6f9.png', '0abf0c485f66.png', 'adb56cecafaf.png', 'c446985355f1.png', '86d6808f0609.png', 'c0202976c670.png', 'a14bbd9a583e.png', '0423237770a7.png', '1db0393cdbc1.png', '55eb405ec71e.png', '38c7153457e2.png', 'f9aa35187bf3.png', 'ee059945b08a.png', '57760be09c03.png', '62ab144d5cee.png', 'e42d9a94a66d.png', '9da74370835a.png', '5b994ff78547.png', 'a528be013a04.png', 'a8e88d4891c4.png', '178412895d5e.png', '369229040a34.png', '7831ce1d895e.png', '1df0431bfa73.png', 'cb39761f0712.png', '70d657f8f503.png', '3dbfbc11e105.png', 'f366fb1cc475.png', 'e12f9f19d1be.png', '10eefba568dd.png', '7d48f8cdfb69.png', '9e2ba2b979f1.png', '7bc00e58d419.png', 'b3a994760537.png', '65a3b13ad9a0.png', 'c613db1cab27.png', '4b6cb0bcfd44.png', 'ff0740cb484a.png', '840527bc6628.png', '91b6ebaa3678.png', 'c73c5f6ef664.png', '77baa08a1345.png', '53f6c1c65c04.png', 'fac399455195.png', 'a9a3225cf4b5.png', '24f271c87e73.png', 'a75bab2463d4.png', '2bbcfdc477db.png', 'c98f623d08d1.png', 'f4d3169b468a.png', '67d8f94f04e0.png', 'fb88d23fc5fe.png', '5d4e5fd34d91.png', 'b95d4dd8e5e2.png', 'a0445785e2f7.png', 'f09cfc6a4dbd.png', '5ed6dc419e4d.png', 'c96f743915b5.png', '2c77bf969079.png', '40e9b5630438.png', '1cb6961d141c.png', '190a309f2cc5.png', '35ac70c0d08f.png', 'd91273efb92a.png', 'c7d0deb71576.png', '4350a1b2f3cb.png', 'af6a1508cd95.png', '00cb6555d108.png', '1c4f3aa4df06.png', '73ba798fee25.png', '0b8bdec9d869.png', '32a3eb37ff40.png', '66366a90d1ef.png', '9f37c98b8187.png', '9ac41b9a809e.png', '4294a14c656a.png', 'ab7991df166b.png', '69b3a00927fc.png', '3bf3085ac167.png', 'eabc7c716255.png', '780f9c237c56.png', '2d552318eb07.png', 'a06e41bd2634.png', '2c1d5be654dd.png', 'fce93caa4758.png', 'd39752cb6e57.png', 'b9127e38d9b9.png', '992b9a07b25f.png', 'dd110d2b8c21.png', '1a1b4b2450ca.png', '28f93cad89c5.png', 'e7a7187066ad.png', '677f087cd697.png', '0cae727cf119.png', '5a36cea278ae.png', 'fed5bb685832.png', '9bafbbd152d2.png', '9ab18a4a957f.png', '5f70ad48a525.png', '4e0656629d02.png', 'f3b6b7ca1eb1.png', 'dbfd238b3468.png', '2d870833c0c9.png', 'ac81fc200162.png', '665ce639a331.png', '4818672273af.png', 'e03a74e7d74f.png', '215d2b7c3fde.png', 'beeca5f14618.png', '405085b53d7b.png', '87295c5fa1cc.png', '10a5026eb8e6.png', '55968f0e63c4.png', '17eff993386f.png', '821789e9053f.png', 'a3ad6c2db6f1.png', 'a7ec056502e7.png', '1006345f70b7.png', 'd95959798b57.png', 'cc671a73e1cb.png', '686ed1dbae20.png', '82088c6734e6.png', '27f82ada84ac.png', 'e04f3c6619a3.png', '419406328dcd.png', 'e7fc93ac5b6d.png', '4c3c1ed09771.png', '338326891d84.png', 'ca7570c5925c.png', '81704925f759.png', '9ae54843c69a.png', 'be7f791a7877.png', '38e111cac46f.png', '354b8911d6ed.png', '2131aa3a1e6f.png', '1c6d119c3d70.png', 'a2dff8dbc9f8.png', '9ed666e982cd.png', '6b664ed2a938.png', '92e3d608fd3c.png', '1df0a4c23c95.png', '1c4d87baaffc.png', '89d9c071a56f.png', '166068a24416.png', 'dfc7ec7db0e0.png', '0083ee8054ee.png', '45c39ab9e797.png', '5a5d3798c357.png', 'cadde4030858.png', 'b6304c545f95.png', '3dbc90c7ee7d.png', '383e72af1955.png', '6e92b1c5ac8e.png', '7a0cff4c24b2.png', 'e82232a3c28b.png', '18ce0cdc473d.png', '25b4080f598b.png', '1dbdc32c17db.png', '4dd7b322f342.png', '93be637084a2.png', '9f8112c710be.png', '2cfe8703f265.png', 'e811f39a1243.png', 'd3e884109b45.png', '63d217b059b6.png', '5069feccd866.png', 'bde1063a5dd7.png', 'eda29a9d78f3.png', '91a88d3b0358.png', 'a476fd984005.png', 'a7c10ca6c117.png', 'a2b97d98f130.png', '942f544c4e15.png', '8dfa629ca74e.png', '8f9819752ca0.png', '4d47300e3ddb.png', '999ad827ed35.png', '540e4973829e.png', '6b30767595d8.png', '8bc6716c2238.png', '33b893e18eb3.png', '94145d1f42cf.png', '3d2ecffe0386.png', '3730c322d35b.png', '609be3ca5ddf.png', 'c6c2bad91f23.png', '5db895d3f1fc.png', 'a8854768549f.png', 'd10d315f123f.png', 'cbd0870aa933.png', '6194e0fff071.png', '8cb6b5b2f19c.png', 'd83d0695e215.png', '9be0683649ff.png', '33b978734eab.png', '547b37da9223.png', '521d3e264d71.png', '15f440753916.png', '1ca91751be4d.png', 'd1cf31577a59.png', '25002fe43f92.png', '6107a2e9f60e.png', '150f92b45349.png', '8fd7ad26e691.png', 'e2a233493b90.png', '4d1cf360b2d7.png', 'aa9cfe639ef1.png', '7c629b491d1a.png', '37c4dfe03aba.png', '415f2d2bd2a1.png', '5eb311bcb5f9.png', '8fbb2ca39911.png', '2241b7e90782.png', '43bc7c066dfb.png', 'd81b6ed83bc2.png', '8a234d68b27e.png', '0231642cf1c2.png', '59ee65760535.png', 'a804cef3e51f.png', 'c58971bcebb2.png', 'e66855a5c583.png', 'e33766353db2.png', 'aafe980edd0c.png', 'd29b37d110f3.png', '2a3a1ed1c285.png', '4958bfcc9f38.png', 'da44f80b422b.png', 'aeccef0bdc26.png', '737ef6226677.png', 'a2ad3da4c7d6.png', '628b581aa905.png', '233d948e2544.png', 'b11dcdcbc8c8.png', '31360e44ac64.png', '6b869f37cdf3.png', '56e56aa08362.png', '5090917a2676.png', '1c0cf251b426.png', '4205e9deb058.png', '1db18bdd43aa.png', 'e1dc02a3dc2a.png', '4f6abc40c72d.png', 'b0cc9f8d06e4.png', '69f43381317b.png', '8201cab8322d.png', '0924cec998fa.png', '9785805af1b8.png', '789c60cba801.png', 'd7ab5c040294.png', '2b3a4a81d748.png', '50915e2329a1.png', '3b5dffe159b6.png', 'e1418d28d668.png', '8ab3faa3701f.png', 'eadfc8809ec8.png', '94a67ec0714f.png', 'fe06dad6851c.png', '837acf120946.png', 'ea9c41e1ced0.png', '653534ded339.png', '7b8c78b41c0d.png', 'be521870a0ea.png', '6bb30ec3231a.png', 'f9d52509c571.png', 'd968a983d4d2.png', '7b49041cbf17.png', '4826d10030b3.png', '87b1938994b5.png', '803120c5d287.png', '53c874dbc594.png', 'c62cef02efa2.png', '4393c5bc576a.png', '77e15f213b04.png', 'c261b1aaa828.png', '55eac26bd383.png', '98f7136d2e7a.png', 'bb2f89488ecd.png', '5a11d21c2828.png', 'e12b67835e03.png', 'aa8a1e814811.png', '8596a24a14bd.png', '3f752fcccec0.png', '8bad12d70368.png', 'bb7e0a2544cd.png', '03e25101e8e8.png', '300305ce82d2.png', '9c52b87d01f1.png', '57f933d3d7c7.png', 'f8372e80f731.png', 'f71bea807c96.png', '78b3f819dcc5.png', 'be21d8b60e2a.png', '84b472c49cfa.png', '0c55d58bebaf.png', '51af8c112682.png', 'ad3fc5076852.png', '44e0d56e9d42.png', '66393d8c60ba.png', 'd838d5b9f571.png', '3f5b4c2948e8.png', 'a9b3177f01c0.png', 'b82dfa63a75f.png', '7d1da90d3ca9.png', 'fe3b0e50be78.png', '49c5e7f6b8d2.png', '7d261f986bef.png', '42cc993f23a9.png', 'da0a83f074f3.png', '8a01daa423f7.png', '51a1d162e223.png', 'e740af6ac6ea.png', 'bd5013540a13.png', 'ff4955e76894.png', '1dfe599d12a9.png', '875d2ffcbf47.png', 'c013e869acce.png', '262ad704319c.png', 'a4359815f152.png', '8a8a251770cd.png', 'a76b69e443ce.png', '0981195eb9fb.png', '345b1f0abbba.png', '82d364726a58.png', '65c958379680.png', 'ef8109305128.png', '910bfd38e2f5.png', '94372043d55b.png', 'd2901144070c.png', 'a53d6d2472a6.png', 'ead23cc922ed.png', '189cbbc9e5e3.png', '38b9bb961847.png', '0fcfc6301f3d.png', '1ade1e949383.png', 'ca9c912ebad7.png', 'b99c825b93c5.png', '09935d72892b.png', 'f481f76a6b75.png', 'a19ecd0a706e.png', '0cecc2864b7f.png', '0161338f53cc.png', '7435e9a3e36e.png', 'b574d229ec4c.png', '64b9206afb3f.png', '1e4650743fa2.png', '51030843fde2.png', '26cd40b57ad1.png', '83a63c4a3e4a.png', '7b87b0015282.png', 'ba0107fb1bfd.png', '726dff37edc0.png', '8ef2eb8c51c4.png', '5b301a6d1ac7.png', '393fa5a023a5.png', 'a627eb8c08c5.png', '09eeafa9656a.png', 'cac80797770f.png', '315c1a0d87fd.png', 'fbcbc81cf9be.png', '2fdffb6160a6.png', 'b2ffa3e18559.png', '6c6efb6b1358.png', '568455854a11.png', 'ca05f7e7801b.png', '2399d68d407f.png', '0ef4c61dc056.png', 'd66ccb75ada1.png', '2f7789c1e046.png', '1efa5d443707.png', 'e5de79795c1d.png', 'f5c953bee7cd.png', 'c6916bc42016.png', '65f69234c8a7.png', '63363410389a.png', 'e26d8718ca58.png', 'a188c60b93fb.png', '7335a2d43ada.png', 'd85a842d20bd.png', 'c23ff6dcf15e.png', '1b862fb6f65d.png', '382752f6694a.png', '2f143453bb71.png', '9e5737f771c3.png', '59f3f70abddd.png', '73a07e2ea23e.png', '3d663a6a50a3.png', '014508ccb9cb.png', 'eb1d37b71fd1.png', '6c250a30593b.png', '8714d17bb6da.png', 'fcc32dffd24d.png', '352e4a939242.png', '936299166bea.png', '8000a6b97a84.png', '9d62478042b6.png', '0790515cf5af.png', 'e3cd96cb094c.png', 'ffa47f6a7bf4.png', '89fc080f7e83.png', '1a369baf9ee6.png', '10de500cf0c5.png', '692e946b1f85.png', 'da0a1043abf7.png', '49386d603494.png', 'aebe87a423c8.png', '913490237ad4.png', 'd7e5fe5245e0.png', '5cab3ef4b31c.png', '9b418ce42c13.png', 'ac2c814949f9.png', '86fbac86ed3e.png', 'a86c6283fd78.png', 'ae20112e7a1e.png', 'a94da3d3b5c0.png', 'af828dab3ffc.png', '191348830ddf.png', '6bf26b777e3a.png', '7eee3d1f1268.png', '691eeb59b4cb.png', '232549883508.png', '42b93b574f23.png', '916ec976ff30.png', '460893cd86e3.png', '8f14bca04b47.png', '721214151233.png', '3b232b394e4f.png', 'b5b913358b32.png', '246e4506824a.png', '97f290d31813.png', '69c4cbb630de.png', '0d744aed4d64.png', 'eda1d75cbcf0.png', '423abbaa5fad.png', '2a8a9e957a6c.png', 'ff59d44a70a7.png', '8e7981855125.png', 'de18071c36e6.png', '9122b31414d3.png', 'e96bd80a8a53.png', '39134907127a.png', '0eced86c9db8.png', '5288f7441f64.png', 'b402daa0864c.png', '37c523296d42.png', '812d5adafaf2.png', '261c6bd63bff.png', 'e8e44b3160e3.png', '3fa4f4d77177.png', 'bfe467b7e997.png', '08c17a2d95b7.png', '48c72dec46e5.png', '05113073b268.png', '0709652336e2.png', '5a444c32cd9a.png', '172df1330a60.png', '5257cb536da2.png', '51aa3361294c.png', 'bc34ed91c9bc.png', 'e34fa07bd64d.png', '2a3378bcfbcc.png', '0f882877bf13.png', '4f60129e9a5b.png', 'a45c30da0c72.png', '58529a8638d0.png', '6089fa333013.png', '7ba6b23c4b46.png', '7fe7309d0b4f.png', '1db6bb46c102.png', 'a15652b22ab8.png', '85fce24084da.png', '682312e82ee3.png', 'f531232ecb55.png', 'cab3dfa7962d.png', '8bf2d925dc0c.png', '98104c8c67eb.png', '6d4f6c9a8406.png', '4360a112db10.png', 'e246cd89e1cc.png', '1dd9adcbfff4.png', '83038ca49b6d.png', '4d167ca69ea8.png', '29580bed2f7d.png', 'c48ae5da188e.png', '4462fba1d2a1.png', 'c5a6f432a1ec.png', '71e4130bf5c8.png', 'd3e56584a481.png', 'c56e65f74187.png', '3b9817a39adf.png', 'ed2c06fcc573.png', 'a73d012c4c38.png', '996f9bba4ef0.png', '9bd008aab548.png', '8af50c9d0a86.png', 'e037643244b7.png', '98441214557f.png', 'ca1036496659.png', 'e2c3b037413b.png', '6e68e742f5bc.png', 'b70cb31b9abb.png', 'b50b30aa6e6c.png', '0bf37ca3156a.png', '5712e2aa73a2.png', 'c1799a6f5c65.png', '8660e1864665.png', '549381330191.png', '1ae8c165fd53.png', '76516f828d88.png', 'd27ac9e54901.png', 'ebf4b22240f4.png', '2f8d14a7d390.png', '384db24ebbd7.png', '8c29a76fa08c.png', '1eee55494271.png', 'c5ad60521f8c.png', '5723d0ec895e.png', 'f68690db78d3.png', '906d02fb822d.png', '7c2f820a6425.png', '6733544ae7a6.png', '76c0c7e1b6cb.png', '263d8851e33b.png', '2682e6da9050.png', 'ee36ca728641.png', '1f31701dd61b.png', 'a1b28bcbce00.png', '5633ced07d8e.png', '9c893e16c055.png', '2bd4d4fbed5c.png', 'db6207e62c7b.png', '83517eaeccb9.png', '3e86335bc2fd.png', '4ccfa0b4e96c.png', '4029d70e9d8a.png', '14ee87d6cc42.png', '89b725411cee.png', '7f2cce721e19.png', 'a06b353e7bed.png', 'd1f1ea894da1.png', '65a7fe9482fe.png', 'be8697eb2078.png', '6f923b60934b.png', '6cdd0f985270.png', 'd667af5742f6.png', '7d1b40fdbd86.png', '6f0e5848d9ce.png', 'e0313be77035.png', '38373431d996.png', 'd807c53c1399.png', '4bd5d0b30198.png', '135575dc57c9.png', '3ffa14d60b24.png', 'f61bf44c677c.png', '7526cf435753.png', '8329e80c10ac.png', '1d11794057ff.png', '61ac9b0dc6b9.png', '7bc4dd99eee5.png', '3128eb593012.png', 'ef26625121b3.png', '93802d1e3c41.png', 'd871895742b1.png', '060e00d1e2ab.png', 'a879c3569552.png', '331121c65e88.png', '0d310aba6373.png', '39f8935185e6.png', '5905a9b06a73.png', '905cc86bf100.png', '92fcf50b3562.png', '904b03ad5594.png', 'b310bd564329.png', 'b1f4122fd36a.png', 'ea6a53e54d0f.png', '111898ab463d.png', '19ef4d292196.png', '542964865b1e.png', '916915f01e17.png', 'da2bdf4236ac.png', '0e82bcacc475.png', 'ba08cee68c71.png', '0ca0aee4d57e.png', 'b6fd109b1bc9.png', 'ac0a48ccbf70.png', '44271f3cb18f.png', 'c4aef0d88d1b.png', 'eebd1e195952.png', 'f994a3b07935.png', 'ca360bec5851.png', '4cde86044ad1.png', 'aef9016557ca.png', '5f13e8a07344.png', 'bd9904495ccd.png', '43e9c66eb0f3.png', '77b7b71ebcc3.png', '4b618537d52f.png', 'ab50123abadb.png', '4e43d05cc2ef.png', '1d2472849dce.png', 'fc4d69128e7c.png', '2463bb04ebc3.png', 'ba2ea9182090.png', 'e9286ddf6ffe.png', '8af6a4e5396f.png', 'af87d48ffe01.png', '08b6e3240858.png', '7005be54cab1.png', '53327edb9e4d.png', 'cd66754e1b3b.png', '9c514d2d5b3f.png', '1fd5d860d4d7.png', 'de16416220de.png', 'e6a5e4718873.png', 'ef99c499d665.png', '25e9fd872182.png', 'a11bf2edd470.png', '28503940d10b.png', '370f575adb23.png', '44855f666225.png', '186c1835eec5.png', '51d574513bcb.png', '7b211d8bd249.png', 'f066db7a2efe.png', 'd2afca74cbc3.png', '57ce57a8cfb0.png', '252305189b3a.png', 'd6228d951958.png', 'bf7b4eae7ad0.png', '2b48daf24be0.png', 'fe0e2dee1834.png', 'e68bdd36e589.png', '286e9981dd9b.png', '478fc46eaa49.png', 'a56729de89e9.png', '248139c423c4.png', '7a12f49e29df.png', '5f4a8c074bd5.png', 'a763661f98a5.png', '58184d6fd087.png', '1ee355480567.png', '1d29cb2f4296.png', 'ab1c20a94f3f.png', '0cbcc7b23613.png', 'fa59221cf464.png', '11242a67122d.png', '668e853258cd.png', '52edbe29d655.png', '9910c827e2fe.png', '523b3f0fc646.png', 'd18aea8238a0.png', '6a57a3db3eff.png', 'ef4121e9bb67.png', 'd2c6b99ef62c.png', '094858f005ab.png', 'a8c54e2a4b79.png', 'bdf47b9f10c4.png', 'a654b25124c3.png', '70ed3ec68b94.png', '6cffc6c6851a.png', '17e6116b89b3.png', '4a96c28f3f07.png', '7d8f67cadc29.png', '82f2784ead76.png', '91cbe1c775ef.png', 'a646c084928c.png', 'af345c68e836.png', '5c817060c0ed.png', '23148a40ecb0.png', '6c315ad3d07f.png', '37de05ef12a5.png', '7f60f2a083d3.png', '66cd9c28e636.png', '1f4bf8e28b41.png', '9de9421f17e3.png', '8d4ff745a409.png', '00e4ddff966a.png', '8b568d47a1fd.png', 'f62b8a076833.png', '79cbae28d8b2.png', '4cfd22ae43d4.png', '971bb98ab935.png', '83e529e95b0e.png', 'f35d80bb1a22.png', '331b87d1b9d1.png', 'b665041e1633.png', 'b376def52ccc.png', 'ceaa5803d780.png', '17f6c7072f61.png', 'db49cdf1ea64.png', '1e036f2e7095.png', '318eb706a134.png', '3601dac9bed7.png', 'a2d349f567a6.png', '9c5dd3612f0c.png', '5511f114e7ee.png', '6de39b94f634.png', 'af8aa32beee4.png', '541db13517e2.png', '080f66eedfb9.png', '75a4343b12f9.png', 'd57d1be1bbd1.png', 'caec68f11c86.png', '247ac63e5510.png', 'c639d837f5e4.png', 'e580676516b0.png', '5ce5eeaf757a.png', 'c57c164bca05.png', '3ce2f8a77a32.png', '82910bba4753.png', '907aaff827e5.png', 'ec6f1797a25a.png', '9870ce41cac4.png', 'd9e58e4d8689.png', '475c7ded0f7a.png', 'bf18ff30a8f6.png', '070f67572d03.png', '8185ce1cdcef.png', '0fc6829da85b.png', 'bd375ba756b1.png', '4d9fc85a8259.png', '435d900fa7b2.png', 'c0f15fe3b4b7.png', '753b14c27c83.png', '3f49f8d100e9.png', 'e19936582c61.png', '2ef10194e80d.png', '1ab3f1c71a5f.png', 'e07045d7c5f7.png', 'e60e4edb3ca9.png', '650fbed3fdca.png', '51cfeccaf40d.png', 'fd4c946c52bf.png', '6b128e648646.png', 'ca0f1a17c8e5.png', 'cc964bf04dbc.png', '46cdc8b685bd.png', '103f97a2ab15.png', '63c0eafd6aa9.png', 'ca25745942b0.png', 'e7defafeb957.png', '36a1e3c780a0.png', '702de9dcde32.png', '883ddb650967.png', '6fb656d506b2.png', 'b3c0c3330278.png', 'addf66a50f42.png', '28a4d00927b7.png', 'c80b0f27541a.png', 'ae94ce412de9.png', 'b294927b14b0.png', 'df4913ca3712.png', 'a484bdf85b4c.png', '63a03880939c.png', '937bc1b924b1.png', '1c13a1483f4a.png', '20f86e068276.png', 'ab653b8554c0.png', '18cde9649e90.png', 'a182b5b191de.png', '500aad15b7c8.png', 'd26bb2ed6e71.png', '4926dea289f8.png', '4e85aa647534.png', 'ec01f0862669.png', '99e8bf998285.png', '3f6c627e2ff2.png', '4b6895d0cf8d.png', 'a821b6ecef33.png', 'f86d1c404acb.png', '3796af4d987a.png', '99ecdb41d5e7.png', '8eb3337a54e9.png', 'ef476be214d4.png', '9039cbfcbb2f.png', '99c6a123ed6a.png', 'a76132e79688.png', 'da6bbb76d562.png', 'd1ca85af57c9.png', 'f09fd9433dff.png', '8c4ceddeb1c6.png', 'b0619ca93a5f.png', '150fc7127582.png', 'aca88f566228.png', '050bb1eafa76.png', '44ecf3f4efa5.png', 'e5f332efcbc7.png', 'cc12453ea915.png', 'af6166d57f13.png', 'bc7bf19b84e3.png', '404ede327e98.png', '5ac7a414560e.png', '6d3d1fe6c32a.png', 'b7a1bb106051.png', 'f9e1c439d4c8.png', '6b3860e8f64f.png', 'd5b4705ac2ee.png', 'a8652b2de23f.png', 'db4ed1e07aa3.png', 'b16dd4483ca5.png', '3f73c91b7e32.png', 'cec299c2a2d5.png', '18f1f979d30d.png', '10ecc5292ab1.png', '0fbbd665431f.png', '218c822a3dd9.png', '26e231747848.png', '537e5c578f40.png', '7ef5ff774a48.png', '2fde69f20585.png', '11b220a397b8.png', 'aea59ebec445.png', '10bf25731c08.png', '82deb07a6618.png', '50916d67bb51.png', '6c3589d7ed8d.png', '8d13c46e7d75.png', 'b9fe7da14a32.png', '237aa50edc34.png', 'e821c1b6417a.png', 'a721efb1e049.png', '2f4e81787d9b.png', '1e9224ccca95.png', '71c1a3cdbe47.png', 'c5bec7f1e5f3.png', 'cac40227d3b2.png', '835b9f6e12ba.png', 'dbb2c63f6f08.png', 'b746a6681ba9.png', 'ee3f5cf52188.png', '5db2e3a4594a.png', '29192375ab1b.png', 'a88365134c3c.png', '7f2123bc89a3.png', '1ee1eb7943db.png', '42a850acd2ac.png', 'b72a86d61959.png', '51405d042000.png', '152db3de8120.png', 'c9f0dc2c8b43.png', 'b6d9974443ce.png', '72595230840c.png', '8b8fe3fc8950.png', '84b4da14bc23.png', '624fb7317106.png', 'e0863b353093.png', '08752092140d.png', 'dcc6c0ad5cad.png', 'b66f23ffa730.png', 'e03e70bc8bba.png', '7347f5133a6a.png', '6a91eb157f47.png', '944a233fbf8e.png', '0babc12807b2.png', '2776d70724d3.png', '3428230bf1bd.png', '2dc647e00ad3.png', 'd10ef306996b.png', '42b08dca9b2f.png', '883c6a184f16.png', 'a0267206d51e.png', 'b0b3b16fc305.png', '535682537302.png', 'e599151ca14b.png', '12ae44be0d38.png', '8ab8d9b3ce3f.png', '93d6d20a5ee3.png', '0773a1c326ad.png', '86722fcd802c.png', 'c5b58cc992af.png', '3323fd59782e.png', 'aec51513cf45.png', 'cae33655ca00.png', 'be3a7d9e981e.png', '107aea0d9289.png', '76e589911303.png', '5d74f98d62be.png', 'b5834ee64541.png', 'd56d32a1d62d.png', '8dfff47b06b7.png', '869bbd3170cc.png', '3c726de3ee90.png', '1414128bead0.png', 'ce207b69ff37.png', 'd85ea1220a03.png', 'e52ed5c29c5e.png', 'a790a3b36390.png', 'f7508f14dd7b.png', 'fd0a70082e7c.png', 'e31c42a8652b.png', '992599744a23.png', '2f42e20db938.png', 'd774692d9919.png', 'e4a44f9158dc.png', '45ae04cfde5d.png', '941d874c8afb.png', 'a6c9e96a10d7.png', '92d9e9f08709.png', '2376e5415458.png', 'df5ce3ea7820.png', '236f56771ec6.png', '17d7d6b092f4.png', '89d2a7403a06.png', '0180bfa26c0b.png', 'e160a3b19911.png', '6c00dd8bf708.png', 'b91ef82e723a.png', '46c1548d730e.png', 'de55ed25e0e8.png', '73881f55a3ec.png', 'f0f89314e860.png', '04579e31e4be.png', '8010c931321f.png', '437cbec4a3f8.png', 'b8ac328009e0.png', 'bb11db08584a.png', '2f2e1949ad56.png', '21d18b022429.png', '76be29bb30b2.png', 'ee02294cc3d9.png', '165c548185f8.png', 'bf87aedf2489.png', '8d3d67661620.png', '537e50fdf22e.png', '07d8db76b301.png', 'cb02bb47fdc5.png', '19b0e3c734f5.png', '2b07790a2422.png', 'a02dfd67a925.png', '983c98354e9c.png', '05339950962e.png', '86410aa13b3e.png', '405b4f78658f.png', 'c3cd0200df79.png', 'ea7e21bab610.png', '441affbe99aa.png', '65f5d2a6eb7e.png', 'ceb601fe8dba.png', '35cd9832fc0a.png', 'febfb20dc311.png', '74eee788edee.png', 'bf9cba745efc.png', '973b0facfa9b.png', 'ffc04fed30e6.png', '3cdef7c591cc.png', 'abf0f56c6f12.png', 'e4151feb8443.png', '02cd34a85b24.png', 'e907d23cce3d.png', '64bad93fde3f.png', '64eb5a79dfdd.png', '97bf61736b86.png', '80f6b30ece8c.png', 'eb050765b323.png', 'a8eb35b3bcd2.png', '1c7a013eeba7.png', '494fc9c745a3.png', '5b644a403e1f.png', '6735931000ec.png', 'e1e490773462.png', '29f9e1ac9507.png', '20404ec7b518.png', '005b95c28852.png', '01d9477b1171.png', '3dec415b188a.png', 'c25e02b39c01.png', 'aeed1f251ceb.png', '4289af3afbd2.png', '0da632ca45e0.png', '61bbc11fe503.png', 'af5a0bc4e1fa.png', 'a81b06f50612.png', '09c8323c612e.png', '7af4d8704032.png', '7ae69d22075a.png', 'a01024054596.png', '6dfd80748e72.png', 'ad944bd56bb6.png', 'b0d6417bad3e.png', '9d9bfefa809c.png', '956765d5f46d.png', '07122e268a1d.png', '6155cf375354.png', '63b71347e95d.png', '530d78467615.png', '80c67efc8101.png', 'cfdbaef73a8b.png', '1e8a1fdee5b9.png', '16ce555748d8.png', '658ad9f09f5d.png', 'c2a58b2cfd0b.png', '582115961a3d.png', '9bf060db8376.png', 'b6bfe9db60e5.png', '67f5d89da548.png', 'a5c9a8c726b2.png', '4c9f0fdaaef7.png', 'e582e56e7942.png', '857230f64a2e.png', 'ee78ce914066.png', '94b9ccc73bb9.png', '0dc8d25b3f69.png', '772af553b8b7.png', '06b71823f9cd.png', '949710bead24.png', 'a384e688e228.png', '75238d945315.png', '2cceb07ff706.png', 'fc782722a50c.png', '49e4b95ee2dc.png', '44a86263117b.png', 'ad12cde115ab.png', '4318b6adeb97.png', 'aeb6f4fd2eed.png', 'a0d04a19cf40.png', '79540be95177.png', '200d947f75db.png', '5ead17e894ae.png', '68987fb159ab.png', 'dcf109df1a2b.png', 'cd314653a4d8.png', '60aa4e649abf.png', '13d71389563f.png', 'd2fb715b0c41.png', '498f143c0374.png', '7d626a7ffe76.png', '4dbce359d0e1.png', 'b9d0b83d70c3.png', '9cf7c1349673.png', '0232dfea7547.png', 'bf7047dc683c.png', '08c60c647673.png', 'd6803e467592.png', '259d30f693b6.png', '8860c7b11530.png', 'fe37f4492920.png', '9bbb6c455913.png', 'd69698f838db.png', 'f23902998c21.png', '3fc219927a97.png', 'a32886cb31ab.png', 'b22354b5f94b.png', 'e68746d426b2.png', '4ef7144e24ff.png', '2ef4a04aed1b.png', '4df6a81b476e.png', 'e8ddfc9709ce.png', 'd473f6fafba0.png', '03ff7d159f10.png', '83fda7c0500b.png', '0369f3efe69b.png', 'bcdc8db5423b.png', '5d3c8c1f57da.png', '5445255635f0.png', 'c6f5b5b5be41.png', '2974c6ad1d58.png', '51a078d6d43a.png', 'fea14b3d44b0.png', 'f901d460517c.png', 'a7b7dc8788b9.png', '1b495ac025b7.png', 'bac1744955c2.png', '7e0598cc88a0.png', 'a386ec9aabde.png', 'd7a01fca9838.png', 'a8b3c0961d42.png', '8448af27ba07.png', '891329021e12.png', 'f69400b316a7.png', 'f0098e9d4aee.png', '3a1ecf5e2839.png', '0fffa73e2402.png', 'd74ccc796517.png', '6ba5ed791444.png', '76e5b50f95a7.png', '30941b65348b.png', 'f6f433f3306f.png', 'c3e02d4a1798.png', '4fecf87184e6.png', 'b2b79b37d314.png', '72c31aa48e2c.png', '164cd5a3a6cd.png', '070d4ce5fd90.png', '2017cd92c63d.png', 'fe3f62695b2d.png', 'd0b132d2c7ec.png', '3c1efa38d0da.png', '838c87c63422.png', 'f0860c21533b.png', 'd85d052900b4.png', '59bd19c1c5bb.png', '9a78c6a7b1c2.png', 'd06ccd0cf4b8.png', 'e632e38fd2d4.png', '7269a1d84a57.png', '299086c6d1b5.png', 'b8297a2291f5.png', 'ed88faaa325a.png', 'd6e26fe51dce.png', 'e067b06fd655.png', '18b06f56ab27.png', '18323d8f2470.png', 'cae51154e1ce.png', 'cb547e723a16.png', '840a06a9c690.png', 'b3d12069e1c5.png', 'ebe0175e530c.png', '417f408ee8e0.png', '8acffaf1f4b9.png', 'f2094a20b275.png', '6e861bc3bd7b.png', '94dcb491143f.png', '3f0d3629d69e.png', '80a02014b418.png', '360832d84ce0.png', 'f2f569a64949.png', '2b21d293fdf2.png', '698d6e422a80.png', 'a1e236fbc863.png', '1f0e223b8055.png', '0e75d51152fc.png', '912fbe06407e.png', '1943983492e5.png', '5dc23e440de3.png', '4d009cebabc9.png', '3402124408ea.png', 'f920ccd926db.png', 'b8fb9f55cd6d.png', 'e55188915f9d.png', 'e01b7bac822b.png', 'a3fcf42ff56d.png', 'c7e827fc7f41.png', '6fe67fd7f5d1.png', '5995321563b7.png', 'a1b12fdce6c3.png', '89ed6a0dd53f.png', '63c7b0265775.png', '01f7bb8be950.png', 'aa10a4b2e709.png', '7da558d92100.png', '3823acc4e464.png', '6377e23928f6.png', '9f1b14dfa14c.png', 'aa5ce75edcf5.png', 'b05922e7abd3.png', '2c8101f14723.png', '633fe9dbaf39.png', 'ca7140ecf389.png', '26453eb7e989.png', 'b83a6eca125f.png', '0a3202889f4d.png', '475300735b7f.png', '4a4cb731f91a.png', 'ea588d1e5d96.png', 'd02b79fc3200.png', 'e7d2c2c3b30f.png', 'dee687c6e88a.png', '351e842842a2.png', 'cad5b1a82e60.png', 'ee77763a6afb.png', 'd6b109c82067.png', 'ae5d31979f19.png', '93421787f520.png', '454792eb6e05.png', '8ceff4c4c860.png', '40dd4e6e4444.png', '1a1e974a7dbf.png', 'f583a722434c.png', '2eba4279e503.png', 'd659d7fd5ccf.png', '7b9d519cbd66.png', 'ecb4500285ed.png', '66b88a4bc474.png', 'bd269a1f0e4d.png', '9df31421cdd2.png', 'b5a3ca5c0a80.png', '49d69c4c6290.png', '9033f1493da1.png', '0ada12c0e78f.png', '8e4a354e3da2.png', '278aa860dffd.png', '97d02a9b94f7.png', '5f51192841f7.png', 'c3a82acb7d7a.png', 'b5c80d0ed0ff.png', '1da25637859b.png', 'd6130f2ec903.png', '3206171db5be.png', 'ff4832d55461.png', '4384fa687afa.png', 'ae57c8630249.png', 'b960142a8de7.png', 'a443c4fd489c.png', 'c7b622ec8104.png', '71c22da3d6c6.png', '5efa24b03d5e.png', '358d2224de73.png', 'b43440c6ebe4.png', 'e499434242cc.png', '441848e0f308.png', '1b3647865779.png', '74898f372d2b.png', '484dbeb9bf2a.png', '81914ceb4e74.png', 'bb85097857fa.png', 'f48241b0c995.png', '66375b3c64db.png', 'c102db7634d8.png', '8433a032b96c.png', '4a0bba3b7d83.png', '05a5183c92d0.png', '210bfe0127c6.png', '0e0003ddd8df.png', '6762b2b48ea5.png', 'fd079d2e93a2.png', 'bffca6eeb2bf.png', '1cb814ed6332.png', '3de8ad4151e1.png', 'b9b99dad668d.png', 'e3ab63dc9a60.png', 'a3d2a0c4cd17.png', 'a673193cd5a9.png', '6daef3e5ca22.png', '65e6f1bd9875.png', 'fd87b6b2e664.png', 'bacfa2b8e706.png', '5078caaf1f57.png', 'a95d9d61ddd4.png', 'e85d410d6836.png', '36ec36c301c1.png', 'b77b8a1f09f1.png', '002c21358ce6.png', '6852f4531591.png', '4ad6109706e8.png', 'dc0f6e5b489b.png', '6e3526053de0.png', '7877be80901c.png', 'fbdc796290d4.png', 'aa94cc4bfd84.png', '12ab2f6397f0.png', 'a505981d1cab.png', '79ce83c07588.png', 'aa4407aab872.png', 'cb28adab4e8a.png', 'b842b43cb7fb.png', 'dc6fa1b38b83.png', 'f02956bd7c50.png', '266fbefa58fb.png', '999115d9386b.png', '7550966ef777.png', '099021fac3c9.png', 'cd8da43e3069.png', '5a03fe3ed15c.png', 'd88c4843aec3.png', 'f3a88d3026dc.png', '6b66b0e86f7e.png', 'f64214bed40e.png', '4489d421e5aa.png', 'b9c7c5182075.png', 'de730033c683.png', '4ec7796df40e.png', '7bc2e0fa3f72.png', '51cd8d2057fa.png', '8c84e96d9b01.png', '0af296d2f04a.png', '83d6e40c869f.png', 'b89938407ee6.png', '95e732e043a1.png', '8eeac97f02f0.png', '4464bb62bf20.png', '9a326446c431.png', '969f92a390db.png', '39b5b05d6cd9.png', 'c3aa424eff9a.png', 'd7078e8b0349.png', '9d75de31f1b8.png', 'f361060eda3e.png', '0eb52045349f.png', '5264a54e1830.png', '681c3c115684.png', '2bbd1f99ecc3.png', 'd141728fa392.png', 'a01c590c444f.png', '76b950c6ed5e.png', 'f431f2e119d7.png', '384e6c915722.png', 'cb0cc98d7e35.png', '3aa2b1ce6700.png', 'de57c9e9fa93.png', '1864d3411143.png', '20c883d3bd38.png', 'f819c65b803c.png', 'cd941e5bc659.png', '2532613a584a.png', 'a3132c8828e4.png', '071435a218ec.png', 'e9f3c85a2a02.png', '881ec6186e68.png', '7350c50667c5.png', '388f12e8df0b.png', '1968183f0e61.png', '6baafa56895c.png', '92d8a7c8e718.png', '8ff863f8874f.png', 'c26f98f58350.png', '0212dd31f623.png', 'f26b02ead915.png', '8a9bef2fbd4e.png', '224bb938e2dd.png', 'a77eb914b383.png', '25b0e72705a8.png', '7ddcfcea7369.png', 'cbe633765ea7.png', '595446774178.png', '1fddd7c98fd2.png', '96ce10a1dbd7.png', '84e8c62165b5.png', '80b5697f2a5e.png', '6af071b0ac6e.png', 'd16e59a2b33a.png', '9fefe2b44795.png', 'cbc2e57447c2.png', '86baef833ae0.png', '41960d5f58c2.png', 'a247961a5cd9.png', 'cd1c98ec48b1.png', 'a62ea0043aa7.png', 'e265c870f9b3.png', 'de778495a1cd.png', '38055d8b9f08.png']\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOVahD+GVBbNxivmLcwFb9r"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}